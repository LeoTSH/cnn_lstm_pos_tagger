{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN+BiLSTM approach to Part-of-Speech(PoS) tagging to predict and restore punctuations to sentences\n",
    "\n",
    "The prevalent take on PoS problems have been to use BiLSTM or LSTM models due to their ability to capture and learn dependency information of sentences which are then used to make predictions.\n",
    "\n",
    "This project intends to combine CNN with BiLSTM. Making use of CNNs' ability to capture word and morphological of sentences and forwarding them to the BiLSTM.\n",
    "\n",
    "Outcome is to produce a hybrid model which outperforms a BiLSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code flow\n",
    "\n",
    "General code flow:\n",
    "\n",
    "1. Import packages and dependencies required for the application\n",
    "2. Load and process Ted Talks dataset to generate the corresponding labels  \n",
    "3. Remove punctuations from dataset to remove bias  \n",
    "4. Build vocabulary mappings of the dataset words and labels  \n",
    "5. Tokenize dataset and labels based on mappings\n",
    "6. Pad sequences and labels in dataset to maximum sequence length\n",
    "7. One-hot encode labels as data is not ordinal\n",
    "8. Split dataset into training and testing sets\n",
    "9. Construct hybrid model\n",
    "10. Feed training data into model with 30% of it used as validation\n",
    "11. Load and process Glove embeddings to extract weight matrix based on unique words in dataset\n",
    "12. Fit and train model with early stopping and checkpoint save of best results\n",
    "13. Save image of model architecture\n",
    "14. Delete current model and load saved model with best results\n",
    "15. Retrieve a sample of testing data and make a prediction on it\n",
    "16. Restore and print out results of prediction\n",
    "17. Make predictions using testing set and construct a Confusion Matrix & Classification Report from it to evaluate model\n",
    "18. Print out Precision, Recall and F1-Scores for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import required packages and dependencies\n",
    "import io, json, keras, string, itertools, random, time, datetime, numpy as np, matplotlib.pyplot as plt, tensorflow as tf\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.initializers import glorot_uniform, random_uniform\n",
    "from keras.layers import Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Embedding, Conv1D, Flatten, Dense, Dropout, LSTM, Bidirectional, TimeDistributed, \\\n",
    "Dropout, Input, concatenate, Reshape\n",
    "from keras import regularizers\n",
    "from keras.utils import plot_model\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom functions to help display the Confusion Matrix and process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom functions\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    '''\n",
    "    Description: \n",
    "        - Prints and plots the confusion matrix.\tNormalization can be applied by setting `normalize=True`\n",
    "\n",
    "    Args:\n",
    "        - cm: Confusion Matrix\n",
    "        - classes: Names of classes\n",
    "        - normalize: Whether to or to not normal values in Confusion Matrix\n",
    "        - cmap: Plot color\n",
    "    '''\n",
    "\n",
    "    # Check if normalize is true or false\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    # Format axis and plot Confusion Matrix\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "def get_labels(seq):\n",
    "    '''\n",
    "    Description: \n",
    "        - Creates a sequence of labels based on the input sequence\n",
    "\n",
    "    Args:\n",
    "        - seq: Input sequence\n",
    "    \n",
    "    Returns:\n",
    "        - Sequence labels\n",
    "    '''\n",
    "    \n",
    "    labels_seq = []\n",
    "    seq = seq.split()\n",
    "    for i in range(len(seq)):\n",
    "        if '...' in seq[i]:\n",
    "            labels_seq.append('<3-dots>')\n",
    "        elif ',' in seq[i]:\n",
    "            labels_seq.append('<comma>')\n",
    "        elif '.' in seq[i]:\n",
    "            labels_seq.append('<period>')\n",
    "        elif '?' in seq[i]:\n",
    "            labels_seq.append('<question>')\n",
    "        elif '!' in seq[i]:\n",
    "            labels_seq.append('<exclaim>')\n",
    "        else:\n",
    "            labels_seq.append('<na>')\n",
    "    return labels_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "np.random.seed(50)\n",
    "model_name = 'ted-glove-cnn-lstm'\n",
    "\n",
    "# Dimension of the embedding layer, must match that of the word vectors\n",
    "embed_dim = 300\n",
    "\n",
    "# Maximum sequence length, how long each sentence/sequence should be\n",
    "max_seq_len = 128\n",
    "\n",
    "# Dropout are\n",
    "drop_prob = 0.35\n",
    "\n",
    "# Number of filters for each CNN layer\n",
    "filter_sizes = [128,128,128]\n",
    "\n",
    "# Kernel size for each CNN layer\n",
    "kernels = [3,5,7]\n",
    "\n",
    "# Weights and bias initialization for each CNN layer\n",
    "kernel_weight = glorot_uniform()\n",
    "bias = glorot_uniform()\n",
    "\n",
    "# Regularization for each CNN layer\n",
    "kernel_reg = regularizers.l2(l=0.0001)\n",
    "\n",
    "# Number of hidden units for Dense layer\n",
    "lstm_hidden = 1024\n",
    "\n",
    "# Number of hidden units for BiLSTM layer\n",
    "lstm_hidden_2 = 1024\n",
    "\n",
    "# Learning rate for Adam optimizer\n",
    "adam_lr = 0.001\n",
    "\n",
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Number of epochs to train for\n",
    "epochs = 50\n",
    "\n",
    "# Portion of training data to be used for validation\n",
    "valid_split = 0.3\n",
    "\n",
    "# Set model training early stop criteria and save best checkpoint file\n",
    "early_s = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "chkpt = ModelCheckpoint(filepath='./cnn_lstm_model.h5', monitor='val_loss', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define miscellaneous settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set misc parameters\n",
    "# Get current date and time\n",
    "current = datetime.datetime.now()\n",
    "date = current.strftime('%b-%d')\n",
    "\n",
    "# Tensorboard settings\n",
    "tensor_b = TensorBoard(log_dir='./tf_logs/model_{}_hidden_{}_dropout_{}_embed_dim_{}_lr_{}'.format(model_name, \n",
    "                        lstm_hidden, drop_prob,\n",
    "                        embed_dim, adam_lr), \n",
    "                        batch_size=batch_size, \n",
    "                        write_graph=True, histogram_freq=0)\n",
    "\n",
    "# Set class names\n",
    "class_names = ['Pad', 'NA', 'Comma', 'Period', 'Question', 'Exclaim', '3-Dots']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and process Ted Talks dataset to generate the corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre number of sentences: 237986\n",
      "\n",
      "\n",
      "(185073, '  and this is more fun.so this last one is called \"the sunshine kid.\"thank you very much for listening.old man sunshine was proud of his sun,and it brightened his day to see his little boy run,not because of what he’d done, nor the problems overcome,but that despite that his disposition remained a sunny one.it hadn’t always been like this.there’d been times when he’d tried to hide his brightness,you see, every star hits periods of hardship,it takes a brighter light to inspire them through the darkness.if we go back to when he was born in a nebula,we know that he never was thought of as regular,because he had a flair about him,to say the midas touch is wrongbut all he went near seemed to turn a little bronze,yes this sun was loved by some more than others,it was a case of joseph and his dreamcoat and his brothersbecause standing out from the crowd had its pros and its cons,and jealousy created enemies in those he outshonesuch as the shadow people.now the shadow people didn’t like the sunshine kid,because he showed up the dark things the shadow people did,and when he shone he showed the places where the shadow people hid,so the shadow people had an evil plan to get rid of him,first up — they made fun of his sunspots,shooting his dreams from the sky, their words were gunshots,designed to remind him he wasn’t very cooland he didn’t fit in with any popular kids at school.they said his head was up in space and they would bring him down to earth,essentially he came from nothing and that is what he was worth,he’d never get to go to university to learn,only degrees he’d ever show would be the first degree burnsfrom those that came too close, they told him he was too bright,that’s why no one ever looked him in the eyes,his judgment became cloudedso did the sky, with evaporated tearsas the sun started to cry.because the sunshine kid was bright, with a warm personality,and inside he burned savagelyhurt by the words and curses of the shadowy folkwho spoke holes in his soul and left cavities,and as his heart hardened, his spark darkened,every time they called him names it cooled his flames,he thought they might like him if he kept his light dimbut they were busy telling lightning she had terrible aim,he couldn’t quite get to grips with what they said,so he let his light be eclipsed by what they said,he fell into a lone star state like texas,and felt like he’d been punched in his solar plexus.but that’s when little miss sunshine came alongsinging her favorite song about how we’re made to be strong,and you don’t have to be wrong to belong, just be true to who you are,because we are all stars at heart.little miss sunshine was hot stuff,the kind of girl when you looked at heryou forgot stuff,but for him, there was no forgetting her,the minute he saw her her image burned in his retina,she was out of this world, and she accepted him,something about this girl meant he knew whenever she was next to him,things weren’t as dark as they seemed, and he dared to dream,shadows were nowhere to be seen; when she was there he beamed,his eyes would light up in ways that can’t be faked,when she grinned her rays erased the razor-tipped words of hate,they gave each other nicknames, they were \"cool star\" and \"fun sun,\"and gradually the shadowy damage became undone,she was one in a septillion, and she was brilliant,could turn the coldest blooded reptilians vermillion,loved by billions, from chileans to brazilians,and taught the sunshine kid the meaning of resilience.she said: “all the darkness in the worldcannot put out the light from a single candleso how the hell can they handle your light?only you can choose to dim it, and the sky is the limit, so silence the critics by burning.”and if eyes are windows to the soul then she drew back the curtainsand let the sun shine through the hurting.in a universe of adversity these stars stuck together,and though days became nights the memories would last forever,whether the weatherman said it or not, it would be fine,\\'cause even behind the clouds the kid could still shine.yes, the sunshine kid was bright, with a warm personality,and inside he burned savagely,fueled by the fire inspired across galaxiesby the girl who showed him belief.thank you very much. twenty-five years ago, scientists at cern created the world wide web.')\n",
      "\n",
      "\n",
      "Length of longest sentence: 4305\n",
      "Chunked longest sentence: 19\n",
      "Post number of sentences: 238004\n",
      "\n",
      "\n",
      "Last Sentence  twenty-five years ago,  scientists at cern created the world wide web.\n",
      "\n",
      "\n",
      "Counter({' ': 5183083, 'e': 2732494, 't': 2236140, 'a': 1861243, 'o': 1797491, 'i': 1648311, 'n': 1556267, 's': 1429598, 'r': 1235404, 'h': 1200803, 'l': 926456, 'd': 817246, 'u': 676726, 'c': 626734, 'm': 542737, 'w': 529153, 'y': 504344, 'g': 480783, 'f': 439860, 'p': 413986, 'b': 347437, 'v': 239213, 'k': 204683, 'x': 40701, 'j': 37556, '0': 34453, '—': 27887, 'z': 21725, 'q': 18177, '1': 16995, '2': 11304, '5': 7462, '9': 6382, '3': 5412, '4': 4555, '8': 3904, '6': 3514, '7': 3450, '’': 920, '£': 291, 'é': 283, 'í': 84, 'á': 65, 'ó': 48, 'ç': 36, 'ã': 35, 'è': 30, 'ö': 29, '“': 21, 'ñ': 20, '”': 20, 'ï': 17, 'ü': 13, 'à': 12, 'ù': 11, 'ā': 10, 'ä': 7, 'ø': 7, 'ê': 6, '\\xa0': 6, '‘': 6, 'â': 5, 'ō': 5, 'อ': 4, 'ë': 3, 'ô': 3, '²': 3, '\\x80': 3, 'ī': 3, 'ì': 3, 'ʾ': 3, 'ć': 2, 'ร': 2, '่': 2, 'ย': 2, 'æ': 2, '\\x93': 2, '•': 2, 'û': 1, 'º': 1, '˚': 1, 'ò': 1, '送': 1, '你': 1, '葱': 1, '¢': 1, '\\x94': 1, 'ă': 1, 'ť': 1, '€': 1, '∇': 1, 'τ': 1, 'č': 1, '¡': 1, 'å': 1, 'ě': 1, 'ū': 1, '¿': 1, 'ú': 1, 'ð': 1, 'प': 1, '्': 1, 'र': 1, 'े': 1, 'म': 1, 'š': 1, 'ọ': 1, '̀': 1, 'ẹ': 1})\n",
      "\n",
      "\n",
      "Number of sequences: \t238003\n",
      "Number of labels: \t238003\n"
     ]
    }
   ],
   "source": [
    "# Read and load dataset\n",
    "data = open('./data/processed/ted_data', 'r', encoding='utf-8').read()\n",
    "\n",
    "# Convert all characters to lowercase\n",
    "data = data.lower()\n",
    "\n",
    "# Look-up table to remove punctuations from data\n",
    "table = str.maketrans('', '', punctuation)\n",
    "\n",
    "# Define and remove characters and bracketed actions\n",
    "replace = ['♫', '♪', '–', '…', '(applause)', '(laughter)']\n",
    "for i in range(len(replace)):\n",
    "    data = data.replace(replace[i], ' ')\n",
    "\n",
    "# Split dataset by sentences\n",
    "data_split = data.split('\\n')\n",
    "print('Pre number of sentences:', len(data_split))\n",
    "print('\\n')\n",
    "# Get longest sentence in dataset and its index\n",
    "print(max(enumerate(data_split), key=lambda x: len(x[1])))\n",
    "print('\\n')\n",
    "print('Length of longest sentence:', len(max(data_split, key=len)))\n",
    "\n",
    "# Clean and split the longest sentence into multiple ones based on full-stops\n",
    "data_split[185073] = data_split[185073].replace(',', ', ')\n",
    "data_split[185073] = data_split[185073].replace('.', '.\\n')\n",
    "long_sent = data_split[185073].split('\\n')\n",
    "\n",
    "# Check number of sentences from chunking longest sentence\n",
    "print('Chunked longest sentence:', len(long_sent))\n",
    "\n",
    "# Remove longest sentence at index 185703\n",
    "del data_split[185073]\n",
    "\n",
    "# Add chunked sentences back to dataset\n",
    "for x in long_sent:\n",
    "    data_split.append(x)\n",
    "\n",
    "# Check length of dataset after addition\n",
    "print('Post number of sentences:', len(data_split))\n",
    "print('\\n')\n",
    "\n",
    "# Remove empty rows\n",
    "data_split = data_split[:238003]\n",
    "\n",
    "# Check last sentence of dataset\n",
    "print('Last Sentence', data_split[-1])\n",
    "print('\\n')\n",
    "\n",
    "# Get corresponding labels for dataset\n",
    "process_labels = [get_labels(seq) for seq in data_split]\n",
    "process_labels = [' '.join(seq) for seq in process_labels]\n",
    "\n",
    "# Remove all punctuations from dataset\n",
    "sequences = [seq.translate(table) for seq in data_split]\n",
    "\n",
    "# Combined sentences back into a single piece for Counter\n",
    "combined_sequences = ' '.join(sequences)\n",
    "\n",
    "# Check if there are additional characters to remove\n",
    "print(Counter(combined_sequences))\n",
    "print('\\n')\n",
    "    \n",
    "# Get all words in the dataset\n",
    "words = combined_sequences.split()\n",
    "\n",
    "# Save inputs and labels for reference\n",
    "with open('./data/processed/processed_input', 'w', encoding='utf-8') as f:\n",
    "    for x in sequences:\n",
    "        f.write(x+'\\n')\n",
    "with open('./data/processed/processed_labels', 'w', encoding='utf-8') as f:\n",
    "    for x in process_labels:\n",
    "        f.write(x+'\\n')\n",
    "\n",
    "# Check number of sequences and labels\n",
    "print('Number of sequences: \\t{}'.format(len(sequences)))\n",
    "print('Number of labels: \\t{}'.format(len(process_labels)))\n",
    "\n",
    "# Load processed labels\n",
    "y_labels = open('./data/processed/processed_labels', 'r', encoding='utf-8').read()\n",
    "y_labels = y_labels.split('\\n')\n",
    "y_labels = y_labels[:-1]\n",
    "all_labels = ' '.join(y_labels)\n",
    "\n",
    "# Get all labels in the dataset\n",
    "labels_tag = all_labels.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build words and labels vocabularies and store them as json dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 104910\n",
      "\n",
      "\n",
      "Class distribution: Counter({'<na>': 4475054, '<comma>': 360733, '<period>': 294389, '<question>': 26054, '<exclaim>': 2330, '<3-dots>': 1394})\n",
      "\n",
      "\n",
      "Number of unique labels: 7\n",
      "{'<na>': 1, '<comma>': 2, '<period>': 3, '<question>': 4, '<exclaim>': 5, '<3-dots>': 6, '<pad>': 0}\n"
     ]
    }
   ],
   "source": [
    "# Build words vocab\n",
    "all_data = ' '.join(sequences)\n",
    "words = all_data.split()\n",
    "words_in_vocab = Counter(words)\n",
    "vocab = sorted(words_in_vocab, key=words_in_vocab.get, reverse=True)\n",
    "\n",
    "# Skip most common word\n",
    "vocab_to_int = {word: index for index, word in enumerate(vocab, 2)}\n",
    "vocab_to_int['<pad>'] = 0  # The special value used for padding\n",
    "vocab_to_int['<oov>'] = 1  # The special value used for OOVs\n",
    "\n",
    "# Check number of unique words\n",
    "unique_vocab = len(vocab_to_int)\n",
    "print('Number of unique words:', unique_vocab)\n",
    "print('\\n')\n",
    "\n",
    "# Build labels vocab\n",
    "labels_in_vocab = Counter(labels_tag)\n",
    "labels_vocab = sorted(labels_in_vocab, key=labels_in_vocab.get, reverse=True)\n",
    "label_to_int = {t: i for i, t in enumerate(labels_vocab, 1)}\n",
    "label_to_int['<pad>'] = 0  # The special value used to padding\n",
    "\n",
    "# Write vocab and label dictionaries to file\n",
    "with open('./vocabs.json', 'w', encoding='utf-8') as fv:\n",
    "    json.dump(vocab_to_int, fv, indent=4)\n",
    "    \n",
    "with open('./labels.json', 'w', encoding='utf-8') as fl:\n",
    "    json.dump(label_to_int, fl, indent=4)\n",
    "    \n",
    "# Check label classes distribution\n",
    "no_classes = len(label_to_int)\n",
    "print('Class distribution:', Counter(labels_in_vocab))\n",
    "print('\\n')\n",
    "\n",
    "# Check number of unique labels\n",
    "print('Number of unique labels:', no_classes)\n",
    "print(label_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize the sequences and their corresponding labels. Pad each sequence and its labels to maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sequence:  twentyfive years ago  scientists at cern created the world wide web\n",
      "\n",
      "\n",
      "Sample sequence: [14518    84   197   649    31 10130   501     2    81  1929   948     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n",
      "\n",
      "Sample label: [1 1 2 1 1 1 1 1 1 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "Encoded label [[0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]]\n",
      "Maximum sequence length: 128\n",
      "Sequence and labels length check passed!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize input sequences\n",
    "seq_int = []\n",
    "for seq in sequences:\n",
    "    seq_int.append([vocab_to_int[word] for word in seq.split()])\n",
    "\n",
    "# Pad input sequences\n",
    "pad_seq = pad_sequences(sequences=seq_int, maxlen=max_seq_len, padding='post', value=0)\n",
    "\n",
    "# Check sample sequence\n",
    "print('Sample sequence:', sequences[-1])\n",
    "print('\\n')\n",
    "print('Sample sequence:', pad_seq[-1])\n",
    "print('\\n')\n",
    "\n",
    "# Tokenize output labels\n",
    "lab_int = []\n",
    "for lab in y_labels:\n",
    "    lab_int.append([label_to_int[word] for word in lab.split()])\n",
    "\n",
    "# Pad input labels\n",
    "pad_labels = pad_sequences(sequences=lab_int, maxlen=max_seq_len, padding='post', value=0)\n",
    "encoded_labels = [to_categorical(i, num_classes=no_classes) for i in pad_labels]\n",
    "\n",
    "# Check sample label\n",
    "print('Sample label:', pad_labels[-1])\n",
    "print('\\n')\n",
    "print('Encoded label', encoded_labels[-1])\n",
    "\n",
    "# Check max seq length\n",
    "print(\"Maximum sequence length: {}\".format(max_seq_len))\n",
    "\n",
    "# Check that all sequences and labels are at max sequence length \n",
    "assert len(pad_seq)==len(seq_int)\n",
    "assert len(pad_seq[0])==max_seq_len\n",
    "\n",
    "assert len(pad_labels)==len(lab_int)\n",
    "assert len(pad_labels[0])==max_seq_len\n",
    "print('Sequence and labels length check passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Dataset: \t(190402, 128) 190402\n",
      "Testing Dataset: \t\t(47601, 128) 47601\n"
     ]
    }
   ],
   "source": [
    "# Split train and label dataset\n",
    "train_test_split_frac = 0.8\n",
    "split_index = int(0.8*len(pad_seq))\n",
    "\n",
    "# Split data into training, validation, and test data (features and labels, x and y)\n",
    "train_val_x, test_x = pad_seq[:split_index], pad_seq[split_index:]\n",
    "train_val_y, test_y = encoded_labels[:split_index], encoded_labels[split_index:]\n",
    "\n",
    "# print out the shapes of your resultant feature data\n",
    "print('Training/Validation Dataset: \\t{}'.format(train_val_x.shape), len(train_val_y))\n",
    "print('Testing Dataset: \\t\\t{}'.format(test_x.shape), len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and process Glove pretrained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 word vectors\n"
     ]
    }
   ],
   "source": [
    "# Load glove pre-trained vectors\n",
    "glove_index = dict()\n",
    "f = open('./data/embeddings/glove.6B.300d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    glove_index[word] = coefs\n",
    "f.close()\n",
    "print('{} word vectors'.format(len(glove_index)))\n",
    "\n",
    "embed_matrix = np.zeros((unique_vocab, embed_dim))\n",
    "for word, i in vocab_to_int.items():\n",
    "    embedding_vector = glove_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embed_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture\n",
    "\n",
    "The model consists of a few parts:\n",
    "\n",
    "1. Embedding Layer:  \n",
    "    * While it is possible to initialize and use a new empty embedding for the network to train and learn on, using a pre-trained embedding improves the model performance\n",
    "    *  Matrix of weights extracted from the Glove pre-trained word vectors based on the number of unique words in the dataset\n",
    "    \n",
    "    \n",
    "2. CNN Layers:\n",
    "    * For each sequence in the dataset, a convolution window of x (Where x is the kernel size) is applied, capturing the morphological and feature information of x words at a time\n",
    "    * 3 CNN layers each generating 128 filters with 3, 5 and 7 kernel sizes. \n",
    "    * Stride 1 is used and padding is applied (SAME) to keep the output length same as the input.\n",
    "    * Outputs from the CNN layers are then concatenated and reshaped\n",
    "    * They are then fed through a dense layer with ReLU activation to learn about their non-linear relationships \n",
    "\n",
    "\n",
    "3. BiLSTM Layer\n",
    "    * Outputs from dense layer are then fed into a BiLSTM layer to learn about the structure and dependencies of the sequences\n",
    "    *  A final Time Distributed dense layer is applied to make predictions on each word in the sequences\n",
    "    \n",
    "![Model Architecture](./images/model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm(max_seq_len, unique_vocab, embed_dim, embed_matrix, filter_sizes, kernels, kernel_weight, bias):\n",
    "    '''\n",
    "    Description: \n",
    "        - Constructs and compiles the CNN+BiLSTM model\n",
    "    \n",
    "    Args(They can be defined earlier at the top of the notebook):\n",
    "        - max_seq_len: Maximum sequence length \n",
    "        - unique_vocab: Number of unique words\n",
    "        - embed_dim: Embedding layer dimension, needs to match with that of Glove pre-trained\n",
    "        - embed_matrix: Pre-trained weights extracted from Glove based on unique words\n",
    "        - filter_sizes: Number of filters per CNN layer\n",
    "        - kernels: Kernel sizes per CNN layer\n",
    "        - kernel_weight: Weights initialization for CNN layers\n",
    "        - bias: Bias initialization for CNN layers\n",
    "        \n",
    "    Return: \n",
    "        - Compiled model\n",
    "    '''\n",
    "    embed_input = Input(shape=(max_seq_len,))\n",
    "\n",
    "    # Add embedding layer using weights from glove\n",
    "    embed = Embedding(input_dim=unique_vocab, output_dim=embed_dim, weights=[embed_matrix], \n",
    "                        input_length=max_seq_len, trainable=True)(embed_input) #104910 * 300\n",
    "    \n",
    "    embed = Dropout(rate=drop_prob)(embed)\n",
    "\n",
    "    cnn_outputs = []\n",
    "    for i in range(len(filter_sizes)):\n",
    "        # Add conv1d layer\n",
    "        out_i = Conv1D(filters=filter_sizes[i], kernel_initializer=kernel_weight, bias_initializer=bias, \n",
    "                          kernel_size=kernels[i], kernel_regularizer=None, activation='relu', \n",
    "                          padding='SAME', strides=1)(embed)\n",
    "#         out_i = BatchNormalization()(out_i)\n",
    "        cnn_outputs.append(out_i)\n",
    "\n",
    "    cnn_outputs = concatenate(cnn_outputs, axis=-1)\n",
    "    cnn_outputs = Dropout(rate=drop_prob)(cnn_outputs)\n",
    "    cnn_outputs = Reshape((-1, np.sum(filter_sizes)))(cnn_outputs)\n",
    "    \n",
    "    dense = Dense(lstm_hidden, activation='relu')(cnn_outputs)\n",
    "    dense = Dropout(rate=drop_prob)(dense)\n",
    "    \n",
    "    blstm_outputs = Bidirectional(LSTM(lstm_hidden_2, return_sequences=True))(dense)\n",
    "    \n",
    "    blstm_outputs = Dropout(rate=drop_prob)(blstm_outputs)\n",
    "    \n",
    "    output = TimeDistributed(Dense(no_classes, activation='softmax'))(blstm_outputs)\n",
    "\n",
    "    model = Model(inputs=[embed_input], outputs=[output])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(adam_lr), \n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 128, 300)     31473000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 128, 16)      14416       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 128, 16)      24016       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 128, 16)      33616       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 128, 16)      43216       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 16)      64          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 16)      64          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 16)      64          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 16)      64          conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 64)      0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 64)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 128, 64)      0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 1024)    66560       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128, 1024)    0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 128, 2048)    16785408    dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128, 2048)    0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 128, 7)       14343       dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 48,454,831\n",
      "Trainable params: 48,454,703\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n",
      "Train on 133281 samples, validate on 57121 samples\n",
      "Epoch 1/50\n",
      "133281/133281 [==============================] - 1314s 10ms/step - loss: 0.0375 - acc: 0.9877 - val_loss: 0.0309 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03086, saving model to ./cnn_lstm_model.h5\n",
      "Epoch 2/50\n",
      "133281/133281 [==============================] - 1314s 10ms/step - loss: 0.0279 - acc: 0.9903 - val_loss: 0.0278 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03086 to 0.02778, saving model to ./cnn_lstm_model.h5\n",
      "Epoch 3/50\n",
      "133281/133281 [==============================] - 1310s 10ms/step - loss: 0.0251 - acc: 0.9912 - val_loss: 0.0263 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02778 to 0.02635, saving model to ./cnn_lstm_model.h5\n",
      "Epoch 4/50\n",
      "133281/133281 [==============================] - 1309s 10ms/step - loss: 0.0233 - acc: 0.9918 - val_loss: 0.0258 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02635 to 0.02576, saving model to ./cnn_lstm_model.h5\n",
      "Epoch 5/50\n",
      "133281/133281 [==============================] - 1309s 10ms/step - loss: 0.0220 - acc: 0.9922 - val_loss: 0.0255 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02576 to 0.02551, saving model to ./cnn_lstm_model.h5\n",
      "Epoch 6/50\n",
      "133281/133281 [==============================] - 1305s 10ms/step - loss: 0.0210 - acc: 0.9925 - val_loss: 0.0252 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02551 to 0.02516, saving model to ./cnn_lstm_model.h5\n",
      "Epoch 7/50\n",
      "133281/133281 [==============================] - 1307s 10ms/step - loss: 0.0201 - acc: 0.9928 - val_loss: 0.0248 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02516 to 0.02481, saving model to ./cnn_lstm_model.h5\n",
      "Epoch 8/50\n",
      "133281/133281 [==============================] - 1307s 10ms/step - loss: 0.0194 - acc: 0.9930 - val_loss: 0.0252 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02481\n",
      "Epoch 9/50\n",
      "133281/133281 [==============================] - 1306s 10ms/step - loss: 0.0186 - acc: 0.9933 - val_loss: 0.0249 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02481\n",
      "Epoch 10/50\n",
      "133281/133281 [==============================] - 1309s 10ms/step - loss: 0.0180 - acc: 0.9935 - val_loss: 0.0251 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02481\n",
      "Epoch 11/50\n",
      "133281/133281 [==============================] - 1308s 10ms/step - loss: 0.0174 - acc: 0.9937 - val_loss: 0.0251 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02481\n",
      "Epoch 12/50\n",
      "133281/133281 [==============================] - 1306s 10ms/step - loss: 0.0168 - acc: 0.9939 - val_loss: 0.0254 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02481\n",
      "Epoch 00012: early stopping\n",
      "Time taken: 15726.777758598328 seconds\n"
     ]
    }
   ],
   "source": [
    "# Model code\n",
    "model = cnn_lstm(max_seq_len=max_seq_len, unique_vocab=unique_vocab, embed_dim=embed_dim,\n",
    "                embed_matrix=embed_matrix, filter_sizes=filter_sizes, kernels=kernels,\n",
    "                 kernel_weight=kernel_weight, bias=bias)\n",
    "\n",
    "# Summarize model\n",
    "model.summary()\n",
    "\n",
    "# Fit, train and evaluate model\n",
    "start = time.time()\n",
    "model.fit(x=train_val_x, y=np.array(train_val_y), batch_size=batch_size, \n",
    "          epochs=epochs, validation_split=valid_split, steps_per_epoch=None, validation_steps=None,\n",
    "          shuffle=True, verbose=1, callbacks=[tensor_b, early_s, chkpt])\n",
    "print('Time taken: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model architecture and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete previous model and load model with best results\n",
    "del model\n",
    "model = load_model('./cnn_lstm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a sample test data, make a prediction from it and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions Index:\n",
      "[array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3,\n",
      "       3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)]\n",
      "\n",
      "\n",
      "Prediction sequence:\n",
      "this is where the robots and models that ive presented today will hopefully play a key role towards these very important goalsthank you bruno giussani auke ive seen in your lab other robots that do things like swim in pollution and measure the pollution while they swim <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "\n",
      "Prediction output:\n",
      "<na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <period> <period> <na> <na> <comma> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <period> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "\n",
      "Combined prediction:\n",
      "This is where the robots and models that I've presented today will hopefully play a key role towards these very important goalsthank. you. bruno giussani auke, I've seen in your lab other robots that do things like swim in pollution and measure the pollution while they swim.                                                                                 \n"
     ]
    }
   ],
   "source": [
    "# Load a sample of test data\n",
    "test_data = test_x[11111]\n",
    "\n",
    "# Restore tokenized test data back to normal sentence\n",
    "pred_x_seq = []\n",
    "for x in test_data:\n",
    "    for value, index in vocab_to_int.items():\n",
    "        if x == index:\n",
    "            pred_x_seq.append(value)\n",
    "\n",
    "# Get predicted output of test data (Make predictions)\n",
    "pred_expand = model.predict(np.expand_dims(test_data, axis=0))\n",
    "\n",
    "# Retrieve position of highest probability from predictions\n",
    "pred_y = []\n",
    "for y in pred_expand:\n",
    "    pred_y.append(np.argmax(y, axis=1))\n",
    "print('Predictions Index:')\n",
    "print(pred_y)\n",
    "\n",
    "# Restore tokenized labels\n",
    "pred_y_seq = []\n",
    "for x in pred_y:\n",
    "    for y in x:\n",
    "        for value, index in label_to_int.items():\n",
    "            if y == index:\n",
    "                pred_y_seq.append(value)\n",
    "\n",
    "# Restore punctuations and capitalization                \n",
    "combined = []\n",
    "for i in range(len(pred_x_seq)):\n",
    "    if pred_y_seq[i] == '<comma>':\n",
    "        combined.append(str(pred_x_seq[i])+',')\n",
    "    elif pred_y_seq[i] == '<period>':\n",
    "        combined.append(str(pred_x_seq[i])+'.')\n",
    "    elif pred_y_seq[i] == '<question>':\n",
    "        combined.append(str(pred_x_seq[i])+'?')\n",
    "    elif pred_y_seq[i] == '<exclaim>':\n",
    "        combined.append(str(pred_x_seq[i])+'!')\n",
    "    elif pred_y_seq[i] == '<3-dots>':\n",
    "        combined.append(str(pred_x_seq[i])+'...')\n",
    "    else:\n",
    "        combined.append(str(pred_x_seq[i]))\n",
    "\n",
    "for i in range(len(combined)):\n",
    "    if '.' in combined[i]:\n",
    "        combined[i+1] = combined[i+1].capitalize()\n",
    "    elif combined[i] == 'i':\n",
    "        combined[i] = combined[i].capitalize()\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Join predicted words back into a sequence\n",
    "combined = ' '.join(combined)\n",
    "combined = combined.replace('<pad>', '')\n",
    "\n",
    "print('\\n')\n",
    "print('Prediction sequence:')            \n",
    "print(' '.join(pred_x_seq))\n",
    "print('\\n')\n",
    "print('Prediction output:')\n",
    "print(' '.join(pred_y_seq))\n",
    "print('\\n')\n",
    "print('Combined prediction:')\n",
    "print(combined.capitalize().replace('ive', \"I've\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "Barring the first 2 classes (Pad and NA) which are not our targets, the below can be observed from the Classifcation Report and Confusion Matrix:\n",
    "\n",
    "* Model performs decently on predicting Commas, Periods and Question Marks achieving 61%, 89% and, 63% F1-Score respectively\n",
    "* Predictions for Exclaimation Marks and 3 Consecutive Dots performed the worst at 7% and 9% F1-Score respectively\n",
    "* The difference in performance could be attributed to class imbalance where the model has not seen enough examples to make more accurate predictions\n",
    "\n",
    "Ted Talks vs MGE\n",
    "<tr>\n",
    "    <td> <img src=\"./images/ted2.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "    <td> <img src=\"./images/mge.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr>\n",
    "| ![Ted](./images/ted2.png \"Ted talks\") | ![MGE](./images/mge.png \"MGE\") |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Confusion Matrix and Classification Report to check model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4931222       0       0       0       0       0       9]\n",
      " [    298  992651   18533    2620     672     131       0]\n",
      " [      9   30129   43875    1278     749      49       0]\n",
      " [    305    4617    4531   54377     252      57       0]\n",
      " [      7    1208     718     263    3319       7       0]\n",
      " [      4     209     236      75      12      30       0]\n",
      " [    334      67      16      33       1       1      24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   4931231\n",
      "           1       0.96      0.98      0.97   1014905\n",
      "           2       0.65      0.58      0.61     76089\n",
      "           3       0.93      0.85      0.89     64139\n",
      "           4       0.66      0.60      0.63      5522\n",
      "           5       0.11      0.05      0.07       566\n",
      "           6       0.73      0.05      0.09       476\n",
      "\n",
      "   micro avg       0.99      0.99      0.99   6092928\n",
      "   macro avg       0.72      0.59      0.61   6092928\n",
      "weighted avg       0.99      0.99      0.99   6092928\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[9.99998175e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.82510209e-06]\n",
      " [2.93623541e-04 9.78072825e-01 1.82608224e-02 2.58152241e-03\n",
      "  6.62130938e-04 1.29076120e-04 0.00000000e+00]\n",
      " [1.18282538e-04 3.95970508e-01 5.76627371e-01 1.67961203e-02\n",
      "  9.84373563e-03 6.43982704e-04 0.00000000e+00]\n",
      " [4.75529709e-03 7.19842841e-02 7.06434463e-02 8.47799311e-01\n",
      "  3.92896678e-03 8.88694866e-04 0.00000000e+00]\n",
      " [1.26765665e-03 2.18761318e-01 1.30025353e-01 4.76276711e-02\n",
      "  6.01050344e-01 1.26765665e-03 0.00000000e+00]\n",
      " [7.06713781e-03 3.69257951e-01 4.16961131e-01 1.32508834e-01\n",
      "  2.12014134e-02 5.30035336e-02 0.00000000e+00]\n",
      " [7.01680672e-01 1.40756303e-01 3.36134454e-02 6.93277311e-02\n",
      "  2.10084034e-03 2.10084034e-03 5.04201681e-02]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create confusion matrix and classification report\n",
    "for_report = model.predict(test_x)\n",
    "out_pred = [np.argmax(x, axis=1) for x in for_report]\n",
    "out_pred = np.concatenate(out_pred, axis=0)\n",
    "\n",
    "y_ = [np.argmax(x, axis=1) for x in test_y]\n",
    "y_ = np.concatenate(y_, axis=0)\n",
    "\n",
    "cm = confusion_matrix(y_true=y_, y_pred=out_pred)\n",
    "print(cm)\n",
    "\n",
    "cr = classification_report(y_true=y_, y_pred=out_pred)\n",
    "print(cr)\n",
    "\n",
    "overall = classification_report(y_true=y_, y_pred=out_pred, output_dict=True)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=class_names, normalize=True, title='Normalized Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the average Precision, Recall and, F1-Score of different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comma, Period, Question Precision:\t0.745\n",
      "Comma, Period, Question Recall:\t\t0.675\n",
      "Comma, Period, Question F1-Score:\t0.709\n",
      "\n",
      "\n",
      "Overall Precision:\t0.615\n",
      "Overall Recall:\t\t0.426\n",
      "Overall F1-Score:\t0.458\n"
     ]
    }
   ],
   "source": [
    "# comma, period, question, exclaim, 3-dots\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "for i in range(2, 7):\n",
    "    precision.append(overall[str(i)]['precision'])\n",
    "    recall.append(overall[str(i)]['recall'])\n",
    "    f1.append(overall[str(i)]['f1-score'])\n",
    "\n",
    "print('Comma, Period, Question Precision:\\t{:.3f}'.format(np.average(precision[:3])))\n",
    "print('Comma, Period, Question Recall:\\t\\t{:.3f}'.format(np.average(recall[:3])))\n",
    "print('Comma, Period, Question F1-Score:\\t{:.3f}'.format(np.average(f1[:3])))\n",
    "print('\\n')\n",
    "\n",
    "print('Overall Precision:\\t{:.3f}'.format(np.average(precision)))\n",
    "print('Overall Recall:\\t\\t{:.3f}'.format(np.average(recall)))\n",
    "print('Overall F1-Score:\\t{:.3f}'.format(np.average(f1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
