{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import random, torch, numpy as np\n",
    "from random import randint\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(w, h, f, p, s):\n",
    "    '''\n",
    "    Args:\n",
    "        w: Width of input\n",
    "        h: Height of input\n",
    "        f: Kernel width/height\n",
    "        p: Padding\n",
    "        s: Stride\n",
    "    '''\n",
    "    w = ((w-f+2*p)/s)+1\n",
    "    h = ((h-f+2*p)/s)+1\n",
    "    return ('Conv Shape:', [w, h])\n",
    "\n",
    "def get_seq_words(seq):\n",
    "    return seq.split()\n",
    "\n",
    "def get_max_len(doc):\n",
    "    max_len = 0\n",
    "    for x in doc:\n",
    "        if len(x) > max_len:\n",
    "            max_len = len(x)\n",
    "    return max_len\n",
    "\n",
    "def chunk_seq(seq):\n",
    "    chunked_seq = []\n",
    "    for i in range(0, len(seq), 5):\n",
    "        chunked_seq.append(seq[i:i+5])\n",
    "    return chunked_seq\n",
    "\n",
    "def get_label(seq):\n",
    "    labels = []\n",
    "    seq = seq.split()\n",
    "    if len(seq) < 5:\n",
    "        pass\n",
    "    else:\n",
    "        for word in seq:\n",
    "            if ',' in word:\n",
    "                labels.append(1)\n",
    "            elif '.' in word:\n",
    "                labels.append(2)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "        return labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28218860"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('./data/processed/ted_data', 'r', encoding='utf-8').read()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good morni\n"
     ]
    }
   ],
   "source": [
    "data = data.lower()\n",
    "data_split = data.split('\\n')\n",
    "all_data = ' '.join(data_split)\n",
    "print(all_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'morning.',\n",
       " 'how',\n",
       " 'are',\n",
       " \"you?(laughter)it's\",\n",
       " 'been',\n",
       " 'great,',\n",
       " \"hasn't\",\n",
       " 'it?',\n",
       " \"i've\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = all_data.split()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = chunk_seq(words)\n",
    "sequences = [' '.join(seq) for seq in x]\n",
    "\n",
    "with open('processed_data', 'w', encoding='utf-8') as f:\n",
    "    for seq in sequences:\n",
    "        f.write(seq+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for seq in sequences:\n",
    "    seq = seq.split()\n",
    "    if ',' in seq[2]:\n",
    "        labels.append('<comma>')\n",
    "    elif '.' in seq[2]:\n",
    "        labels.append('<period>')\n",
    "    else:\n",
    "        labels.append('<na>')\n",
    "        \n",
    "with open('labels', 'w', encoding='utf-8') as f:\n",
    "    for label in labels:\n",
    "        f.write(label+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: \t1006181\n",
      "Number of labels: \t1006181\n"
     ]
    }
   ],
   "source": [
    "# Check number of sequences and labels\n",
    "print('Number of sequences: \\t{}'.format(len(sequences)))\n",
    "print('Number of labels: \\t{}'.format(len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'<na>': 877643, '<period>': 57696, '<comma>': 70842})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label for label in labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocab, \n",
    "words_in_vocab = Counter(words)\n",
    "vocab = sorted(words_in_vocab, key=words_in_vocab.get, reverse=True)\n",
    "\n",
    "# Skip most common word\n",
    "vocab_to_int = {word: index for index, word in enumerate(vocab, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tokenize sequences\n",
    "seq_int = []\n",
    "for seq in sequences:\n",
    "    seq_int.append([vocab_to_int[word] for word in seq.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 181375\n",
      "Check tokenized sequences: \n",
      " [[136, 3505, 51, 16, 75870], [80, 2023, 1890, 684, 151], [80, 5526, 324, 47, 1], [219, 571, 7, 232, 71], [75871, 18, 80, 153, 8970]]\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique words: {}'.format(len(vocab_to_int)))\n",
    "print('Check tokenized sequences: \\n', seq_int[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 0 0 0 0 0 0 2 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Encode labels\n",
    "encoded_labels = []\n",
    "for label in labels:\n",
    "    if label == '<comma>':\n",
    "        encoded_labels.append(1)\n",
    "    elif label == '<period>':\n",
    "        encoded_labels.append(2)\n",
    "    else:\n",
    "        encoded_labels.append(0)\n",
    "encoded_labels = np.array(encoded_labels)\n",
    "print(encoded_labels[20:36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 0\n",
      "Maximum review length: 5\n",
      "Sequence lengths:  Counter({5: 1006180, 3: 1})\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers\n",
    "seq_len = Counter([len(seq) for seq in seq_int])\n",
    "print(\"Zero-length reviews: {}\".format(seq_len[0]))\n",
    "print(\"Maximum review length: {}\".format(max(seq_len)))\n",
    "\n",
    "# One sequence with length 3\n",
    "print('Sequence lengths: ', seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to 5 or sequence length, post padding\n",
    "features = np.zeros((len(seq_int), 5), dtype=int)\n",
    "\n",
    "for i, row in enumerate(seq_int):\n",
    "    features[i, :len(row)] = np.array(row)[:5]\n",
    "\n",
    "# Check that all sequences at at length 5\n",
    "assert len(features)==len(seq_int)\n",
    "assert len(features[0])==5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   169 181375  14894      0      0]\n"
     ]
    }
   ],
   "source": [
    "print(features[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation/Test amount: \t100618\n",
      "Training Dataset: \t(804944, 5) (804944,)\n",
      "Validation Dataset: \t(100618, 5) (100618,)\n",
      "Testing Dataset: \t(100619, 5) (100619,)\n"
     ]
    }
   ],
   "source": [
    "train_test_split_frac = 0.8\n",
    "split_index = int(0.8*len(features))\n",
    "\n",
    "# Split data into training, validation, and test data (features and labels, x and y)\n",
    "train_x, left_over_x = features[:split_index], features[split_index:]\n",
    "train_y, left_over_y = encoded_labels[:split_index], encoded_labels[split_index:]\n",
    "\n",
    "val_test_index = int(0.5*len(left_over_x))\n",
    "print('Validation/Test amount: \\t{}'.format(val_test_index))\n",
    "\n",
    "val_x, test_x = left_over_x[:val_test_index], left_over_x[val_test_index:]\n",
    "val_y, test_y = left_over_y[:val_test_index], left_over_y[val_test_index:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print('Training Dataset: \\t{}'.format(train_x.shape), train_y.shape)\n",
    "print('Validation Dataset: \\t{}'.format(val_x.shape), val_y.shape)\n",
    "print('Testing Dataset: \\t{}'.format(test_x.shape), test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "batch_size = 128\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "val_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([128, 5])\n",
      "Sample input: \n",
      " tensor([[ 68155,      4,    119,  11340,    119],\n",
      "        [ 39571,   1082,     17,  18749,      9],\n",
      "        [     5,    255,     40,   1738,      2],\n",
      "        [    20,     19,     26,    100,     28],\n",
      "        [   456,      1,    831,      4,    262],\n",
      "        [    30,  72078,    292,   2207,      2],\n",
      "        [   263,      5,    122,      4,    513],\n",
      "        [    28,    173,      3,     67,    366],\n",
      "        [     2,    789,    140,      7,      5],\n",
      "        [    10,     78,    142,     44,   8057],\n",
      "        [     1,  24395,      4,      1,  86044],\n",
      "        [   125,      1,    658,   1947,     24],\n",
      "        [    57,     32,  16102,      8,   3892],\n",
      "        [   165,   1532,     27,    308,      8],\n",
      "        [113416,     23,      8,     26,    415],\n",
      "        [   656,  22408,      2,     73,   6295],\n",
      "        [    77,    189,   1671,  10089,     36],\n",
      "        [    39,     12,     23,     92,      6],\n",
      "        [    73,   1187,      1,   6299,     12],\n",
      "        [     7,    381,      9,   1651,    314],\n",
      "        [   104,      7,      1,  69493,      2],\n",
      "        [   106,   1919,    171,  14360,     46],\n",
      "        [    38,    377,    135,      8,    569],\n",
      "        [     2,     11,     79,     27,    156],\n",
      "        [   302,      7,      1,    544,      5],\n",
      "        [     3,   6401,    348,     60,     38],\n",
      "        [     1,    101,   2607,  23307,      1],\n",
      "        [   158,      3,      1,   4115,      2],\n",
      "        [   483,     46,     10,     53,      5],\n",
      "        [ 11662,     29,     43,     29,  16448],\n",
      "        [     3,   2103,     20,    112,      4],\n",
      "        [   106,     67,     54,   1466,      7],\n",
      "        [     3,    303,     27,   1095,    135],\n",
      "        [   117,    102,   1162,     27,    771],\n",
      "        [ 49342,     29,      5,    167,  71834],\n",
      "        [     3,     28,   7230,    127,     23],\n",
      "        [    10,    165,    161,      1,    133],\n",
      "        [   161,     48,    166,   2212,  27025],\n",
      "        [     2,     11,     79,    135,     19],\n",
      "        [  1265,     27,    682, 115410,    112],\n",
      "        [   936,    240,  21580,    119,   1178],\n",
      "        [     2,     54,     42,     16,    132],\n",
      "        [ 16292,  48618,      2,    278,   4060],\n",
      "        [     9,     41,   1101,  31167,    696],\n",
      "        [    55,   9549,      2, 154897,     34],\n",
      "        [    91,    695,  45519,     46,     10],\n",
      "        [   456,    220,     21,     56,    270],\n",
      "        [    21,      5,   6759,     40,    196],\n",
      "        [   580,      6,    259,     36,  18483],\n",
      "        [  4440,     13,     14,   2023,      2],\n",
      "        [  3941,     16,      6,     11,     76],\n",
      "        [   189,    216,      4,    241,   8542],\n",
      "        [  1366,      1,  24513,      4,      1],\n",
      "        [     2,      8,     18,   1763,    261],\n",
      "        [   167,    525,    110,     23,      2],\n",
      "        [ 85196,      7,    118,   2222,      1],\n",
      "        [  1360,     17,     15,    185,      1],\n",
      "        [    29,      1,    120,      4,  86743],\n",
      "        [    14,    144,  80566,      2,      8],\n",
      "        [     4,     55,   1274,     33,      4],\n",
      "        [     7,    232,     34,     11,     67],\n",
      "        [    61,    510,     22,     87,    433],\n",
      "        [   489,    148,      1,   1317,   9180],\n",
      "        [  1317,     56,   2680,   1375,      2],\n",
      "        [     2,  11045,    339,  12649,      1],\n",
      "        [    12,     38,    689,   1174,      2],\n",
      "        [  6385,     20,     50,     16,    100],\n",
      "        [    48,   5907,      1,  27302,   7565],\n",
      "        [   335,    541,    802,     16,  61576],\n",
      "        [    21,      5,    193,    342,      4],\n",
      "        [   306,     95,   2182,    484,     30],\n",
      "        [   480,      4,    308,      1,  30677],\n",
      "        [    46,     11,     16,     23,     11],\n",
      "        [   414,      2,      1,    257,      4],\n",
      "        [    89,    393,    171,      4,    236],\n",
      "        [     8,    470,    248,      5,   3611],\n",
      "        [  4811,      7,   8985,    199,      8],\n",
      "        [    34,    109,      5,   1511,     56],\n",
      "        [    19,    124,   3689,  28627,   1448],\n",
      "        [    62,      9,     38,      4,      1],\n",
      "        [   962,     29,      5,    120,      4],\n",
      "        [     1,  10775,     16,   5702,     61],\n",
      "        [   195,    411,      6,     97,    375],\n",
      "        [    33,      4,      1,    752,     61],\n",
      "        [   328,    568,      8,     14,     50],\n",
      "        [     7,   7105, 152500,     13,     14],\n",
      "        [     2,     13,    189,      6,   1027],\n",
      "        [    14,      1,    338,     43,    797],\n",
      "        [     5,    381,   2465,      2,     60],\n",
      "        [   137,     22,     12,   2888,      2],\n",
      "        [   103,  18718,     73,   5053,  59076],\n",
      "        [  2323,   2751,    136,     93,   2101],\n",
      "        [   134,   4675,     30,   3128,     25],\n",
      "        [     9,      5,     66,   6563,    875],\n",
      "        [    41,   4245,     15,  14992,     10],\n",
      "        [    28,   1236,      3,   1464,      7],\n",
      "        [     5,   1251,     17,   2672,     10],\n",
      "        [   628,   2077,    339,      2,      8],\n",
      "        [    72,     64,  12584,     11,     43],\n",
      "        [  6867,     21,   2940,     60,    263],\n",
      "        [    13,     40,     25,     33,     52],\n",
      "        [    13,     14, 111856,      1,    973],\n",
      "        [     1,    588,      4,   1400,  20567],\n",
      "        [   206, 120395,     62,      9,    694],\n",
      "        [    39,  84409,   5561,     23,     10],\n",
      "        [    98,   1264,     21,     91,     98],\n",
      "        [     1,     94,     38,     71,     52],\n",
      "        [   430,      7,   4541,   2128,     17],\n",
      "        [     5,    117,     77,      1,   5130],\n",
      "        [   569,     17,    116,    108,  19003],\n",
      "        [     1,  72027,     21,      1, 144247],\n",
      "        [ 17562,    928,    465,    367,     13],\n",
      "        [   730, 105604,    223,   1794,   5634],\n",
      "        [  5244,  17112,     29,      5,  16021],\n",
      "        [    70,     38,   2121,    628,     89],\n",
      "        [119996,     51,     27,   3309,     87],\n",
      "        [    10,    102,      5,     49,    136],\n",
      "        [     1,   2916,      4,   9596,     60],\n",
      "        [    46,     13,    426,     58,      6],\n",
      "        [  1145,     60,      1,   3319,     91],\n",
      "        [     7,    412,      3,    213,    281],\n",
      "        [    12,    544,   4135,    141,    212],\n",
      "        [   179,   3407,   2612,   1962,      3],\n",
      "        [   319,     97,     91, 144606,  18081],\n",
      "        [     1,   3516,      4,      1,   3385],\n",
      "        [    25,     52,     54,     15,  13258],\n",
      "        [  7798,    374,     54,    378,     36],\n",
      "        [   683,   1067,   2132,   6555,    417]], dtype=torch.int32)\n",
      "\n",
      "Sample label size:  torch.Size([128])\n",
      "Sample label: \n",
      " tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device to train on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device to train on:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Embedding Layer\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)        \n",
    "        \n",
    "        # Convolution and Maxpool Layers\n",
    "        # Sees 181376 * 64 * 1 = 2902016\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=50, kernel_size=(3,embedding_dim), stride=1, padding=0)\n",
    "        # See 90688 * 32 * 16 = 46432256\n",
    "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=50, kernel_size=(3,embedding_dim), stride=1, padding=0)\n",
    "#         # 45344 * 64 * 64 = 742916096\n",
    "#         self.conv3 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        # Dropout Layer\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "        # 2048 > 256\n",
    "        # Fully connected and output Layers\n",
    "        self.full_1 = nn.Linear(1, 3)\n",
    "#         self.output = nn.Linear(128, output_size)                \n",
    "\n",
    "    def forward(self, x):\n",
    "        print('x shape:',x.shape)\n",
    "        x = self.embedding(x)\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(self.dropout(F.relu(self.conv1(x))))\n",
    "        print('Conv_1:', x.shape)\n",
    "        x = self.pool(self.dropout(F.relu(self.conv2(x))))\n",
    "        print('Conv_2:', x.shape)\n",
    "        x = self.pool(self.dropout(F.relu(self.conv3(x))))\n",
    "        print('Conv_3:', x.shape)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.dropout(F.relu(self.full_1(x)))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embedding): Embedding(181376, 64)\n",
      "  (conv1): Conv2d(1, 50, kernel_size=(3, 64), stride=(1, 1))\n",
      "  (conv2): Conv2d(1, 50, kernel_size=(3, 64), stride=(1, 1))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.2)\n",
      "  (full_1): Linear(in_features=1, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize CNN\n",
    "vocab_size = len(vocab_to_int)+1\n",
    "output_size = 3\n",
    "embedding_dim = 64\n",
    "\n",
    "model = Net(vocab_size, output_size, embedding_dim)\n",
    "print(model)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([128, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got CUDAIntTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-fe411a13b20b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;31m# calculate the batch loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-2d78f603f600>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x shape:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;31m# add sequence of convolutional and max pooling layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    108\u001b[0m         return F.embedding(\n\u001b[0;32m    109\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got CUDAIntTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 8 # you may increase this number to train a final model\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.to(device), target.to(device)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.to(device), target.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
