{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras, string, itertools, random, datetime, numpy as np, matplotlib.pyplot as plt, tensorflow as tf\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Embedding, Conv1D, Flatten, Dense, Dropout, MaxPool1D, LSTM, \\\n",
    "Bidirectional, TimeDistributed, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom functions\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    '''\n",
    "    Description: Prints and plots the confusion matrix.\tNormalization can be applied by setting `normalize=True`\n",
    "\n",
    "    Args:\n",
    "    - cm: Confusion Matrix\n",
    "    - classes: Names of classes\n",
    "    - normalize: Whether to or to not normal values in Confusion Matrix\n",
    "    - cmap: Plot color\n",
    "    '''\n",
    "\n",
    "    # Check if normalize is true or false\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    # Format axis and plot Confusion Matrix\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "def chunk_seq(words, chunk_len):\n",
    "    '''\n",
    "    Description: Creates sequence of words of length equals to chunk_len\n",
    "\n",
    "    Args:\n",
    "    - words: Words in dataset\n",
    "    - chunk_len: Breaks sequence into provided length\n",
    "    \n",
    "    Returns:\n",
    "        Chunked dataset\n",
    "    '''\n",
    "    \n",
    "    chunked_seq = []\n",
    "    for i in range(0, len(words), chunk_len):\n",
    "        chunked_seq.append(words[i:i+chunk_len])\n",
    "    return chunked_seq\n",
    "\n",
    "def get_labels(seq):\n",
    "    labels_seq = []\n",
    "    seq = seq.split()\n",
    "    for i in range(len(seq)):\n",
    "        if ',' in seq[i]:\n",
    "            labels_seq.append('<comma>')\n",
    "        elif '.' in seq[i]:\n",
    "            labels_seq.append('<period>')\n",
    "        else:\n",
    "            labels_seq.append('<na>')\n",
    "    return labels_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "name_1 = 'lstm'\n",
    "name_2 = 'cnn-lstm'\n",
    "model_name = name_2\n",
    "max_seq_len = 128\n",
    "drop_prob = 0.2\n",
    "no_filters_1 = 32\n",
    "no_filters_2 = 64\n",
    "no_filters_3 = 32\n",
    "kernel_1 = 3\n",
    "kernel_2 = 5\n",
    "kernel_3 = 7\n",
    "lstm_hidden = 100\n",
    "embed_dim = 300\n",
    "adam_lr = 0.001\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "valid_split = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set misc parameters\n",
    "current = datetime.datetime.now()\n",
    "date = current.strftime('%b-%d')\n",
    "tensor_b = TensorBoard(log_dir='./tf_logs/model_{}_hidden_{}_dropout_{}_embed_dim_{}_lr_{}'.format(model_name, \n",
    "                        lstm_hidden, drop_prob,\n",
    "                        embed_dim, adam_lr), \n",
    "                        batch_size=batch_size, \n",
    "                        write_graph=True, histogram_freq=0)\n",
    "early_s = EarlyStopping(monitor='val_loss')\n",
    "class_names = ['Pad', 'NA', 'Comma', 'Period']\n",
    "\n",
    "# Look-up table to remove punctuations from data\n",
    "table = str.maketrans('', '', punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(laughter) and this is more fun.so this last one is called \"the sunshine kid.\"thank you very much for listening.old man sunshine was proud of his sun,and it brightened his day to see his little boy run,not because of what he’d done, nor the problems overcome,but that despite that his disposition remained a sunny one.it hadn’t always been like this.there’d been times when he’d tried to hide his brightness,you see, every star hits periods of hardship,it takes a brighter light to inspire them through the darkness.if we go back to when he was born in a nebula,we know that he never was thought of as regular,because he had a flair about him,to say the midas touch is wrongbut all he went near seemed to turn a little bronze,yes this sun was loved by some more than others,it was a case of joseph and his dreamcoat and his brothersbecause standing out from the crowd had its pros and its cons,and jealousy created enemies in those he outshonesuch as the shadow people.now the shadow people didn’t like the sunshine kid,because he showed up the dark things the shadow people did,and when he shone he showed the places where the shadow people hid,so the shadow people had an evil plan to get rid of him,first up — they made fun of his sunspots,shooting his dreams from the sky, their words were gunshots,designed to remind him he wasn’t very cooland he didn’t fit in with any popular kids at school.they said his head was up in space and they would bring him down to earth,essentially he came from nothing and that is what he was worth,he’d never get to go to university to learn,only degrees he’d ever show would be the first degree burnsfrom those that came too close, they told him he was too bright,that’s why no one ever looked him in the eyes,his judgment became cloudedso did the sky, with evaporated tearsas the sun started to cry.because the sunshine kid was bright, with a warm personality,and inside he burned savagelyhurt by the words and curses of the shadowy folkwho spoke holes in his soul and left cavities,and as his heart hardened, his spark darkened,every time they called him names it cooled his flames,he thought they might like him if he kept his light dimbut they were busy telling lightning she had terrible aim,he couldn’t quite get to grips with what they said,so he let his light be eclipsed by what they said,he fell into a lone star state like texas,and felt like he’d been punched in his solar plexus.but that’s when little miss sunshine came alongsinging her favorite song about how we’re made to be strong,and you don’t have to be wrong to belong, just be true to who you are,because we are all stars at heart.little miss sunshine was hot stuff,the kind of girl when you looked at heryou forgot stuff,but for him, there was no forgetting her,the minute he saw her her image burned in his retina,she was out of this world, and she accepted him,something about this girl meant he knew whenever she was next to him,things weren’t as dark as they seemed, and he dared to dream,shadows were nowhere to be seen; when she was there he beamed,his eyes would light up in ways that can’t be faked,when she grinned her rays erased the razor-tipped words of hate,they gave each other nicknames, they were \"cool star\" and \"fun sun,\"and gradually the shadowy damage became undone,she was one in a septillion, and she was brilliant,could turn the coldest blooded reptilians vermillion,loved by billions, from chileans to brazilians,and taught the sunshine kid the meaning of resilience.she said: “all the darkness in the worldcannot put out the light from a single candleso how the hell can they handle your light?only you can choose to dim it, and the sky is the limit, so silence the critics by burning.”and if eyes are windows to the soul then she drew back the curtainsand let the sun shine through the hurting.in a universe of adversity these stars stuck together,and though days became nights the memories would last forever,whether the weatherman said it or not, it would be fine,'cause even behind the clouds the kid could still shine.yes, the sunshine kid was bright, with a warm personality,and inside he burned savagely,fueled by the fire inspired across galaxiesby the girl who showed him belief.thank you very much.(applause)twenty-five years ago, scientists at cern created the world wide web.\n",
      "Length of longest sentence 740\n",
      "Number of sequences: \t39304\n",
      "Number of labels: \t39304\n"
     ]
    }
   ],
   "source": [
    "# Load and process input/label data\n",
    "data = open('./data/processed/ted_data', 'r', encoding='utf-8').read()\n",
    "data = data.lower()\n",
    "data_split = data.split('\\n')\n",
    "all_data = ' '.join(data_split)\n",
    "longest_sent = max(data_split, key=len)\n",
    "print(longest_sent)\n",
    "print('Length of longest sentence', len(longest_sent.split()))\n",
    "words = all_data.split()\n",
    "\n",
    "# Chunk sequence\n",
    "x = chunk_seq(words, max_seq_len)\n",
    "sequences = [' '.join(seq) for seq in x]\n",
    "\n",
    "# Get sequence labels\n",
    "process_labels = [get_labels(seq) for seq in sequences]\n",
    "process_labels = [' '.join(seq) for seq in process_labels]\n",
    "\n",
    "# Remove punctuations\n",
    "sequences = [seq.translate(table) for seq in sequences]\n",
    "\n",
    "with open('./processed_input', 'w', encoding='utf-8') as f:\n",
    "    for x in sequences:\n",
    "        f.write(x+'\\n')\n",
    "\n",
    "with open('./processed_labels', 'w', encoding='utf-8') as f:\n",
    "    for x in process_labels:\n",
    "        f.write(x+'\\n')\n",
    "\n",
    "# Check number of sequences and labels\n",
    "print('Number of sequences: \\t{}'.format(len(sequences)))\n",
    "print('Number of labels: \\t{}'.format(len(process_labels)))\n",
    "\n",
    "y_labels = open('./processed_labels', 'r', encoding='utf-8').read()\n",
    "y_labels = y_labels.split('\\n')\n",
    "y_labels = y_labels[:-1]\n",
    "all_labels = ' '.join(y_labels)\n",
    "labels_tag = all_labels.split()\n",
    "\n",
    "split = int(0.8*len(all_labels))\n",
    "test_y_counts = all_labels[split:]\n",
    "test_y_counts_split = test_y_counts.split()\n",
    "counts = Counter(test_y_counts_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 108807\n",
      "Class distribution: Counter({'<na>': 4387594, '<comma>': 354651, '<period>': 288658})\n",
      "Number of unique labels: 4\n",
      "{'<na>': 1, '<comma>': 2, '<period>': 3, '-PAD-': 0}\n"
     ]
    }
   ],
   "source": [
    "# Build words vocab\n",
    "all_data = ' '.join(sequences)\n",
    "words = all_data.split()\n",
    "words_in_vocab = Counter(words)\n",
    "vocab = sorted(words_in_vocab, key=words_in_vocab.get, reverse=True)\n",
    "\n",
    "# Skip most common word\n",
    "vocab_to_int = {word: index for index, word in enumerate(vocab, 2)}\n",
    "vocab_to_int['-PAD-'] = 0  # The special value used for padding\n",
    "vocab_to_int['-OOV-'] = 1  # The special value used for OOVs\n",
    "unique_vocab = len(vocab_to_int)\n",
    "print('Number of unique words:', unique_vocab)\n",
    "\n",
    "# Build labels vocab\n",
    "labels_in_vocab = Counter(labels_tag)\n",
    "labels_vocab = sorted(labels_in_vocab, key=labels_in_vocab.get, reverse=True)\n",
    "label_to_int = {t: i for i, t in enumerate(labels_vocab, 1)}\n",
    "label_to_int['-PAD-'] = 0  # The special value used to padding\n",
    "\n",
    "# Check labels\n",
    "no_classes = len(label_to_int)\n",
    "print('Class distribution:', Counter(labels_in_vocab))\n",
    "print('Number of unique labels:', no_classes)\n",
    "print(label_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sequence: plans made with the game to actually build the real cityand these videos that i have shown you these are the people who are coming up with new kinds of solutions we know that cities are growing theyre getting bigger as we go and the percentage of population living in cities is projected to rise so we need the solutions and these people playing the game they are trying out different kinds of solutions they might have something that is really important so what we are seeing here is dream cities that might be real one day so it might be that this is not just a game it might be a way to decide our own fatethank youapplause\n",
      "Sample sequence: [ 2810   152    22     2   526     4    84   312     2   232 14963    47\n",
      "  1816     7     9    19   964    11    47    18     2    38    69    18\n",
      "   311    62    22   105   482     5  1134    12    58     7   550    18\n",
      "   663   125   264   829    30    12    95     3     2  2460     5   583\n",
      "   324     8   550    10  6551     4  1195    17    12   123     2  1134\n",
      "     3    47    38   739     2   526    20    18   235    53   135   482\n",
      "     5  1134    20   170    19   100     7    10    72   180    17    25\n",
      "    12    18   544    83    10   863   550     7   170    29   232    37\n",
      "   142    17    13   170    29     7    14    10    31    46     6   526\n",
      "    13   170    29     6    86     4  1221    42   160 94258  9729     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "Sample label: [1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 3\n",
      " 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 3\n",
      " 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 3 1 1 1\n",
      " 1 1 1 1 1 1 3 3 0 0 0 0 0 0 0 0 0]\n",
      "Encoded label [[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "Maximum sequence length: 128\n",
      "Sequence and labels length check passed!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize input sequences\n",
    "seq_int = []\n",
    "for seq in sequences:\n",
    "    seq_int.append([vocab_to_int[word] for word in seq.split()])\n",
    "\n",
    "# Pad input sequences\n",
    "pad_seq = pad_sequences(sequences=seq_int, maxlen=max_seq_len, padding='post', value=0)\n",
    "\n",
    "# Check sample sequence\n",
    "print('Sample sequence:', sequences[-1])\n",
    "print('\\n')\n",
    "print('Sample sequence:', pad_seq[-1])\n",
    "print('\\n')\n",
    "# Tokenize output labels\n",
    "lab_int = []\n",
    "for lab in y_labels:\n",
    "    lab_int.append([label_to_int[word] for word in lab.split()])\n",
    "\n",
    "# Pad input labels\n",
    "pad_labels = pad_sequences(sequences=lab_int, maxlen=max_seq_len, padding='post', value=0)\n",
    "encoded_labels = [to_categorical(i, num_classes=no_classes) for i in pad_labels]\n",
    "\n",
    "# Check sample label\n",
    "print('Sample label:', pad_labels[-1])\n",
    "print('\\n')\n",
    "print('Encoded label', encoded_labels[-1])\n",
    "print('\\n')\n",
    "# Check max seq length\n",
    "print(\"Maximum sequence length: {}\".format(max_seq_len))\n",
    "print('\\n')\n",
    "\n",
    "# Check that all sequences and labels are at max sequence length \n",
    "assert len(pad_seq)==len(seq_int)\n",
    "assert len(pad_seq[0])==max_seq_len\n",
    "\n",
    "assert len(pad_labels)==len(lab_int)\n",
    "assert len(pad_labels[0])==max_seq_len\n",
    "print('Sequence and labels length check passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all sequences and labels are at max sequence length \n",
    "assert len(pad_seq)==len(seq_int)\n",
    "assert len(pad_seq[0])==max_seq_len\n",
    "\n",
    "assert len(pad_labels)==len(lab_int)\n",
    "assert len(pad_labels[0])==max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Dataset: \t(31443, 128) 31443\n",
      "Testing Dataset: \t\t(7861, 128) 7861\n"
     ]
    }
   ],
   "source": [
    "# Split train and label dataset\n",
    "train_test_split_frac = 0.8\n",
    "split_index = int(0.8*len(pad_seq))\n",
    "\n",
    "# Split data into training, validation, and test data (features and labels, x and y)\n",
    "train_val_x, test_x = pad_seq[:split_index], pad_seq[split_index:]\n",
    "train_val_y, test_y = encoded_labels[:split_index], encoded_labels[split_index:]\n",
    "\n",
    "# print out the shapes of your resultant feature data\n",
    "print('Training/Validation Dataset: \\t{}'.format(train_val_x.shape), len(train_val_y))\n",
    "print('Testing Dataset: \\t\\t{}'.format(test_x.shape), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 128, 300)          32642100  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 128, 32)           28832     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 128, 64)           10304     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 128, 32)           14368     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128, 200)          106400    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128, 200)          240800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128, 200)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 128, 4)            804       \n",
      "=================================================================\n",
      "Total params: 33,043,608\n",
      "Trainable params: 33,043,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 22010 samples, validate on 9433 samples\n",
      "Epoch 1/10\n",
      "22010/22010 [==============================] - 131s 6ms/step - loss: 0.4727 - acc: 0.8677 - val_loss: 0.3018 - val_acc: 0.8839\n",
      "Epoch 2/10\n",
      "22010/22010 [==============================] - 368s 17ms/step - loss: 0.2927 - acc: 0.8898 - val_loss: 0.2794 - val_acc: 0.8937\n",
      "Epoch 3/10\n",
      "22010/22010 [==============================] - 496s 23ms/step - loss: 0.2646 - acc: 0.9005 - val_loss: 0.2786 - val_acc: 0.8950\n",
      "Epoch 4/10\n",
      "22010/22010 [==============================] - 515s 23ms/step - loss: 0.2443 - acc: 0.9098 - val_loss: 0.2694 - val_acc: 0.9003\n",
      "Epoch 5/10\n",
      "22010/22010 [==============================] - 429s 19ms/step - loss: 0.2264 - acc: 0.9175 - val_loss: 0.2683 - val_acc: 0.9017\n",
      "Epoch 6/10\n",
      "22010/22010 [==============================] - 480s 22ms/step - loss: 0.2122 - acc: 0.9233 - val_loss: 0.2709 - val_acc: 0.9008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7b7186b9b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model code\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=unique_vocab, output_dim=embed_dim, input_length=max_seq_len))\n",
    "model.add(Conv1D(filters=no_filters_1, kernel_size=kernel_1, padding='SAME', strides=1))\n",
    "model.add(Dropout(rate=drop_prob, seed=50))\n",
    "model.add(Conv1D(filters=no_filters_2, kernel_size=kernel_2, padding='SAME', strides=1))\n",
    "model.add(Dropout(rate=drop_prob, seed=50))\n",
    "model.add(Conv1D(filters=no_filters_3, kernel_size=kernel_3, padding='SAME', strides=1))\n",
    "model.add(Dropout(rate=drop_prob, seed=50))\n",
    "model.add(Bidirectional(LSTM(lstm_hidden, return_sequences=True)))\n",
    "model.add(Dropout(rate=drop_prob, seed=50))\n",
    "model.add(Bidirectional(LSTM(lstm_hidden, return_sequences=True)))\n",
    "model.add(Dropout(rate=drop_prob, seed=50))\n",
    "model.add(TimeDistributed(Dense(no_classes, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(adam_lr), \n",
    "              metrics=['accuracy'])#, ignore_class_accuracy(0)])\n",
    "model.summary()\n",
    "model.fit(x=train_val_x, y=np.array(train_val_y), batch_size=batch_size, \n",
    "          epochs=epochs, validation_split=valid_split, steps_per_epoch=None, validation_steps=None,\n",
    "          shuffle=True, verbose=1, callbacks=[tensor_b, early_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions Index:\n",
      "[array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1,\n",
      "       1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]\n",
      "\n",
      "\n",
      "Prediction sequence:\n",
      "if hed be interested in doing a photography project exploring this questionas and i was interested in the question but i was actually much more interested in staceys motivation for asking it particularly since id never known stacey to have a boyfriend so as part of this project i thought itd be interesting if she tried to meet someone so my idea was to have stacey here go speed dating in las vegas on valentines day laughter applause musicsb we ended up at what was advertised as the worlds largest speed dating event i had 19 dates and each date lasted three minutes participants were given a list of ice breaker questions to get the ball rolling things like if you could be any kind of animal what\n",
      "\n",
      "\n",
      "Prediction output:\n",
      "<na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <period> <na> <na> <na> <na> <na> <na> <comma> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <comma> <na> <na> <na> <na> <na> <na> <na> <na> <na> <period> <na> <na> <na> <na> <na> <comma> <na> <na> <na> <na> <comma> <na> <na> <na> <na> <na> <comma> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <period> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <period> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <period> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na>\n",
      "\n",
      "\n",
      "Combined prediction:\n",
      "if hed be interested in doing a photography project exploring this questionas. And I was interested in the question, but I was actually much more interested in staceys motivation for asking it, particularly since id never known stacey to have a boyfriend. So as part of this project, I thought itd be interesting, if she tried to meet someone, so my idea was to have stacey here go speed dating in las vegas on valentines day. Laughter applause musicsb we ended up at what was advertised as the worlds largest speed dating event. I had 19 dates and each date lasted three minutes participants. Were given a list of ice breaker questions to get the ball rolling things like if you could be any kind of animal what\n"
     ]
    }
   ],
   "source": [
    "test_data = test_x[56]\n",
    "pred_x_seq = []\n",
    "for x in test_data:\n",
    "    for value, index in vocab_to_int.items():\n",
    "        if x == index:\n",
    "            pred_x_seq.append(value)\n",
    "\n",
    "# Predicted output\n",
    "pred_expand = model.predict(np.expand_dims(test_data, axis=0))\n",
    "pred_y = []\n",
    "for y in pred_expand:\n",
    "    pred_y.append(np.argmax(y, axis=1))\n",
    "print('Predictions Index:')\n",
    "print(pred_y)\n",
    "\n",
    "pred_y_seq = []\n",
    "for x in pred_y:\n",
    "    for y in x:\n",
    "        for value, index in label_to_int.items():\n",
    "            if y == index:\n",
    "                pred_y_seq.append(value)\n",
    "\n",
    "combined = []\n",
    "for i in range(len(pred_x_seq)):\n",
    "    if pred_y_seq[i] == '<comma>':\n",
    "        combined.append(str(pred_x_seq[i])+',')\n",
    "    elif pred_y_seq[i] == '<period>':\n",
    "        combined.append(str(pred_x_seq[i])+'.')\n",
    "    else:\n",
    "        combined.append(str(pred_x_seq[i]))\n",
    "\n",
    "for i in range(len(combined)):\n",
    "    if '.' in combined[i]:\n",
    "        combined[i+1] = combined[i+1].capitalize()\n",
    "    if combined[i] == 'i':\n",
    "        combined[i] = combined[i].capitalize()\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "combined = ' '.join(combined)\n",
    "combined\n",
    "\n",
    "print('\\n')\n",
    "print('Prediction sequence:')            \n",
    "print(' '.join(pred_x_seq))\n",
    "print('\\n')\n",
    "print('Prediction output:')\n",
    "print(' '.join(pred_y_seq))\n",
    "print('\\n')\n",
    "print('Combined prediction:')\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset distribution: Counter({'<na>': 884201, '<comma>': 68090, '<period>': 56544})\n",
      "[[     0      9      0      0]\n",
      " [     0 850826  18507  12544]\n",
      " [     0  30133  25071  12694]\n",
      " [     0  18078   9628  28718]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.95      0.96      0.96    881877\n",
      "           2       0.47      0.37      0.41     67898\n",
      "           3       0.53      0.51      0.52     56424\n",
      "\n",
      "   micro avg       0.90      0.90      0.90   1006208\n",
      "   macro avg       0.49      0.46      0.47   1006208\n",
      "weighted avg       0.89      0.90      0.89   1006208\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[0.         1.         0.         0.        ]\n",
      " [0.         0.96478987 0.02098592 0.01422421]\n",
      " [0.         0.44379805 0.36924504 0.18695691]\n",
      " [0.         0.32039558 0.17063661 0.50896782]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create confusion matrix and classification report\n",
    "for_report = model.predict(test_x)\n",
    "out_pred = [np.argmax(x, axis=1) for x in for_report]\n",
    "out_pred = np.concatenate(out_pred, axis=0)\n",
    "\n",
    "y_ = [np.argmax(x, axis=1) for x in test_y]\n",
    "y_ = np.concatenate(y_, axis=0)\n",
    "\n",
    "print('Test dataset distribution:', counts)\n",
    "cm = confusion_matrix(y_true=y_, y_pred=out_pred)\n",
    "print(cm)\n",
    "\n",
    "cr = classification_report(y_true=y_, y_pred=out_pred)\n",
    "print(cr)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=class_names, normalize=True, title='Normalized Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
