{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN+BiLSTM approach to Part-of-Speech(PoS) tagging to predict and restore punctuations to sentences\n",
    "\n",
    "The prevalent take on PoS problems have been to use BiLSTM or LSTM models due to their ability to capture and learn dependency information of sentences which are then used to make predictions.\n",
    "\n",
    "This project intends to combine CNN with BiLSTM. Making use of CNNs' ability to capture word and morphological of sentences and forwarding them to the BiLSTM.\n",
    "\n",
    "Outcome is to produce a hybrid model which outperforms a BiLSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import required packages and dependencies\n",
    "import io, json, keras, string, itertools, random, time, datetime, numpy as np, matplotlib.pyplot as plt, tensorflow as tf\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.initializers import glorot_uniform, random_uniform\n",
    "from keras.layers import Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Embedding, Conv1D, Flatten, Dense, Dropout, LSTM, Bidirectional, TimeDistributed, \\\n",
    "Dropout, Input, concatenate, Reshape\n",
    "from keras import regularizers\n",
    "from keras.utils import plot_model\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom functions to help display the Confusion Matrix and process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom functions\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    '''\n",
    "    Description: \n",
    "        - Prints and plots the confusion matrix.\tNormalization can be applied by setting `normalize=True`\n",
    "\n",
    "    Args:\n",
    "        - cm: Confusion Matrix\n",
    "        - classes: Names of classes\n",
    "        - normalize: Whether to or to not normal values in Confusion Matrix\n",
    "        - cmap: Plot color\n",
    "    '''\n",
    "\n",
    "    # Check if normalize is true or false\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    # Format axis and plot Confusion Matrix\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "def get_labels(seq):\n",
    "    '''\n",
    "    Description: \n",
    "        - Creates a sequence of labels based on the input sequence\n",
    "\n",
    "    Args:\n",
    "        - seq: Input sequence\n",
    "    \n",
    "    Returns:\n",
    "        - Sequence labels\n",
    "    '''\n",
    "    \n",
    "    labels_seq = []\n",
    "    seq = seq.split()\n",
    "    for i in range(len(seq)):\n",
    "        if '...' in seq[i]:\n",
    "            labels_seq.append('<3-dots>')\n",
    "        elif ',' in seq[i]:\n",
    "            labels_seq.append('<comma>')\n",
    "        elif '.' in seq[i]:\n",
    "            labels_seq.append('<period>')\n",
    "        elif '?' in seq[i]:\n",
    "            labels_seq.append('<question>')\n",
    "        elif '!' in seq[i]:\n",
    "            labels_seq.append('<exclaim>')\n",
    "        else:\n",
    "            labels_seq.append('<na>')\n",
    "    return labels_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set model and project parameters/settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "np.random.seed(50)\n",
    "model_name = 'ted-glove-cnn-lstm'\n",
    "\n",
    "# Dimension of the embedding layer, must match that of the word vectors\n",
    "embed_dim = 300\n",
    "\n",
    "# Maximum sequence length, how long each sentence/sequence should be\n",
    "max_seq_len = 128\n",
    "\n",
    "# Dropout are\n",
    "drop_prob = 0.35\n",
    "\n",
    "# Number of filters for each CNN layer\n",
    "filter_sizes = [64,64,64]\n",
    "\n",
    "# Kernel size for each CNN layer\n",
    "kernels = [3,5,7]\n",
    "\n",
    "# Weights and bias initialization for each CNN layer\n",
    "kernel_weight = glorot_uniform()\n",
    "bias = glorot_uniform()\n",
    "\n",
    "# Regularization for each CNN layer\n",
    "kernel_reg = regularizers.l2(l=0.0001)\n",
    "\n",
    "# Number of hidden units for Dense layer\n",
    "lstm_hidden = 1024\n",
    "\n",
    "# Number of hidden units for BiLSTM layer\n",
    "lstm_hidden_2 = 1024\n",
    "\n",
    "# Learning rate for Adam optimizer\n",
    "adam_lr = 0.001\n",
    "\n",
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Number of epochs to train for\n",
    "epochs = 50\n",
    "\n",
    "# Portion of training data to be used for validation\n",
    "valid_split = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set misc parameters\n",
    "# Get current date and time\n",
    "current = datetime.datetime.now()\n",
    "date = current.strftime('%b-%d')\n",
    "\n",
    "# Tensorboard settings\n",
    "tensor_b = TensorBoard(log_dir='./tf_logs/model_{}_hidden_{}_dropout_{}_embed_dim_{}_lr_{}'.format(model_name, \n",
    "                        lstm_hidden, drop_prob,\n",
    "                        embed_dim, adam_lr), \n",
    "                        batch_size=batch_size, \n",
    "                        write_graph=True, histogram_freq=0)\n",
    "\n",
    "# Set model training early stop criteria and save best checkpoint file\n",
    "early_s = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "chkpt = ModelCheckpoint(filepath='cnn_lstm_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# Set class names\n",
    "class_names = ['Pad', 'NA', 'Comma', 'Period', 'Question', 'Exclaim', '3-Dots']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read, load and process the Ted Talks dataset into training and validation sets with their corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre number of sentences: 237986\n",
      "\n",
      "\n",
      "(185073, '  and this is more fun.so this last one is called \"the sunshine kid.\"thank you very much for listening.old man sunshine was proud of his sun,and it brightened his day to see his little boy run,not because of what he’d done, nor the problems overcome,but that despite that his disposition remained a sunny one.it hadn’t always been like this.there’d been times when he’d tried to hide his brightness,you see, every star hits periods of hardship,it takes a brighter light to inspire them through the darkness.if we go back to when he was born in a nebula,we know that he never was thought of as regular,because he had a flair about him,to say the midas touch is wrongbut all he went near seemed to turn a little bronze,yes this sun was loved by some more than others,it was a case of joseph and his dreamcoat and his brothersbecause standing out from the crowd had its pros and its cons,and jealousy created enemies in those he outshonesuch as the shadow people.now the shadow people didn’t like the sunshine kid,because he showed up the dark things the shadow people did,and when he shone he showed the places where the shadow people hid,so the shadow people had an evil plan to get rid of him,first up — they made fun of his sunspots,shooting his dreams from the sky, their words were gunshots,designed to remind him he wasn’t very cooland he didn’t fit in with any popular kids at school.they said his head was up in space and they would bring him down to earth,essentially he came from nothing and that is what he was worth,he’d never get to go to university to learn,only degrees he’d ever show would be the first degree burnsfrom those that came too close, they told him he was too bright,that’s why no one ever looked him in the eyes,his judgment became cloudedso did the sky, with evaporated tearsas the sun started to cry.because the sunshine kid was bright, with a warm personality,and inside he burned savagelyhurt by the words and curses of the shadowy folkwho spoke holes in his soul and left cavities,and as his heart hardened, his spark darkened,every time they called him names it cooled his flames,he thought they might like him if he kept his light dimbut they were busy telling lightning she had terrible aim,he couldn’t quite get to grips with what they said,so he let his light be eclipsed by what they said,he fell into a lone star state like texas,and felt like he’d been punched in his solar plexus.but that’s when little miss sunshine came alongsinging her favorite song about how we’re made to be strong,and you don’t have to be wrong to belong, just be true to who you are,because we are all stars at heart.little miss sunshine was hot stuff,the kind of girl when you looked at heryou forgot stuff,but for him, there was no forgetting her,the minute he saw her her image burned in his retina,she was out of this world, and she accepted him,something about this girl meant he knew whenever she was next to him,things weren’t as dark as they seemed, and he dared to dream,shadows were nowhere to be seen; when she was there he beamed,his eyes would light up in ways that can’t be faked,when she grinned her rays erased the razor-tipped words of hate,they gave each other nicknames, they were \"cool star\" and \"fun sun,\"and gradually the shadowy damage became undone,she was one in a septillion, and she was brilliant,could turn the coldest blooded reptilians vermillion,loved by billions, from chileans to brazilians,and taught the sunshine kid the meaning of resilience.she said: “all the darkness in the worldcannot put out the light from a single candleso how the hell can they handle your light?only you can choose to dim it, and the sky is the limit, so silence the critics by burning.”and if eyes are windows to the soul then she drew back the curtainsand let the sun shine through the hurting.in a universe of adversity these stars stuck together,and though days became nights the memories would last forever,whether the weatherman said it or not, it would be fine,\\'cause even behind the clouds the kid could still shine.yes, the sunshine kid was bright, with a warm personality,and inside he burned savagely,fueled by the fire inspired across galaxiesby the girl who showed him belief.thank you very much. twenty-five years ago, scientists at cern created the world wide web.')\n",
      "\n",
      "\n",
      "Length of longest sentence: 4305\n",
      "Chunked longest sentence: 19\n",
      "Post number of sentences: 238004\n",
      "\n",
      "\n",
      "Last Sentence  twenty-five years ago,  scientists at cern created the world wide web.\n",
      "\n",
      "\n",
      "Counter({' ': 5183083, 'e': 2732494, 't': 2236140, 'a': 1861243, 'o': 1797491, 'i': 1648311, 'n': 1556267, 's': 1429598, 'r': 1235404, 'h': 1200803, 'l': 926456, 'd': 817246, 'u': 676726, 'c': 626734, 'm': 542737, 'w': 529153, 'y': 504344, 'g': 480783, 'f': 439860, 'p': 413986, 'b': 347437, 'v': 239213, 'k': 204683, 'x': 40701, 'j': 37556, '0': 34453, '—': 27887, 'z': 21725, 'q': 18177, '1': 16995, '2': 11304, '5': 7462, '9': 6382, '3': 5412, '4': 4555, '8': 3904, '6': 3514, '7': 3450, '’': 920, '£': 291, 'é': 283, 'í': 84, 'á': 65, 'ó': 48, 'ç': 36, 'ã': 35, 'è': 30, 'ö': 29, '“': 21, 'ñ': 20, '”': 20, 'ï': 17, 'ü': 13, 'à': 12, 'ù': 11, 'ā': 10, 'ä': 7, 'ø': 7, 'ê': 6, '\\xa0': 6, '‘': 6, 'â': 5, 'ō': 5, 'อ': 4, 'ë': 3, 'ô': 3, '²': 3, '\\x80': 3, 'ī': 3, 'ì': 3, 'ʾ': 3, 'ć': 2, 'ร': 2, '่': 2, 'ย': 2, 'æ': 2, '\\x93': 2, '•': 2, 'û': 1, 'º': 1, '˚': 1, 'ò': 1, '送': 1, '你': 1, '葱': 1, '¢': 1, '\\x94': 1, 'ă': 1, 'ť': 1, '€': 1, '∇': 1, 'τ': 1, 'č': 1, '¡': 1, 'å': 1, 'ě': 1, 'ū': 1, '¿': 1, 'ú': 1, 'ð': 1, 'प': 1, '्': 1, 'र': 1, 'े': 1, 'म': 1, 'š': 1, 'ọ': 1, '̀': 1, 'ẹ': 1})\n",
      "\n",
      "\n",
      "Number of sequences: \t238003\n",
      "Number of labels: \t238003\n"
     ]
    }
   ],
   "source": [
    "# Read and load dataset\n",
    "data = open('./data/processed/ted_data', 'r', encoding='utf-8').read()\n",
    "\n",
    "# Convert all characters to lowercase\n",
    "data = data.lower()\n",
    "\n",
    "# Look-up table to remove punctuations from data\n",
    "table = str.maketrans('', '', punctuation)\n",
    "\n",
    "# Define and remove characters and bracketed actions\n",
    "replace = ['♫', '♪', '–', '…', '(applause)', '(laughter)']\n",
    "for i in range(len(replace)):\n",
    "    data = data.replace(replace[i], ' ')\n",
    "\n",
    "# Split dataset by sentences\n",
    "data_split = data.split('\\n')\n",
    "print('Pre number of sentences:', len(data_split))\n",
    "print('\\n')\n",
    "# Get longest sentence in dataset and its index\n",
    "print(max(enumerate(data_split), key=lambda x: len(x[1])))\n",
    "print('\\n')\n",
    "print('Length of longest sentence:', len(max(data_split, key=len)))\n",
    "\n",
    "# Clean and split the longest sentence into multiple ones based on full-stops\n",
    "data_split[185073] = data_split[185073].replace(',', ', ')\n",
    "data_split[185073] = data_split[185073].replace('.', '.\\n')\n",
    "long_sent = data_split[185073].split('\\n')\n",
    "\n",
    "# Check number of sentences from chunking longest sentence\n",
    "print('Chunked longest sentence:', len(long_sent))\n",
    "\n",
    "# Remove longest sentence at index 185703\n",
    "del data_split[185073]\n",
    "\n",
    "# Add chunked sentences back to dataset\n",
    "for x in long_sent:\n",
    "    data_split.append(x)\n",
    "\n",
    "# Check length of dataset after addition\n",
    "print('Post number of sentences:', len(data_split))\n",
    "print('\\n')\n",
    "\n",
    "# Remove empty rows\n",
    "data_split = data_split[:238003]\n",
    "\n",
    "# Check last sentence of dataset\n",
    "print('Last Sentence', data_split[-1])\n",
    "print('\\n')\n",
    "\n",
    "# Get corresponding labels for dataset\n",
    "process_labels = [get_labels(seq) for seq in data_split]\n",
    "process_labels = [' '.join(seq) for seq in process_labels]\n",
    "\n",
    "# Remove all punctuations from dataset\n",
    "sequences = [seq.translate(table) for seq in data_split]\n",
    "\n",
    "# Combined sentences back into a single piece for Counter\n",
    "combined_sequences = ' '.join(sequences)\n",
    "\n",
    "# Check if there are additional characters to remove\n",
    "print(Counter(combined_sequences))\n",
    "print('\\n')\n",
    "    \n",
    "# Get all words in the dataset\n",
    "words = combined_sequences.split()\n",
    "\n",
    "# Save inputs and labels for reference\n",
    "with open('./data/processed/processed_input', 'w', encoding='utf-8') as f:\n",
    "    for x in sequences:\n",
    "        f.write(x+'\\n')\n",
    "with open('./data/processed/processed_labels', 'w', encoding='utf-8') as f:\n",
    "    for x in process_labels:\n",
    "        f.write(x+'\\n')\n",
    "\n",
    "# Check number of sequences and labels\n",
    "print('Number of sequences: \\t{}'.format(len(sequences)))\n",
    "print('Number of labels: \\t{}'.format(len(process_labels)))\n",
    "\n",
    "# Load processed labels\n",
    "y_labels = open('./data/processed/processed_labels', 'r', encoding='utf-8').read()\n",
    "y_labels = y_labels.split('\\n')\n",
    "y_labels = y_labels[:-1]\n",
    "all_labels = ' '.join(y_labels)\n",
    "\n",
    "# Get all labels in the dataset\n",
    "labels_tag = all_labels.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build words and labels vocabularies and store them as json dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 104910\n",
      "\n",
      "\n",
      "Class distribution: Counter({'<na>': 4475054, '<comma>': 360733, '<period>': 294389, '<question>': 26054, '<exclaim>': 2330, '<3-dots>': 1394})\n",
      "\n",
      "\n",
      "Number of unique labels: 7\n",
      "{'<na>': 1, '<comma>': 2, '<period>': 3, '<question>': 4, '<exclaim>': 5, '<3-dots>': 6, '<pad>': 0}\n"
     ]
    }
   ],
   "source": [
    "# Build words vocab\n",
    "all_data = ' '.join(sequences)\n",
    "words = all_data.split()\n",
    "words_in_vocab = Counter(words)\n",
    "vocab = sorted(words_in_vocab, key=words_in_vocab.get, reverse=True)\n",
    "\n",
    "# Skip most common word\n",
    "vocab_to_int = {word: index for index, word in enumerate(vocab, 2)}\n",
    "vocab_to_int['<pad>'] = 0  # The special value used for padding\n",
    "vocab_to_int['<oov>'] = 1  # The special value used for OOVs\n",
    "\n",
    "# Check number of unique words\n",
    "unique_vocab = len(vocab_to_int)\n",
    "print('Number of unique words:', unique_vocab)\n",
    "print('\\n')\n",
    "\n",
    "# Build labels vocab\n",
    "labels_in_vocab = Counter(labels_tag)\n",
    "labels_vocab = sorted(labels_in_vocab, key=labels_in_vocab.get, reverse=True)\n",
    "label_to_int = {t: i for i, t in enumerate(labels_vocab, 1)}\n",
    "label_to_int['<pad>'] = 0  # The special value used to padding\n",
    "\n",
    "# Write vocab and label dictionaries to file\n",
    "with open('./vocabs.json', 'w', encoding='utf-8') as fv:\n",
    "    json.dump(vocab_to_int, fv, indent=4)\n",
    "    \n",
    "with open('./labels.json', 'w', encoding='utf-8') as fl:\n",
    "    json.dump(label_to_int, fl, indent=4)\n",
    "    \n",
    "# Check label classes distribution\n",
    "no_classes = len(label_to_int)\n",
    "print('Class distribution:', Counter(labels_in_vocab))\n",
    "print('\\n')\n",
    "\n",
    "# Check number of unique labels\n",
    "print('Number of unique labels:', no_classes)\n",
    "print(label_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize the sequences and their corresponding labels. Pad each sequence and its labels to maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sequence:  twentyfive years ago  scientists at cern created the world wide web\n",
      "\n",
      "\n",
      "Sample sequence: [14518    84   197   649    31 10130   501     2    81  1929   948     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n",
      "\n",
      "Sample label: [1 1 2 1 1 1 1 1 1 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "Encoded label [[0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]]\n",
      "Maximum sequence length: 128\n",
      "Sequence and labels length check passed!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize input sequences\n",
    "seq_int = []\n",
    "for seq in sequences:\n",
    "    seq_int.append([vocab_to_int[word] for word in seq.split()])\n",
    "\n",
    "# Pad input sequences\n",
    "pad_seq = pad_sequences(sequences=seq_int, maxlen=max_seq_len, padding='post', value=0)\n",
    "\n",
    "# Check sample sequence\n",
    "print('Sample sequence:', sequences[-1])\n",
    "print('\\n')\n",
    "print('Sample sequence:', pad_seq[-1])\n",
    "print('\\n')\n",
    "\n",
    "# Tokenize output labels\n",
    "lab_int = []\n",
    "for lab in y_labels:\n",
    "    lab_int.append([label_to_int[word] for word in lab.split()])\n",
    "\n",
    "# Pad input labels\n",
    "pad_labels = pad_sequences(sequences=lab_int, maxlen=max_seq_len, padding='post', value=0)\n",
    "encoded_labels = [to_categorical(i, num_classes=no_classes) for i in pad_labels]\n",
    "\n",
    "# Check sample label\n",
    "print('Sample label:', pad_labels[-1])\n",
    "print('\\n')\n",
    "print('Encoded label', encoded_labels[-1])\n",
    "\n",
    "# Check max seq length\n",
    "print(\"Maximum sequence length: {}\".format(max_seq_len))\n",
    "\n",
    "# Check that all sequences and labels are at max sequence length \n",
    "assert len(pad_seq)==len(seq_int)\n",
    "assert len(pad_seq[0])==max_seq_len\n",
    "\n",
    "assert len(pad_labels)==len(lab_int)\n",
    "assert len(pad_labels[0])==max_seq_len\n",
    "print('Sequence and labels length check passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Dataset: \t(190402, 128) 190402\n",
      "Testing Dataset: \t\t(47601, 128) 47601\n"
     ]
    }
   ],
   "source": [
    "# Split train and label dataset\n",
    "train_test_split_frac = 0.8\n",
    "split_index = int(0.8*len(pad_seq))\n",
    "\n",
    "# Split data into training, validation, and test data (features and labels, x and y)\n",
    "train_val_x, test_x = pad_seq[:split_index], pad_seq[split_index:]\n",
    "train_val_y, test_y = encoded_labels[:split_index], encoded_labels[split_index:]\n",
    "\n",
    "# print out the shapes of your resultant feature data\n",
    "print('Training/Validation Dataset: \\t{}'.format(train_val_x.shape), len(train_val_y))\n",
    "print('Testing Dataset: \\t\\t{}'.format(test_x.shape), len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and process Glove pretrained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 word vectors\n"
     ]
    }
   ],
   "source": [
    "# Load glove pre-trained vectors\n",
    "glove_index = dict()\n",
    "f = open('./data/embeddings/glove.6B.300d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    glove_index[word] = coefs\n",
    "f.close()\n",
    "print('{} word vectors'.format(len(glove_index)))\n",
    "\n",
    "embed_matrix = np.zeros((unique_vocab, embed_dim))\n",
    "for word, i in vocab_to_int.items():\n",
    "    embedding_vector = glove_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embed_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm(max_seq_len, unique_vocab, embed_dim, embed_matrix, filter_sizes, kernels, kernel_weight, bias):\n",
    "    '''\n",
    "    Description: \n",
    "        - Constructs and compiles the CNN+BiLSTM model\n",
    "    \n",
    "    Args(They can be defined earlier at the top of the notebook):\n",
    "        - max_seq_len: Maximum sequence length \n",
    "        - unique_vocab: Number of unique words\n",
    "        - embed_dim: Embedding layer dimension, needs to match with that of Glove pre-trained\n",
    "        - embed_matrix: Pre-trained weights extracted from Glove based on unique words\n",
    "        - filter_sizes: Number of filters per CNN layer\n",
    "        - kernels: Kernel sizes per CNN layer\n",
    "        - kernel_weight: Weights initialization for CNN layers\n",
    "        - bias: Bias initialization for CNN layers\n",
    "        \n",
    "    Return: \n",
    "        - Compiled model\n",
    "    '''\n",
    "    embed_input = Input(shape=(max_seq_len,))\n",
    "\n",
    "    # Add embedding layer using weights from glove\n",
    "    embed = Embedding(input_dim=unique_vocab, output_dim=embed_dim, weights=[embed_matrix], \n",
    "                        input_length=max_seq_len, trainable=True)(embed_input) #104910 * 300\n",
    "    \n",
    "    embed = Dropout(rate=drop_prob)(embed)\n",
    "\n",
    "    cnn_outputs = []\n",
    "    for i in range(len(filter_sizes)):\n",
    "        # Add conv1d layer\n",
    "        out_i = Conv1D(filters=filter_sizes[i], kernel_initializer=kernel_weight, bias_initializer=bias, \n",
    "                          kernel_size=kernels[i], kernel_regularizer=None, activation='relu', \n",
    "                          padding='SAME', strides=1)(embed)\n",
    "        out_i = BatchNormalization()(out_i)\n",
    "        cnn_outputs.append(out_i)\n",
    "\n",
    "    cnn_outputs = concatenate(cnn_outputs, axis=-1)\n",
    "    cnn_outputs = Dropout(rate=drop_prob)(cnn_outputs)\n",
    "    cnn_outputs = Reshape((-1, np.sum(filter_sizes)))(cnn_outputs)\n",
    "    \n",
    "    dense = Dense(lstm_hidden, activation='relu')(cnn_outputs)\n",
    "    dense = Dropout(rate=drop_prob)(dense)\n",
    "    \n",
    "    blstm_outputs = Bidirectional(LSTM(lstm_hidden_2, return_sequences=True))(dense)\n",
    "    \n",
    "    blstm_outputs = Dropout(rate=drop_prob)(blstm_outputs)\n",
    "    \n",
    "    output = TimeDistributed(Dense(no_classes, activation='softmax'))(blstm_outputs)\n",
    "\n",
    "    model = Model(inputs=[embed_input], outputs=[output])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(adam_lr), \n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 128, 300)     31473000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 128, 64)      57664       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 128, 64)      96064       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 128, 64)      134464      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 64)      256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 192)     0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 192)     0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 128, 192)     0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 1024)    197632      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128, 1024)    0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 128, 2048)    16785408    dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128, 2048)    0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 128, 7)       14343       dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 48,759,343\n",
      "Trainable params: 48,758,959\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "Train on 133281 samples, validate on 57121 samples\n",
      "Epoch 1/50\n",
      "133281/133281 [==============================] - 1340s 10ms/step - loss: 0.0353 - acc: 0.9884 - val_loss: 0.0297 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02968, saving model to cnn_lstm_model.h5\n",
      "Epoch 2/50\n",
      "133281/133281 [==============================] - 1369s 10ms/step - loss: 0.0265 - acc: 0.9907 - val_loss: 0.0263 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02968 to 0.02627, saving model to cnn_lstm_model.h5\n",
      "Epoch 3/50\n",
      "133281/133281 [==============================] - 1364s 10ms/step - loss: 0.0237 - acc: 0.9917 - val_loss: 0.0255 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02627 to 0.02548, saving model to cnn_lstm_model.h5\n",
      "Epoch 4/50\n",
      "133281/133281 [==============================] - 1376s 10ms/step - loss: 0.0220 - acc: 0.9922 - val_loss: 0.0251 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02548 to 0.02515, saving model to cnn_lstm_model.h5\n",
      "Epoch 5/50\n",
      "133281/133281 [==============================] - 1377s 10ms/step - loss: 0.0208 - acc: 0.9926 - val_loss: 0.0244 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02515 to 0.02442, saving model to cnn_lstm_model.h5\n",
      "Epoch 6/50\n",
      "133281/133281 [==============================] - 1360s 10ms/step - loss: 0.0198 - acc: 0.9929 - val_loss: 0.0244 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02442 to 0.02436, saving model to cnn_lstm_model.h5\n",
      "Epoch 7/50\n",
      "133281/133281 [==============================] - 1312s 10ms/step - loss: 0.0190 - acc: 0.9932 - val_loss: 0.0242 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02436 to 0.02419, saving model to cnn_lstm_model.h5\n",
      "Epoch 8/50\n",
      "133281/133281 [==============================] - 1312s 10ms/step - loss: 0.0182 - acc: 0.9934 - val_loss: 0.0246 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02419\n",
      "Epoch 9/50\n",
      "133281/133281 [==============================] - 1319s 10ms/step - loss: 0.0176 - acc: 0.9937 - val_loss: 0.0248 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02419\n",
      "Epoch 10/50\n",
      "133281/133281 [==============================] - 1336s 10ms/step - loss: 0.0169 - acc: 0.9939 - val_loss: 0.0247 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02419\n",
      "Epoch 11/50\n",
      "133281/133281 [==============================] - 1372s 10ms/step - loss: 0.0164 - acc: 0.9941 - val_loss: 0.0250 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02419\n",
      "Epoch 12/50\n",
      "133281/133281 [==============================] - 1415s 11ms/step - loss: 0.0159 - acc: 0.9942 - val_loss: 0.0255 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02419\n",
      "Epoch 00012: early stopping\n",
      "Time taken: 16273.585237503052 seconds\n"
     ]
    }
   ],
   "source": [
    "# Model code\n",
    "model = cnn_lstm(max_seq_len=max_seq_len, unique_vocab=unique_vocab, embed_dim=embed_dim,\n",
    "                embed_matrix=embed_matrix, filter_sizes=filter_sizes, kernels=kernels,\n",
    "                 kernel_weight=kernel_weight, bias=bias)\n",
    "\n",
    "# Summarize model\n",
    "model.summary()\n",
    "\n",
    "# Fit, train and evaluate model\n",
    "start = time.time()\n",
    "model.fit(x=train_val_x, y=np.array(train_val_y), batch_size=batch_size, \n",
    "          epochs=epochs, validation_split=valid_split, steps_per_epoch=None, validation_steps=None,\n",
    "          shuffle=True, verbose=1, callbacks=[tensor_b, early_s, chkpt])\n",
    "print('Time taken: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model architecture and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a sample test data, make a prediction from it and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions Index:\n",
      "[array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3,\n",
      "       3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)]\n",
      "\n",
      "\n",
      "Prediction sequence:\n",
      "this is where the robots and models that ive presented today will hopefully play a key role towards these very important goalsthank you bruno giussani auke ive seen in your lab other robots that do things like swim in pollution and measure the pollution while they swim <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "\n",
      "Prediction output:\n",
      "<na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <period> <period> <na> <na> <comma> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <period> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "\n",
      "Combined prediction:\n",
      "This is where the robots and models that I've presented today will hopefully play a key role towards these very important goalsthank. you. bruno giussani auke, I've seen in your lab other robots that do things like swim in pollution and measure the pollution while they swim.                                                                                 \n"
     ]
    }
   ],
   "source": [
    "# Load a sample of test data\n",
    "test_data = test_x[11111]\n",
    "\n",
    "# Restore tokenized test data back to normal sentence\n",
    "pred_x_seq = []\n",
    "for x in test_data:\n",
    "    for value, index in vocab_to_int.items():\n",
    "        if x == index:\n",
    "            pred_x_seq.append(value)\n",
    "\n",
    "# Get predicted output of test data (Make predictions)\n",
    "pred_expand = model.predict(np.expand_dims(test_data, axis=0))\n",
    "\n",
    "# Retrieve position of highest probability from predictions\n",
    "pred_y = []\n",
    "for y in pred_expand:\n",
    "    pred_y.append(np.argmax(y, axis=1))\n",
    "print('Predictions Index:')\n",
    "print(pred_y)\n",
    "\n",
    "# Restore tokenized labels\n",
    "pred_y_seq = []\n",
    "for x in pred_y:\n",
    "    for y in x:\n",
    "        for value, index in label_to_int.items():\n",
    "            if y == index:\n",
    "                pred_y_seq.append(value)\n",
    "\n",
    "# Restore punctuations and capitalization                \n",
    "combined = []\n",
    "for i in range(len(pred_x_seq)):\n",
    "    if pred_y_seq[i] == '<comma>':\n",
    "        combined.append(str(pred_x_seq[i])+',')\n",
    "    elif pred_y_seq[i] == '<period>':\n",
    "        combined.append(str(pred_x_seq[i])+'.')\n",
    "    elif pred_y_seq[i] == '<question>':\n",
    "        combined.append(str(pred_x_seq[i])+'?')\n",
    "    elif pred_y_seq[i] == '<exclaim>':\n",
    "        combined.append(str(pred_x_seq[i])+'!')\n",
    "    elif pred_y_seq[i] == '<3-dots>':\n",
    "        combined.append(str(pred_x_seq[i])+'...')\n",
    "    else:\n",
    "        combined.append(str(pred_x_seq[i]))\n",
    "\n",
    "for i in range(len(combined)):\n",
    "    if '.' in combined[i]:\n",
    "        combined[i+1] = combined[i+1].capitalize()\n",
    "    elif combined[i] == 'i':\n",
    "        combined[i] = combined[i].capitalize()\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Join predicted words back into a sequence\n",
    "combined = ' '.join(combined)\n",
    "combined = combined.replace('<pad>', '')\n",
    "\n",
    "print('\\n')\n",
    "print('Prediction sequence:')            \n",
    "print(' '.join(pred_x_seq))\n",
    "print('\\n')\n",
    "print('Prediction output:')\n",
    "print(' '.join(pred_y_seq))\n",
    "print('\\n')\n",
    "print('Combined prediction:')\n",
    "print(combined.capitalize().replace('ive', \"I've\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Confusion Matrix and Classification Report to check model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4931230       0       0       0       0       0       1]\n",
      " [    297  989860   19050    4469     947     278       4]\n",
      " [      9   27831   44860    2328     932     127       2]\n",
      " [    313    3641    3678   56036     360     111       0]\n",
      " [      7    1052     571     249    3627      16       0]\n",
      " [      4     148     208     134      21      51       0]\n",
      " [    346      59      20      38       1       0      12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   4931231\n",
      "           1       0.97      0.98      0.97   1014905\n",
      "           2       0.66      0.59      0.62     76089\n",
      "           3       0.89      0.87      0.88     64139\n",
      "           4       0.62      0.66      0.64      5522\n",
      "           5       0.09      0.09      0.09       566\n",
      "           6       0.63      0.03      0.05       476\n",
      "\n",
      "   micro avg       0.99      0.99      0.99   6092928\n",
      "   macro avg       0.69      0.60      0.61   6092928\n",
      "weighted avg       0.99      0.99      0.99   6092928\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[9.99999797e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.02789121e-07]\n",
      " [2.92638227e-04 9.75322813e-01 1.87702297e-02 4.40336780e-03\n",
      "  9.33092260e-04 2.73917263e-04 3.94125559e-06]\n",
      " [1.18282538e-04 3.65769034e-01 5.89572737e-01 3.05957497e-02\n",
      "  1.22488139e-02 1.66909803e-03 2.62850083e-05]\n",
      " [4.88002619e-03 5.67673334e-02 5.73442056e-02 8.73665009e-01\n",
      "  5.61280968e-03 1.73061632e-03 0.00000000e+00]\n",
      " [1.26765665e-03 1.90510685e-01 1.03404564e-01 4.50923578e-02\n",
      "  6.56827237e-01 2.89750091e-03 0.00000000e+00]\n",
      " [7.06713781e-03 2.61484099e-01 3.67491166e-01 2.36749117e-01\n",
      "  3.71024735e-02 9.01060071e-02 0.00000000e+00]\n",
      " [7.26890756e-01 1.23949580e-01 4.20168067e-02 7.98319328e-02\n",
      "  2.10084034e-03 0.00000000e+00 2.52100840e-02]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAElCAYAAABgV7DzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzsnXd8VMX6h583WXpLQk12KSEBUugh9C4okIBKly6W371XAXsv2AsqoHKv12sBAekoJHRQVEAJXaoQIEA2oRiqAsEs8/vjLGE3Bc4mwV1lHj7nw54z78x3Zs7Ju1POzohSCo1Go9GYw8/bGdBoNJq/EtppajQajQdop6nRaDQeoJ2mRqPReIB2mhqNRuMB2mlqNBqNB2ineZMgImNFZJrzcw0R+U1E/ItYI0VEuhRlmh5ovyoiv4rI0UKkcUPq5c9GRJ4RkU+8nY+/K9ppFhFOh3FMRMq4XLtXRFZ7MVt5opQ6rJQqq5Ry/Jm6ItJcRBaLyGkROSkiSSJydxGkWx14FIhSSlUraDo3sl5ERDmfD4vLNYuIHBcRUy9Li0hHEUm9np1S6nWl1L2Fya8mf7TTLFoswJjCJiIGf6t7IyKtgG+A74BwoCLwT6B7ESRfE8hQSh0vgrRuJKdxL28P4FRRCrg6Zc2N4W/1h+kDjAMeE5GAvAJFpLWIbBCRM87/W7uErRaR10RkLXAeqO289qqIrHN2GxNEpKKITBeRs840armkMVFEjjjDNolIu3zyUcvZ8rGISCtn2leOiyKS4rTzE5GnRGS/iGSIyGwRCXJJZ6iIHHKGPWuibqYopd5SSv2qDDYppfq7pHefiCQ7W6ELRSTEJUyJyD9EZJ+InBKRSc4vly7ACiDEmf/JebXIXIcOnC3ejc56OiYi7+WsF+d5iDMfJ535us8lvbHO+vhCRM6JyE4RaXadOpgKDHM5HwZ8kSOfd4vIbmeaB0Tk/5zXywBLXMr5mzN/Y0VkrohME5GzwAhxH4oZ4EynvPO8u4gcFZHK18mrJj+UUvooggNIAboA84FXndfuBVY7PwdhtCqGYrRI73KeV3SGrwYOA9HO8GLOa8lAGFAB2AXsdepYMP7gPnfJwxCMFpwFo7t6FCjpDBsLTHN+rgUowJKjDFc033CePwT8BNiAEsB/gRnOsCjgN6C9M+w9IAvokkfdlAYcQKdr1F9n4FegqTO9D4DvXcIVkAgEADWAE0A3Z1hHINXF1u3c9f44P/8IDHV+Lgu0zKteMFrF/wZKAo2dmre41OdFjNaiP/AG8NM1yqeA+sAxZxkCnJ/rA8rFLs55vwXogPEF2vQa5RoL/AHcgdEIKuV6r50204HJzmcjDYj39t/LX/nQLc2i5wVgVB7f5HHAPqXUVKVUllJqBrAH6OliM1kptdMZ/ofz2udKqf1KqTMYLY39SqmVSqksYA7Q5EpkpdQ0pVSGM/67GM6nngd5fx/4HbjSavw/4FmlVKpSKhPjj7GvsyXWF0hUSn3vDHseuJxPuoEYf9Dp19AeDHymlNrsTO9poJVrSxp4Uyl1Wil1GPgWw5EVhD+AcBGppJT6TSn1U04D5zhpW+BJpdRFpdRW4BOML70rrFFKLVbGGOhUoNF1dC8CCcAAYCCw0HktG6XUIuf9Vkqp74DlQJ49Bhd+VEp9rZS6rJS6kEf4AxhfSquBBKVU4nXS01wD7TSLGKXUDowW0VM5gkKAQzmuHQKsLudH8kjymMvnC3mcl71yIiKPOrt2Z0TkNEbrtJKZfDu7gR2BQUqpK86vJvCVGBM3p4HdGC3Gqs7yZOdXKfU7kJFP8qcwHGrwNbLgVj9Kqd+c6bnWj+vM+Hlcyu4h9wB1gT3OIY74fPJzUil1zuVazvuVMz8lTYwpfoHRLc/VNYfs7vNPziGB0xgt2evdw7yem2yUUqcxvmDrA+9eJy3NddBO88bwInAf7n9gaRhOyJUagN3lvMBLTjnHL58E+gOBSqkA4AxGN89M3FeA250t2iscAborpQJcjpJKKTtGq7G6SxqlMbp/uVBKncfoEve5Rjbc6sc5hlcR9/oxy+8YQwJX0vIHslv+Sql9Sqm7gCrAW8BccXnrwSU/QSJSzuVazvtVEH7A+PKoCqxxDRCREsA84B2gqvMeLubqPczv+bjmcyMijYGRwAyM3oSmEGineQNQSiUDs4DRLpcXA3VFZJBzAmYAxrhgUXWVymGMKZ4ALCLyAlD+epGc3dBZwDCl1N4cwR8Br4lITadtZRG53Rk2F4gXkbYiUhx4mWs/T09gTFI8LiIVnek1EpGZzvAvgbtFpLHTebwOrFdKpVy35LnZi9HqixORYsBzGEMVV8o8REQqO1vUp52X3V4zUkodAdYBb4hISRFpiNFCnV6A/LimqzCGZHo5P7tS3JnPE0CWiHQHbnUJPwZUFJEKZvVEpCQwDXgGuBuwisi/ClGEmx7tNG8cLwPZrRelVAYQjzFBk4HhROKVUr8Wkd4yjDHPvRjdyItcp9vm5BagGkZr68qs7E5n2ESMcbflInIOY1KohbM8OzHGyr7EaHWeAvJ9h1AptQ5jXK0zcEBETgIfY3yZoJRahTEuOs+ZXhjGuJ/HOFvL/8IYg7RjtDxd89YN2CkivznLOFApdTFXQsZkXS2MVudXwItKqRUFyVOO/O101l/O6+cwvmhnY9TnIIz6vxK+B6O1eMA5ZBKSM408eANj8ug/zrHiIcCrIlKnsOW4WZHcX3YajUajyQ/d0tRoNBoP0E5To9FoPEA7TY1Go/EA7TQ1Go3GA7TT1Gg0Gg+4qVZEEUspJcXLXd/wBtAksoZXdDWaP5NDh1L49ddfr/uDimvhX76mUll5/Ro0N+rCiWVKqW6F0fOUm8tpFi9HiXr9r294A1i7/kOv6Go0fyZtWlxvoafro7IuUiLC3Cu6F7d8YOpnwkXJTeU0NRrNXwABpFCN1RuKdpoajcb38OE1uLXT1Gg0PoaAn+9u06Sdpkaj8T1091yj0WhMIujuuUaj0ZhHfLql6bvu/E/ioxcHc2jVG2yc80y+Nu8+0ZcdC14kadbTNI6wZV8f3LMF2xe8wPYFLzC4Z4sC6S9ftpSG0fWIjghn3Ntv5grPzMxkyKABREeE0651Cw6lpGSHjXvrDaIjwmkYXY8Vy5dpba3ts9oeI37mDm/g7U2K/sxDSlVWJRs/4HbcMvI91XLgG2rHPnuusJKNH1C3PzhJLV2zQ5Vs/IBqP3ScSvr5oCrZ+AEV3P5xdeDICRXc/nFVrd1j6sCRE6pau8fyTKNk4wfUhT9UruO3i1kqtHZtteuX/erM75mqQYOGavO2nW42E96fpO697//UhT+UmjJthurTr7+68IdSm7ftVA0aNFSnf7uodu89oEJr11a/XczKU0dra+0/S7tp0xhV6L/TMtVUydbPmDqAjX+2H7npW5prN+/n5Jnz+YbHd2jIl4lJACRtT6FCuVJUq1Serq0jWfXTHk6dPc/pcxdY9dMebm0T5ZH2hqQkwsLCCa1dm+LFi9NvwEASExa42SQmLGDw0OEA9O7Tl9XfrEIpRWLCAvoNGEiJEiWoFRpKWFg4G5KStLbW9jltjxHn7LmZwwvc9E7zeoRUCSD16Knsc/ux04RUCSCkcgCpx1yuHz9NSOU8tzvPl7Q0OzZb9jY7WK027HZ7bpvqho3FYqF8hQpkZGRgt+eOm5Zmfvsara21/yztAuHD3XOfcZoi4hCRrSKyQ0TmODfqMht3hIjckN8p5jUerZTK+7qH+6LltWq+5Eg4XxsTcbW21vYFbc8R7TRNckEp1VgpVR+4BPzD2xkCo2VpqxaYfW6tGkD6iTPYj5/GVtXlehXjuidYrTZSU69u42O3pxISEpLb5ohhk5WVxdkzZwgKCsJqyx03ONjMljFaW2v/udoFwk/MHV7Al5ymKz8A4QAi8rWIbBKRnSJy/xUDEblbRPaKyHdAmxuVkUXfbWdQfHMAmjeoxdnfLnD017OsWLebLq0iCChXioBypejSKoIV63Z7lHaz2FiSk/eRcvAgly5dYs6smcTF93KziYvvxfSpUwCYP28uHTp1RkSIi+/FnFkzyczMJOXgQZKT9xHbvLnW1to+p+0xV97T9NGWps+9pykiFqA7sNR5aaRS6qSIlAI2iMg8jK1OXwJiMPb2/hbYkk969wOGsy1WNlf4lDdG0C6mDpUCypK89BVe+WgxxSzGAPMnc9ewdM1Obmsbzc6FL3L+4h/839hpAJw6e543/reUNdOeAOD1j5dy6mz+E0p5YbFYGD/xQ3rG3YbD4WD4iJFERUfz8tgXaBrTjPievRgx8h5GjhhKdEQ4gYFBTJ1u7HgbFR1Nn379adIwCovFwoT3J+Hvb35gXGtr7T9Lu0D48HuaPrMbpYg4gO3O0x+AR5VSl0RkLHCn83ot4DaMLWd7K6WGOeOOBuoqpR68loZf6SrKW0vDndqgl4bT/P1p06IZmzZtLJTH8ytvUyVajDJle3HlU5uUUoVfj84DfKmleUEp1dj1goh0BLoArZRS50VkNVDSGewb3l6j0RQ9PvwzSt/NmUEF4JTTYUYALZ3X1wMdRaSiiBQD+nkthxqNpmgRMX94AV9qaebFUuAfIvIz8AvwE4BSKt3Zbf8RSAc2A767lpRGo/EMH25p+ozTVErlmqVRSmViTArlZf858PmNzpdGo/ECPjwR5DNOU6PRaAz0IsQajUZjHr2epkaj0XiCaKep0Wg0HqHHNDUajcYDdEtTo9FoPEC3NDUajcYkomfPNRqNxiNu7HqdhUM7TY1G41MI2mn6DE0ia7B2vXdWGwps87hXdAFOfP+W17T9vbRQ7BV8+Y9Pkw/iPHyUm8ppajSavwLi01922mlqNBqfQztNjUaj8QA/P/2epkaj0ZhDj2lqNBqNeUSPaWo0Go1naKep0Wg0HqCdpkaj0ZhFQLz8fu+18N0pqj+R5cuW0jC6HtER4Yx7+81c4ZmZmQwZNIDoiHDatW7BoZSU7LBxb71BdEQ4DaPrsWL5Mo+1u7asx7bZj7Nj7pM8NqxTrvAa1QJY/OH9JE17hGX//gfWKhWyw157MI5NMx5ly8zHePeR2z3WXrF8KU0aRNIoqi7vjsv9AnxmZibDhwykUVRdOrVrlV3ub1auoF2rWFrENKJdq1i++/Ybj7WXL1tKo+gI6kfW4Z186nzooIHUj6xD+zYtc9V5/cg6NIqOKFCde/N+36zaniIipg5vcNM7TYfDwUOjH2BBwhK2/LyLOTNnsHvXLjebyZ99SmBAIDv3JDNqzMM8+8yTAOzetYs5s2ayedtOFiYuZcyof+FwOExr+/kJEx6/k9sf+pQmA9+h362NiQit4mbzxuh4pi/eRPMh7/H6pyt4+V/GlkktG9SkVcNaxA5+j5hB7xITVZ12TWt7VO5Hx4xi/oJFbNi6g7mzZ7Jnt3u5v5j8GQEBgWzbtZcHRo3hheeeAqBipUrMnreA9Zu28d9PPue+e4ab1r2i/fCYB/k6YTGbt+1kzqyZuev8808JCAxgx+59jBr9EM89Y2jv3rWLubNnsWnrDhYkLuGh0Q94VOfevN83q7anXJkIKiqnKSLdROQXEUkWkafyCK8hIt+KyBYR+VlEelwrvZveaW5ISiIsLJzQ2rUpXrw4/QYMJDFhgZtNYsICBg81HEPvPn1Z/c0qlFIkJiyg34CBlChRglqhoYSFhbMhKcm0dmxUDfan/kpK2kn+yHIwZ8VW4ttHu9lEhFZl9cZkAL7btD87XCkoUcJC8WL+lChmwWLx4/jJ30xrb9yQRO2wsOxy9+k3gMSEhW42ixIWMGjIMADu6N2X1d9+g1KKRo2bEBwSAkBkVDQXL14kMzPTI23XOu/bf0CuOl+UsJAhzjq/s09fVn97tc779h/gVucbN5ivc2/e75tVuyAUldMUEX9gEsYGjVHAXSISlcPsOWC2UqoJMBD497XSvOmdZlqaHZuteva51WrDbrfntqlu2FgsFspXqEBGRgZ2e+64aWnuca9FSJXypB47nX1uP34Ga+UKbjbb96VzR6cGANzesT7ly5QkqHxp1u84xPeb9nNw0QscXPw8K3/ayy8px01rp6fZsbrl3Up6Ws5yp2WXz2KxUKG8UW5XFnw1j0aNmlCiRAnT2ml2O1abzUU7d70ZNrnrPOf9CrFaSbObr3Nv3u+bVbtAiMnj+jQHkpVSB5RSl4CZQM6xLAWUd36uAKRdK0GfdZoiokTkXZfzx5x7nbvabBORGYXRUUrlpW3OxkTcayF53PWcWk+/n0i7JrX58YuHaNe0Nvbjp8lyXKa2rSL1alUhvOerhMW/Ssdm4bRpHGpau1DldrJ7105eePZpJn74H9O6hdU2E/dGaRf2ft+s2h4jHrU0K4nIRpfj/hypWYEjLuepzmuujAWGiEgqsBgYda3s+azTBDKB3iJSKa9AEYnEyH97ESlTUBGr1UZq6tU6tdtTCXF2Pd1sjhg2WVlZnD1zhqCgIKy23HGDg93jXgv78TPYqgZc1alSgbRfz7rZpP96loFPfUGrYRN48T9LATj7+0Vu71ifpB2H+f3CJX6/cIllP+6hRf2aprVDrDbsbnm3Uy04Z7mt2eXLysrizFmj3AD21FTu6t+H/346mdphYaZ1Aaw2G/bUVBft3PVm2ORR5znuV5rdnj1UYErbi/f7ZtUuCH5+fqYO4FelVDOX4+McSeXl3XN+C9wFTFZK2YAewFSR/Pfb8GWnmQV8DDycT/ggYCqwHOhVUJFmsbEkJ+8j5eBBLl26xJxZM4mLd08uLr4X06dOAWD+vLl06NQZESEuvhdzZs0kMzOTlIMHSU7eR2zz5qa1N+4+Qnj1StQMDqSYxZ9+XRuz6Hv3wfmKFUpnf6s/PrwzUxI2AHDk6GnaNamNv78fFn8/2jWpzZ6UY6a1Y5rFsj85Obvc8+bMIi6+p5tNj/hefDntCwC+nj+XDh07ISKcPn2avnf25KVXXqNV6zamNV21Xet87uxZueq8R3xPpjnr/Kt5c+nQ8Wqdz509y63Om8War3Nv3u+bVdtTingiKBWo7nJuI3f3+x5gNoBS6kegJJBnYw18/z3NScDPIvJ2HmEDgK5APeBBIM9uurO5fj9A9Ro1coVbLBbGT/yQnnG34XA4GD5iJFHR0bw89gWaxjQjvmcvRoy8h5EjhhIdEU5gYBBTp88EICo6mj79+tOkYRQWi4UJ70/C39/8Mv0Ox2UefudrEt6/D38/P6YkJLH74DGev/9WNu9OZdEPu2gfE8bL/+qOUrBmywEeGvcVAPO/+ZkOzcLZOP0RFLDix19YvGa3aW2LxcI7E97njp7duexwMHT43URGRfPqSy/SJCaGuPheDBsxkvtGDqNRVF0Cg4L4/IsvAfj4P5M4sD+Zt954jbfeeA2ABYlLqVylyrUk3bTfm/ABveK64bjsYNjwu3PX+d33cM+IYdSPrENgYBBfTJuRXee9+/ajaaNoLP7GvfOkzr15v29W7QJRdL3/DUAdEQkF7BgTPYNy2BwGbgEmO3uwJYET+WYtr3EMX0BEflNKlRWRl4E/gAtAWaXUWBGJBSYopdo4Z8cOAQ2UUqeulWZMTDO1dv3GG5/5PNCLEHsHX/5lyd+RNi2asWnTxkJVevEq4apyn3GmbNM+6r1JKdXsWjbOV4gmAP7AZ0qp15x+ZaNSaqFzNv1/QFmMrvsTSqnl+aXn6y1NMAq7Gfjc5dpdQISIpDjPywN9gE/+3KxpNJobQVF+2SmlFmNM8Lhee8Hl8y7A9DiTL49pAqCUOokx3nAPgHOAth/QUClVSylVC+MVgru8lkmNRlOkiJ+YOryBzztNJ+9ydWC2PWBXSrm+KPY9ECUiwX96zjQaTZHjyz+j9NnuuVKqrMvnY0Bpl+CWOWwdgHaYGs3fAG86RDP4rNPUaDQ3L9ppajQajQdop6nRaDSe4Ls+UztNjUbjY4jejVKj0WhMI4AP986109RoNL6Gnj3XaDQaj/Bhn6mdpkaj8T10S1Oj0WjMIrqlqQH+O2m017QHf7HJa9pTh8Z4TRvA34uTsN5e4emvigD+/r5bd9ppajQan0N3zzUajcYsunuu0Wg05jHe0/Rdr6mdpkaj8TH0e5oajUbjEX4+PImmnaZGo/Et9JimRqPRmEePaWo0Go2H+LDP/MvsEXRDWb5sKQ2j6xEdEc64t9/MFZ6ZmcmQQQOIjginXesWHEpJyQ4b99YbREeE0zC6HiuWL/NY++d1q3myT0cev7MdiZMn5Qr/Zt5Unh3YlecHdePVe3tjP7AXgHVLvuL5Qd2yjxHNa3Lol50eaTexleff/erzUf8G9GlULVd45zoV+WJIY8b3jmZ872i61quUHTasuY33+0Tzfp9o2tYO8qzQwMrlS4lpGEnj6Lq8Ny73FsOZmZmMGDKQxtF16dyuFYcOpQCwaUMSbVs0pW2LprRp3oSEBV95rL1i2VKa1I+gYWQd3h2X9/0eNnggDSPr0LFty+z7nZGRQfdbO1M1qByPjHnQY13w7rPmTW1P0XsE+TAOh4OHRj/AoiUrsNpstG0ZS3x8LyKjorJtJn/2KYEBgezck8zsWTN59pknmfblLHbv2sWcWTPZvG0n6Wlp9OjWhe279uLv729K+7LDwRdvP8cTH04nqGowY4f3pEn7rlhr1822aXXbHXTuMxSAzd8tZ8b4V3jsg6m07n4nrbvfCcCR5D1MfPQeataLNl1uP4H/a1OTFxfvJeP3S7xzRxRJh05z5PRFN7s1B07y8brDbtdiqlcgrGJpHpq/k2L+frweH8GmI6e58MdlU9oOh4NHHxrF14uWYbXa6NS2BT3iexIRebXOv5j8GQGBgWzduZe5s2fy4rNPMXnaTCKj67N6bRIWi4Wj6em0adGE7nE9sVjMPcoOh4NHxjzIwsXLsdpstG/dnB7xvYh00Z7y+acEBATw8+59zJk9k+effYovps+kZMmSPP/iy+zauYNdO3eY0sup7a1nzZvaBUG3NH2YDUlJhIWFE1q7NsWLF6ffgIEkJixws0lMWMDgocMB6N2nL6u/WYVSisSEBfQbMJASJUpQKzSUsLBwNiQlmdY+sHMrVavXooqtJpZixWnRtSebv3Pfo75U2XLZnzMvXsjzafpp2QJa3na7J8WmTuUyHD2bybFzmWRdVvyw/yTNawaailsjsBQ7jp7jsoLMrMscPHmeptUrmNbetCGJ2mFhhIYadd673wAWJS50s1mcuIBBg4cBcEfvvny3+huUUpQuXTrbQV7MvOhxa2PjhiRqu9zvvv0HsCjH/V6UsDD7ft/Zuy+rvzXud5kyZWjdpi0lS5b0SPMK3nzWvKntKSLG7LmZwxvc9E4zLc2OzVY9+9xqtWG323PbVDdsLBYL5StUICMjA7s9d9y0NPe41+LUiaMEVQ3JPg+qGsypE8dy2a2cPYXH7mjL7PdfZ8hjL+UKX78igZa3euY0K5Ypzq+/Xco+z/j9EhXLFMtl1yo0kIm9o3nyljAqlSkOwMGM88TYKlDc349yJSw0CC6XHWaGtDQ7Vrd6s5Keo87T09KybSwWC+XLV+BkRgYAG5PW06JpA1o3a8T49/9tupV5RdtW3eaibSMtr/vtol2hvHG/C4s3nzVvanuOua65t7rnhXKaIlJNRGaKyH4R2SUii0Wk7vVj+g5KqVzXct6MfG1MxC2sNkCX/sN55+s19B/1NAs/e98tbP+OLZQoWQpbeD3TuvnmJ8f5hsOnuW/Gz4yZv5NtaWcZ0zEUgK32s2w6coa3bo/ksc61+eX47zjM9cwNncLUOdCseQvWb97Ot2vW8964t7h48WIu2xulXRh8/Vm7UdoFQcTc4Q0K7DTFqLWvgNVKqTClVBTwDFC1qDL3Z2C12khNPZJ9brenEhISktvmiGGTlZXF2TNnCAoKwmrLHTc42D3utQiqEszJY2nZ5yePpRNQqUq+9i1u7cXm1e7d95+WL/S4aw5Gy7JS2autw4plinPy9z/cbM5lOsi6bPzBLN9zgrBKV7een7M1nYfn7+TFJcbEVPpZ847LarVhd6s3O9Vy1HmI1Zptk5WVxdmzZwgMcp9wqhcRSZkyZTwaXzTuZaqLdirBed1vF+0zZ437XVi8+ax5U7sg/F1bmp2AP5RSH125oJTaCqwRkXEiskNEtovIAAAR6Sgi34nIbBHZKyJvishgEUly2oU57SaLyH9E5FsROSAiHUTkMxHZLSKTr2g5bTaKyE4Ryd1nNUmz2FiSk/eRcvAgly5dYs6smcTF93KziYvvxfSpUwCYP28uHTp1RkSIi+/FnFkzyczMJOXgQZKT9xHbvLlp7dCoRhw7fJAT9sNk/XGJ9SsSaNK+q5vN0cMHsz9vW7OKqjVqZZ9fvnyZDasW0aJrT4/Lve/E7wSXL0GVcsWx+AntwoJIOnzKzSaw1NXuevOaAaSeMhyjn0C5EsYkQM2gUtQKKsWW1DOmtZs2i2V/cjIpKUadz58zix5x7mXoEdeLL6d/AcDX8+fSvkMnRISUlINkZWUBcPjQIfbt/YWaNWuZ1o5pFst+l/s9d/YseuS43z3ie2bf76/mz6VDx85F8gfqzWfNm9oeY7KV6a2WZmFmz+sDeS3U2BtoDDQCKgEbROR7Z1gjIBI4CRwAPlFKNReRMcAo4CGnXSDQGegFJABtgHudaTV2OudnlVInRcQfWCUiDZVSP+fMjIjcD9wPUL1GjVyZtVgsjJ/4IT3jbsPhcDB8xEiioqN5eewLNI1pRnzPXowYeQ8jRwwlOiKcwMAgpk6fCUBUdDR9+vWnScMoLBYLE96f5NGMor/FwtAnXmHc6KFcdjho32sAtrB6zP/oXWpFNqBph1tZOXsyO5PWYLEUo3T5Ctz34nvZ8X/Zsp6gKsFUsdU0rXmFywo+XneYsd3r4Sew6pdfOXLqIoNiQkg+cZ6kw6eJr1+V5jUDcFxW/JaZxcTvDAfu7ye80TMSgPOXHIz/9gCXc/fg8sVisfDO+Pfp3bM7DoeDIcPvJjIqmtdefpEmTWPoEd+LoSNGcv/IYTSOrktgYBCfTf0SgJ/WrWH8O29TrFgxxM+Pdyd+SMVKla6j6K797oQPuCO+Gw6Hg6Ej7iYrWGTTAAAgAElEQVQqKppXXnqBpk2bEdezF8Pvvod77x5Gw8g6BAYFMXnqjOz4UXVDOXf2LJcuXSIxYQELFi1zm3m/nra3njVvanuKr7/cLnmNY5iKKDIaCFVKPZzj+nhgu1LqM+f5VGAOcBbD0XV1Xv8eeFoptVZEOgOjlVJ3OFuTK5RS00WkNrBMKVXHGecLYL5S6msR+QeGM7QAwcAopdTMa+U5JqaZWrt+Y4HKW1hmbz1yfaMbxLwtR72m7f1FiL33x3czLkLcpkUzNm3aWKiCl6seoZo+8qkp2+8fabtJKdWsMHqeUpiW5k6gbx7Xr1VhmS6fL7ucX86Rl8w8bLLtRCQUeAyIVUqdcjragr0HotFofA5fbmkWZkzzG6CEiNx35YKIxAKngAEi4i8ilYH2QFG/1FUe+B04IyJVge5FnL5Go/EWf9cxTaWUEpE7gQki8hRwEUjBGJcsC2zDeIvlCaXUURGJKIL8XtHeJiJbMFq7B4C1RZW2RqPxLvJ3Xk9TKZUG9M8j6HHn4Wq7Gljtct4xrzCl1AiX6ykYE07kEZb9WaPR/L3wYZ+pfxGk0Wh8D38/MXWYQUS6icgvIpLs7BXnZdPf+QOdnSLy5bXSu+kX7NBoNL6FMV5ZNE1N5yuJk4CuQCrGa4sLlVK7XGzqAE8DbZwTy/n/wgTd0tRoND6In5g7TNAcSFZKHVBKXQJmAjl/QncfMEkpdQpAKXX8mnnzvDgajUZzYynCn1FaAdeXpFOd11ypC9QVkbUi8pOIdLtWgrp7rtFofA4PeueVRMT1FysfK6U+dk0qjzg5f9FjAeoAHQEb8IOI1FdKnc5LUDtNjUbjUwjGa0cm+fU6vwhKBaq7nNuAtDxsflJK/QEcFJFfMJzohrwS1N1zjUbjW4i5mXOTs+cbgDoiEioixYGBwMIcNl9jLECEiFTC6K4fyC9B7TQ1Go3PUVS/CFJKZQEPAsuA3cBspdROEXlZRK4s87QMyBCRXcC3wONKqXxXndbdc41G41MI4FeEb7crpRYDi3Nce8HlswIecR7X5aZymoq8V6f+M4iLCPaKrre1qw763GvaACdnjfSqvqZg+PIvgm4qp6nRaP4a/G1/e67RaDRFjTdXMDKDdpoajcbn8Pdhr6mdpkaj8Tl091yj0WhMYsyeezsX+aOdpkaj8S28uD2vGbTT1Gg0PocP+0ztNDUajW8h+PZOnvpnlMDyZUtpFB1B/cg6vPP2m7nCMzMzGTpoIPUj69C+TUsOpaRkh4176w3qR9ahUXQEK5Yv81h71YpltGgSTWyjCCa++3ae2vcMH0Rsowhu7dSaw4euau/c8TPdOrelTWwj2rVozMWLF/8y2l2bWNn2QR92TOrHY3c2zBVevVIZlr7UnR/fuYOk9+7ktqY2AAa2D+Ond+/IPn6fO5KGtYI80i7o/c7IyKBb185UDizHw2Me9EjTVbthdD2iI8IZl4/2kEEDiI4Ip13rFrmeteiIcBpG1yvQs+ZNbU8pwqXhipyb3mk6HA4eHvMgXycsZvO2ncyZNZPdu3a52Uz+/FMCAgPYsXsfo0Y/xHPPGCvm7961i7mzZ7Fp6w4WJC7hodEP4HA4PNJ+8tHRzJqfwNoNPzN/7kx+2eOuPf2LzwgICGDDtj3844ExvPTCMwBkZWXxz3uH887ESazdsI0Fi1dRrFixv4S2n58w4b7W3P7qcpqMmUe/drWJsAW42TzZtzHz1h2k1WNfM+y9b5l4f2sAZn6/n5aPfk3LR7/mnonfcej4OX5OOelRuQt6v0uWLMkLY1/m9bfGmdbLqf3Q6AdYkLCELT/vYs7MGbm1P/uUwIBAdu5JZtSYh3n2mScB41mbM2smm7ftZGHiUsaM+pfHz5q3tAuCmDy8wU3vNDduSCIsLJzQ2rUpXrw4ffsPIDFhgZvNooSFDBk6HIA7+/Rl9berUEqRmLCAvv0HUKJECWqFhhIWFs7GDeZ3K968MYnQ2mHUCjW07+wzgCWJCW42SxYlMHDQUAB63dGHH1Z/g1KKb1etIKp+A+o3aARAUMWK+Pv7/yW0Y8Mrsz/9LCnHzvFH1mXmrDlAfPMabjYKKF+6OAAVShcn/eT5XOn0b1eb2WvyXYwmTwpzv8uUKUPrNm0pWbKkR5pX2JDkrt1vwMBc2okJCxjs1O7dpy+rv7n6rPUbMNDtWduQZP5Z86a2p4gYvz03c3iDm95pptntWG227HOr1UZamj0PG2NJPovFQvkKFcjIyCAtzY7NdnWpvhCrlTS7e9xrkZ6eRoj1qnaI1Up6unv89LS0XNonMzLYn7wXEaHfHT3o1DaW98e/Y77QXtYOqVia1Izfs8/tGeexBpVxs3lt1mYGtg8j+X8D+eq5W3nkkx9zpdO3jedOszD3u7DkfF6sVhv2HM9LWpodW/Xc2nZ77rg58+2r2gXhb7nv+bUQEQew3Zn+bmC4Uip3UyH/+J8A77lufnQd+xFAM6WUxwNNeS3gkXOsJD8bM3FvlHZWloP1P65jxeofKVW6NL3jb6Vxk6a079jZ57XzXkrbXat/2zCmfbuPiQt30KJuFT4d04GYh+ZzJUuxdSpzPjOLXYdPmdK8Xpk8tSkIhdL24rNWWO2C4MuvHN2oluYFpVRjpVR94BLwD7MRRcRfKXWvWYdZWKw2G/bU1Oxzuz2V4OCQPGyMbUaysrI4e+YMQUFBWK02UlOvbj+SZrcTHOIe91qEhFhJs1/VTrPbqVbNPX6I1ZpLOzAoiBCrldZt2lGxUiVKly5Nl9u6s23rlr+Etj3jPLaKV1uW1oqlScvR/R5+S13mrT0IwPq9xylZzJ9K5a92i/u19byVCYW734Ul5/Nit6cSkuN5sVptpB7J41mz5Y6bM9++qu0pQpEuQlzk/Bnd8x+AcAARGSIiSSKyVUT+69xeExH5zbko6HqglYisFpFmzrC7RGS7iOwQkbeuJCoid4vIXhH5DmhT0MzFNIslOXkfKQcPcunSJebOnkVcfC83mx7xPZk2dQoAX82bS4eOnRER4uJ7MXf2LDIzM0k5eJDk5H00i21uWrtJTCwH9idzKMXQ/mreLLrFxbvZdOsRz8wvpwKw8Ot5tOvQCRGh8y23snPnds6fP09WVhbr1nxPvYjIv4T2xuQThAeXp2aVshSz+NGvbW0WbTjsZnPk19/o2ND4w6xnrUDJ4v6cOGPM0ItA79ahzCmA0yzM/S4szWLdtefMmplLOy6+F9Od2vPnzaVDp6vP2pxZM92etdjm5p81b2p7jMmu+d+qe34FEbEA3YGlIhIJDMDYW/gPEfk3MBj4AigD7LiyMOiVB1REQoC3gBjgFLBcRO4A1gMvOa+fwVhtOc+mjojcD9wPUL1GjVzhFouF9yZ8QK+4bjguOxg2/G6ioqN5eewLNI1pRnzPXoy4+x7uGTGM+pF1CAwM4otpMwCIio6md99+NG0UjcXfwviJH3o0IWKxWHjznYn0uyOOy5cdDBo6gojIaN54dSyNm8TQPa4ng4eN5F/3jSC2UQQBgYH87/PpAAQEBvLPBx+ia4dWiAhdbu3Grd16/CW0HZcVD3/yIwkvdMPfT5iyai+7j5zm+YFN2bz/VxZtOMxTk5P497/aMqpnNErBfR/8kB2/bVQ17Bm/k3LsnGlN13IX9H4DRNQJ5dzZs1y6dImEhQtIWLSMyKgo09rjJ35Iz7jbcDgcDB8xMrf2yHsYOWIo0RHhBAYGMXX6TMB41vr060+ThlFYLBYmvD/J42fNW9oFwZe753IjFuV1GdMEo6X5KIbjega4sqdwKWCGUmqsiGQBJZRSDmf81cBjGFtt9lFKDXNevweIBr4HertcHw3Uvd6YZtOYZmrtT3nulXTDOZ95Y1/R8FVsw6Z4Vd+bixD78h/+jaJNi2Zs2rSxUAWvEl5fDRg3x5Tth72jNl1nY7Ui50a1NC8opRq7XhDjCZqilHo6D/uLVxxmDq5V+d5Zgl2j0dxQBN/+wvkzXzlaBfQVkSoAIhIkIjWvE2c90EFEKjnHP+8CvnNe7ygiFUWkGNDvRmZco9H8ufiJucMb/Gm/PVdK7RKR5zDGJf2AP4AHgEPXiJMuIk9jjFkKsFgptQBARMYCPwLpwGbgxg6yaDSaPwUR3/7t+Q1xmkqpsvlcnwXMup69Uqqjy+cvgS/ziPM54N1duzQazQ3Bh32mXuVIo9H4Hj48pKmdpkaj8S2Ket/zokY7TY1G43P48qIY2mlqNBqfQsR7P5E0g3aaGo3G5/Dh3rl2mhqNxvfw4Yamdpoajca30BNBGo1G4yE+7DO109RoND6GF38iaQbtNDUajU8hgL8PNzVvKqfpzdVT7KcueEUXILBMca9pp00b4TVtgFvG/3B9oxvEN4+095r2Xx3d0tRoNBoP8OWl4bTT1Gg0PoUxe+7tXOSPL/9aSaPR3IwU8R5BItJNRH4RkWQReeoadn1FRF3Znyw/dEtTo9H4FAJYiqip6Vy8fBLQFUgFNojIwpy73YpIOWA0xgLn10S3NDUajc9RhC3N5kCyUuqAUuoSMBO4PQ+7V4C3gYvXS1A7TY1G42MIfiYPoJKIbHQ57s+RmBU44nKe6rx2VU2kCVBdKZVoJne6e67RaHwK49VA0+a/Xmc3yrxSyt6U0bn1znhghFlB3dIEli9bSsPoekRHhDPu7TdzhWdmZjJk0ACiI8Jp17oFh1JSssPGvfUG0RHhNIyux4rlyzzWXrt6Bb06NiW+XSM+nfRervBN69cyoEc7moYGsmLR125h419/gd5dWtC7SwuWLpznsfbqVcvp2LwB7ZpFMWnCuFzh69f9QI9OLQmtUoZFC+e7hc2ZMZX2sdG0j41mzoypHmuvXL6U5o2jiGlQjwnvvJUrPDMzk5HD7iKmQT26dGjF4UMpABw+lEJIxbK0bxlD+5YxPDL6Xx5rtwgNZMa9zZh9XyxDW1TP06ZzvUpMHxnDtJExjI2PyL5etVwJJvRrwJf3NGP6yBiqlS/hkbY3nzVvanuEyU3VTA57pgKuN9kGpLmclwPqA6tFJAVoCSy81mTQTd/SdDgcPDT6ARYtWYHVZqNty1ji43sRGRWVbTP5s08JDAhk555kZs+aybPPPMm0L2exe9cu5syayeZtO0lPS6NHty5s37UXf39ze7w5HA5ef+5R/jt9AVWDrQzq2ZGOXXsQVvfqH2m1EBuvvPsfpvz3fbe4369ayp4d25i9dC2XLmVyT78etO3UlbLlypvWfu6JMUyft4jgEBs9u7Sha7d46kZEZtuE2Krz7of/478fjneLe/rUSSaMe41Fq9aBCHGdW9G1ezwBAYGmtZ94ZDTzE5YSYrVxS7uWdIvrSUTk1TqfNuUzAgIC2bT9F+bNmcXY55/msy9mAFArNIzvf9pkSisnfgKPdQlnzOztHD+XyafDmvBDcgYpGeezbWyBJRnWsgb/mL6Nc5lZBJYulh32fFw9pvx4mA2HTlOqmB+XPdhI2tvPmre0C0IRLtixAagjIqGAHRgIDLoSqJQ6A1S6ci4iq4HHlFIb881bUeXsr8qGpCTCwsIJrV2b4sWL02/AQBITFrjZJCYsYPDQ4QD07tOX1d+sQilFYsIC+g0YSIkSJagVGkpYWDgbkpJMa+/YupHqtWpjqxlKseLF6dazD6uXL3KzsVavSd3I+vj5ud+qA/t+IaZlGywWC6VLl6FuVH3Wrl5pWnvr5g3UCg2jZi2j3D3v7MfyJQluNtVr1CIyukEu7e++WUG7jrcQEBhEQEAg7TrewnerlpvW3rQxidDaYdQKNbR79+3PksSFbjaLExcycPBQAG6/sw/fr/4GpQq/1X1UcDlST18g7cxFsi4rVu4+Qbvwim42vRoGM29LGucyswA4df4PAGpVLI2/n7Dh0GkALvxxmcysy6a1vfmseVPbUwRjN0ozx/VQSmUBDwLLgN3AbKXUThF5WUR6FSR/N73TTEuzY7Ndbb1brTbsdntum+qGjcVioXyFCmRkZGC3546bluYe91ocP5pOtRBb9nmV4BCOHUu7Royr1I2qz9pvV3DhwnlOncxgw7ofOJpuXvtoehoh1qvawSFWjqWb0z6ankZIiHvcoybjAqSnpWF1qbcQq430HPFdbSwWC+XLV+BkRgYAhw8dpEOrZsTf1okf13r2M8nKZUtw7Fxm9vmJc5lULuf+M9MaQaWoHliKjwY14uMhjWkRarSgawSW4rfMLF6/I4rJw5vyQMdQj17C9uaz5k3tglCU72kqpRYrpeoqpcKUUq85r72glFqYh23Ha7UywWT3XERsGO86RWHsL74YeFQplXnNiCYRkTuAvVfenRKRl4HvlVLmm04FJK/WS86fcOVrYyJuYbXzo3X7W9i5bTPD7+xKYFAlGsXEYvGgu1QY7cLENRtfkbdN1WrB/LznIEEVK7J1yyaGDOjDuo0/U768uWGJvKYFcmbH30+oHliKB2b+TJVyJfjPoEYM+Wwj/n5CI1sFRkzezLGzF3m5VyQ96lcjcftRU9K+/qzdKG1PEXy7NXfdvIlRO/OBr5VSdYA6QCmMd5qKijswHDKQ/S1wwx0mGN+aqalX30iw21MJCQnJbXPEsMnKyuLsmTMEBQVhteWOGxzsHvdaVA0O4Whaavb58fQ0qlQJNh3/vlGPM3vpWv775QKUUtQIDTMdNzjESpr9qnZ6mp0q1cxpB4dYSUtzj1vVZFyAEKsVu0u9pdlTqZYjfkjIVZusrCzOnj1DYFAQJUqUIKii0Z1u3CSG0Nq12Z+817T2iXOZVC13dfKmcrkS/PrbJTeb4+cy+SE5A8dlRfqZixw+eZ7qgaU4fi6Tvcd+I+3MRRwKftiXQb2qZU1re/NZ86a2x4jhlM0c3sCMQ+8MXFRKfQ6glHIADwPDRORBEfnwiqGIJIpIR+fnW0XkRxHZLCJzRKSs8/qbIrJLRH4WkXdEpDXQCxgnIltFJExEJotIX6f9LSKyRUS2i8hnIlLCeT1FRF5ypr9dRCIoAM1iY0lO3kfKwYNcunSJObNmEhfvPtQRF9+L6VOnADB/3lw6dOqMiBAX34s5s2aSmZlJysGDJCfvI7Z5c9Pa0Y1iOHzwAKmHU/jj0iWWJsyjQ9cepuI6HA5OnzK6q3t372Dv7p20an+Lae1GTZpx8EAyhw8Z5U74ag5du8ebituhc1d++HYlp0+f4vTpU/zw7Uo6dO5qWrtpTCwH9idzKMXQnj93Nt3ierrZdI/ryczpxqz8gq/m0a5DJ0SEX0+cwOFwAJBy8AAHkpOpVau2ae3d6eewBZYiuEJJLH5Cl8jKrEnOcLP5fl8GTWsEAFChlIXqgaWxn77I7qPnKFfSQkApY2IopmYABzN+N63tzWfNm9oFQUwe3sBM9zwacJuqVEqddU7P5xlfRCoBzwFdlFK/i8iTwCNOB3snEKGUUiISoJQ6LSILgUSl1Fxn/CvplAQmA7copfaKyBfAP4EJTqlflVJNReRfwGPAvR6UHTDGbsZP/JCecbfhcDgYPmIkUdHRvDz2BZrGNCO+Zy9GjLyHkSOGEh0RTmBgEFOnzwQgKjqaPv3606RhFBaLhQnvT/JoRtFisfD0K+P459A7uexwcMeAoYTXi2TSu68S3aApHW/twY5tm3j4vsGcPXOa71Yu4d/vvc5Xq5LI+uMP7u7TDYAy5crx+sT/YbGYfxnCYrHwylsTGNqvJw6HgwGDhlMvIop333iJBo1juLV7PNs2b+S+YQM4c+YUK5ct5r03X2HVui0EBAYx+rGn6dmlDQBjHnuGgMAgj7TffncifW/vgcPhYPCwEURGRfP6Ky/SpGkzusf1ZMjwkfzj3uHENKhHYGAgn0z5EoB1a3/gjVfHYvG34O/vz7vvTyIwyLy2Q8F7K5MZ368+/iIkbj/KwYzz3Nu2JnuOnmNN8knWHzxFi1qBTB8Zw2UFk1Yf4OxFY1Low28P8P6ABogIe46eY+E2c13zK+X25rPmLW1P8fXtLuR6M5IiMgaoqZR6JMf1rRgOLVwp9aDzWiLwDlDWGXalD1cc+BH4PwwHvBFYhOEoL4nIZNyd5mQgEdgHfKCUau+8fgvwgFKqt9Npt1FK2UWkBfCaUqpLHvm/H7gfoHqNGjF79x8yWzdFyt70c17RBe+up1m2pHffaov7cK3XtG/G9TTbtGjGpk0bC+Xxakc1VK9OW2zKdnBM9U3Xebm9yDHTPd8JuGVKRMoDVYGMHGmUvGICrFBKNXYeUUqpe5zT/82BeRjjmEuvo329yr8yEeUgn1avUupjpVQzpVSzypUqXyc5jUbjfcyNZ/rymOYqoLSIDIPsVUPeBT4EDgKNRcRPRKpjOESAn4A2IhLujFNaROo6xzUrKKUWAw8BjZ325zDezM/JHqDWlXSAocB3nhZSo9H8dbgye27m8AbX1VVG//1OoK+I7MNoXV52vu+0FsNxbsfolm92xjmB8VvOGSLyM4YTjcBwjInOa99hTCiBsfLI484JnzAX7YvA3cAcEdkOXAY+KmyhNRqNb+PLLU1TA05KqSMYM9w4Z7tniEiMUmoTMDifON8AsXkE5Zp2U0qtxeWVI1x+PK+UWgU0ySNOLZfPG4GO1y+JRqP5K+C700AF+O25UmodUPMG5EWj0WgQ0btRajQajUd4q+ttBu00NRqNz+G7LlM7TY1G44P4cENTO02NRuNbGK8c+a7X1E5To9H4HLqlqdFoNKYRn/7tuXaaGo3Gp9Ddc41Go/EED1Zl9wbaaWo0Gp9DO00fQZH3kv5/BmcvZHlFF2DL0VNe044IMrkNxQ1i8ag2XtPOyLEi/J9JxbLeWw6wKBDdPddoNBpzGIsQezsX+aOdpkaj8Tn07LlGo9F4gO6eazQajUl091yj0Wg8QnRLU6PRaEyj39PUaDQa8wi+vQixt/Ym8imWL1tKo+gI6kfW4Z2338wVnpmZydBBA6kfWYf2bVpyKCUFgIyMDLp17UzlwHI8PObBAmmv/34lg25rzsCuMUz7eEKu8JmfT2JIj5YM79mWMcPv4Kj9SHbYsbRUHhnZmyHdWzCkR0vSUw97pP3zj6t5qm8nnujdnsQp/84V/s28aTx31608P7g7r93XB/uBvQCsW/oVzw/unn3c3aIWh/bu9Ej7x+9W0r9rLH07N+WLj8bnCv/y00kMvK0lg+Pa8ODQ20m3u5ft93Nn6dkminfGPu6RLsDK5UuJbRRF0/r1GP/OW7nCMzMzGTn0LprWr0eX9q04fCjFLfzIkcPYKlfggwnveqz97cpltI+tT5umkXw4flye2v8cOZg2TSOJ79KWI4cN7UuXLvHIA/dxS+umdG3bjHVrPN9fcPmypTSMrkd0RDjj8nnOhwwaQHREOO1at8h+zgHGvfUG0RHhNIyux4rlyzzW9hQxeXiDm95pOhwOHh7zIF8nLGbztp3MmTWT3bt2udlM/vxTAgID2LF7H6NGP8RzzzwFQMmSJXlh7Mu8/lbuh9+s9nsvP8E7n8xm6qIfWZk4j4PJe9xs6kY25JN53zAlYQ0db+vFf8a9mB326pP/5K57RjFtyXo+nrOSwIqVTGtfdjiY+vbzPDJxCq/PWsn6ZQuzneIVWt12O6/OWM4r05fQY+g/mDHhVQBad7uTV6Yv4ZXpS7j/pfFUCrZRs260R+V+Z+zjjP90DjOW/sTyxHkc3Ode7npRDZn89TdMX7SWTt168eFbY93C/zvhdZo0b21a01X78YdHM+frRH7avJ15c2axZ7f7/Z46+TMqBASyeccv/HPUQ4x97mm38GefeJQut3YrkPZzj49h6pyFfPvTNhbMm8XePbvdbGZO/ZwKFQJYu3k39/1zNK+PfRaAL6d8CsCqdZuZ8dViXnnuSS5fvuyR9kOjH2BBwhK2/LyLOTNn5H7OP/uUwIBAdu5JZtSYh3n2mScB2L1rF3NmzWTztp0sTFzKmFH/wuFweFx+j/Bhr3nTO82NG5IICwsntHZtihcvTt/+A0hMWOBmsyhhIUOGDgfgzj59Wf3tKpRSlClThtZt2lKyZMm8kr4uu3/ehLVmKCHVa1GseHFuievNmlVL3GyatmxHyVKlAYhu3IzjR9MAOJi8B0dWFrFtOgFQukzZbDszHNi5laq2WlSx1sBSrDgtbu3Jlu9XuNmUKnt1V+XMC+fzHGdav3whLW7tZVoXYNe2Tdhq1sZawyh317jefL9ysZtNTKur5a7fOJbjR+3ZYXt2bOXkr8dp3razR7oAmzYmUTssjFqhxv3u3bc/ixMXutksWbSQu4YMBeD2O/vw3epvsn9JtmjhAmqGhhIRGZUr7euxddMGatUOo2YtQ/v23v1ZvjjBzWb5kgT63WVox93emzXffYtSin2/7KZNe+NeV6pchfIVKrBtyybT2huS3J/zfgMG5nrOExMWMNj5nPfu05fV3xjPeWLCAvoNGEiJEiWoFRpKWFg4G5KSPC6/J4jJf97gpneaaXY7Vpst+9xqtZGWZs/DpjoAFouF8hUqkJGRUWjtE8fSqVLNmn1euWoIvx5Lz9d+0dxptGzfBYAjKfspW74Czz44jJF3dGDSWy949O1/6sRRgqoGZ58HVgnm1ImjuexWzpnC43e2Y/YHbzD40Zdyha9fkUDL2243rQvOcgdfLXeVaiGcuEa5E+ZMpVWHrgBcvnyZia8/x6gnX/ZI8wrpaWlYrdWzz0OsNtLT0txs0lxsLBYL5ctX4GRGBr///jsT33ubJ595oWDa6WkEu2hXC7GSnu7+rB1NSyPYanPRLs+pkxlE1m/I8iUJZGVlcfjQQbZv3UKaPdW0dlqaHZvtqrbVasNut+e2qZ77Obfbc8fN+TdS1IiYO7xBgZ2miDhEZKvL8VQB0hghIh9ex6ZXQdI2S16/Rc+5qZMZmwKK576WT7rLFsxmz44t3HXvKAAcWVn8vPFHHnjyZT6eu4r01BSWzP+yUNJ59Xe69BvOuK9+oN+DT5Hw2Un3lI0AACAASURBVAduYft3bKFEyVLYwuqZ1jW0zZd7ydez2L19K0Oc5Z437RNad+xK1RBbnvYF0c51L/OxefPVsfxz1EOULVu2QNr5petmQt42A4eMIDjESo9OrRj79GPENG+JxeLvgXQhnvMb9fxfAx/unRdq9vyCUqpxkeUkH5RSC4GF1zUsIFabDXvq1W9suz2V4OCQPGyOYLPZyMrK4uyZMwQFBRVau3K1ELdu54ljaVSqUi2X3cZ1q5n60bt8MC2R4sVLAEbrrE5UQ0Kq1wKg7S1x7Nq20bR2UJVqnHRp3Z06nk5g5ar52re4tRdfvPWc27X1yxM87pqDkffjLi2s40fTqJxHuZP+v73zjq+yWBrwMyFUEUhEIAUl9CTUEEAEpapAElBRikhXBAsq9vIJ4r1eBRUQKyqKqHQE6RYsV6/SBQQvGgSEBEThCgpCIMz3x27CSUjwJDknOZB98ju/vGXfM/u2ObO7M7NffcZbLz/Hy+8tolRpc96bvl3NhtVfM/fdN/jryGGOpx2nbLnzuO3+0V7JDo+IIMVjMC01ZTfVwsJyLBORcb8PHSQkNJQ1q1ex4P15jHrkQQ4e/J2goCBKly7D0OG3eSU7LDyCPR6y96amUK1aeA5ldhMekSH7EJVCQhERRj/5TGa57le2JapmHa/kgrEOd+8+JTslZTfh4eGnl9l1+nMeEXn6sdnfEV8iBPZslD5tnotIRRHZKiL17Pp0EbnZLncWkXUiskFEPsnh2CQRWSki60XkYxGpardnWqMi8paIvCwin4rITyLSVkSmiMj3IvJWfurcLL45yck/smP7dtLS0pgzayYJiVkVQdfEJN6ZNhWA9+fOoW27Dj65qfUbxrF7x0+k7trJ8bQ0Plk8jzYdsg4w/LBlI+MeG8m/Xn6PkAsuzHLsHwd/538HfgNg3covqFHbe4svKqYxv+zazq8pP3PieBorP1xI08uuyFJm78/bM5c3fLWCqlZBg2kmr16xOF9KM7pRHLt2bss8748Wz+Oyjl2ylNm6eSNPP3o34159j1CP8x7z3Gss+Pd3zP98I3c8+ARdr+nltcIEiGvWnG3JyezcYe73vDmz6JKQlKVM565JTH9nGgAL3p/L5W3bIyIs/fhzNv53Gxv/u43ht41g5H0Peq0wARrHxbN9WzI/7zSyF8ybxRVdErOUuaJzIrOnG9mLF8yj9eXtEBH+OnKEI4cPA/DFpx8THBxM3frRXsuOb571OZ89c8Zpz3lCYjfetc/5vLlzaNvePOcJid2YPXMGx44dY8f27SQn/0jzFi28lp1nvGyaF5VeLYilWVZEvvVY/5eqzhSR24G3RGQiEKKqr4nIhcBrwOWqul1EcjLTvgQuUVUVkZuA+4F7cigXAnQAugELgdbATcBqEWmiqt/mcEyuBAcH89yESXRL6Ez6yXT6DxhETGwsY0Y/RlyzeBKTujFw0BCGDOxPg+g6hISE8vY70zOPr18nij8OHSItLY2FHyxg4eLlRMd4N0gQHBzM3Y+N5Z6bruNkejoJPfoSVSea1yc+Sf0GTWnTsQsvjR3FX0cO89idgwCoGhbJU6+8R4kSJbjtgTHcNeBqQKkb24Sk6/t7fd4lgoO58b4xPDOiPydPpnNZUk8iatVl3qvPEhXdiKaXX8Ens6eyedWXlAguyXkVKnDzqOcyj9+6fiUhVcKoEnGR1zI9z/veUWO5c1APTqank3h9X2rWjWbyhCep36AJl3fqyqSnH+PIkcM8csfAzPN+ZvL0M3+xl7LHPjeRHt26kp6eTt/+A4mOieXJMaNoEhdP18Qk+g0czLAhA4hrUI+QkBDeeNv7bo+/k/3E2An07ZHIyfR0evUdSL3oGMY9+TiNm8RxZdckevcbxJ3DBtE6LppKIaG89IZRoL/9to++PRIJCgqiWlg4E1+ZkmfZ4ye+QFLCVaSnpzNg4ODTn/PBQxg8sB+x9WsTEhLKtHdnABATG0uP63vStFEMwcHBTHj+RUqU8L5rID/4Uh+KSGdgIlACeF1Vn8q2fyRGh5wAfgUGq+rOXL8vv/klReRPVc2xc0dEJgM9gMaqultEkoDeqto3W7mBQLyq3i4iDYFngTCgFLBdVTtnK/MW8JGqvisiNYHlqlrHftfbwDxVnZ9NxlBgKED1iy5qtjV5R77Ot6Cs3f57kcgF2HbwjyKTXdT5NOuFn//3hfzE4WN+dss5A0WVT7N1y3jWrl1TIJ0X06ipvrPQOz/UZjUqrlXV+Nz2i0gJ4AfgCmA3sBroo6pbPMq0B1aq6hERGQ60U9VeuX2nz0fPRSQIiAb+AjIsSoEcerizMgl4QVUbArcAufnxHLP/T3osZ6yfZjmr6mRVjVfV+MqVL8y+2+FwBBzeOhx5pZtbAMmq+pOqpgEzgCzuHqr6qaoesavfAGccZfSHy9HdwPdAH2CKiJQEvgbaikgUQC7N84pAxujAAD/Uy+FwnCX4sE8zAtjlsb7bbsuNIcDSM+z3aZ/mMmAKpm+ghar+ISJfAI+q6ijbTJ5nLdF9GHPZk9HAbBFJwWj7qALUzeFwnKWY0XOvi1cWEU+3kcmqOjnb12UnZ4c7kRuBeKDtmQTmW2mqam49wdEeZUZ6LC8lmwZX1beAt+zyAiBriMLpZQZ6bN8BNPBYH4jD4TgnyEO0z29n6tPEWJbVPdYjgdTshUSkE/AI0FZVj2Xf70mxjwhyOByBhw+b56uBOiISJSKlgN5k8/sWkabAq0A3Vd33d1/olKbD4Qg4fBURpKongNuB5ZixllmqullExohIhqPqOKA8pnvwWxE5YzCNy6fpcDgCCx/HSKrqEmBJtm2PeSx3ysv3OaXpcDgCCjNHUOCGUTql6XA4Ao7AVZlOaTocjkAkgLWmU5oOhyPgcLNROhwORx4I4C5NpzQdDkfgEcA60ylNh8MRWAR6EuJipTS3pByiyaP+n340J5bd165I5AI0iCy69GxHjxddejSAMiX9m/cxUGUfP+H9TJW+JH+JJrNRhAmGvaFYKU2Hw3F2EMA60ylNh8MRgASw1nRK0+FwBBhFN6e5Nzil6XA4AgoTRlnUtcgdpzQdDkfg4ZSmw+FweI9rnjscDkceCGSXI5eEGLisbmWW3XsZH953GTe3O31qoocS6zP/zkuZf+elLLv3MlaP7ghAeKUyzL2jFfPvvJRFI1vTu2X10479Oz7/5EM6XtKI9s1jeXniuNP2r/rPlyR1aEWdauVZ8sG8zO1bNm2gR5e2XNUmji5tm7Po/dl5lv3xh8to3iSGuIb1GP/M06ftP3bsGIP79yGuYT06tW3Fzzt3ZNm/a9fPRFapyKQJz+ZZ9oqPl9MmvgGtmkYzafzp533s2DFuGdSXVk2j6dqxDbus7OPHjzNi2BDaXxrHZS0a8fxzY/Ms+8Ply2gUW4/Y+rUZN/ap0/YfO3aMG2/oRWz92lx2aUt27tiRuW/c0/8itn5tGsXW46MP8+7zW5SyP/pwGXGNomkcW5fnxuV8vwfe2JvGsXVpf1krdtprvmb1Klq3jKN1yzgubdGUhQvez7PsvOKrJMT+oNhbmkECj10dw6DXV/PLwaPMub0VK7bsY9u+w5ll/rXov5nLN156ETHhxln81z+O0fulbzierpQrVYKFd7dhxZZ97PvjjFOMZJKens6oB+/i7dmLqRYewdVXtqFT50Tq1MucZonwyOqMnTSZ11+akOXYMuXK8cwLbxBVqza/7E2lW8fWXN7hCipUrOS17PtGjuD9hcsIj4ikw2WX0CUhifrRMZllpk2dQsVKIazbtJW5s2cy+v8eYsrb0zP3P/LAPXS6srNX8rLLfvjeO5k5fwlh4ZF0aX8pV3ZJpF79U+c9fdqbVKxUia/Xf8/8ubP4x+hHePXNd1k4fy5pacf49D/rOHLkCG1bNuGaHj2pfnENr2XfNeI2Fi/9iIjISNpc0pzExG5Ex5w677emvEFIpRA2/zeZWTNn8MjDD/DOezP5fssWZs+cwboNm9mTmkrXzp3YtOUHSpTwzom9qGXfc9cdLFi8nIiISNq1aUnXxKz3++23plApJIQNm39gzqwZjHrkQd56ZwYxsQ34/KtVBAcHs3fPHi5t2ZQuCUkEB/tJfQS4c3uxtzQbVa/Ezv1H2H3gL46nK4s37KVjTNVcyyc0CWPRhj0AHE9XjqebGIhSwUEE5fFqbli3motr1OKiGlGUKlWKxKuv56Oli7KUibzoYqJjGxIkWb+8Zq06RNWqDUDVauFccOGF7P/tN69lr12zipo1a1EjqialSpXi2ut6smRR1iz/Sxd9QJ++/QDofk0PPv9sBarmfBcvXMDFNaKyvHTesn7tamrUrMXFNYzs7j16snzJwixlli1ZSM8+RnZi92v59+efoqqICEcOH+bEiRMcPfoXpUqVpHwF7yOeVq9aRa1atYmqaWRf36s3ixZmnc9v0cIF9O1nZpG+tsd1fLbiE1SVRQsXcH2v3pQuXZoaUVHUqlWb1atWnRWy16xeRc1atYiy97vH9b1YnO1+L160gD59+wNw9bXX8Zm93+XKlctUkEePHfV7iGNGGKU3n6Kg2CvNqhVLs/f3vzLXfzl4lKoVS+dYNrxSGSJDyvJN8v7MbdUqluGDu1rz2UPteO2z7V5bmQB796QSFnFqXvqw8Ah+2ZNyhiNyZsO61RxPS+PiqJpeH7MnNZWIyFPdCeERkezZk3WSvlSPMsHBwVSoUJED+/dz+PBhJj43lgcefoz8sHdPKhERp2SHhUewN9t5792TSri9NkZ2BQ4c2E9i92spd955NK53MfENajPsjrsJCQn1WnZqagqRHucdERFJSkrK6WWqe5x3xYrs37+flJTTj01N9f5+FaXsPdlkh0dEkJpN9p7U1MwynvcbYPWqlbSIa0ir+MZMeP4l/1mZlkBunvtcaYpIGRFZJSIbRGSziDyeQ5kaIvKXiKwXke9t+QFefHc7EbnUp/XNYZvmEkCb0DiM5Zt+4aTH/r0Hj9JtwldcOfYLrmkWzgXlS3kvPAdBef313Ld3DyNvHcLY518lKA+mrnolO+cyT/1jNMNvv4vy5cvnqa5nlJ3tTuRWv/VrVxNUogTf/ncHqzZs5dUXJrBzx08Fky3eyS7o/TobZWe0k5u3aMmqdZv47MuVPDvuaY4ePeq17Pzgw9kofY4/LM1jQAdVbQw0ATqLyCU5lNumqk1VNRozrebdIjLob767HeBTpbn34DGqVSqbuV61Yhn2HcrZWuzaOIzFtmmenX1/HOPHX/4kPirEa9nVwiPYk7I7c31PagpVqoV7ffwffxxiyA3Xcs9Do2ga39Lr48BYGim7d2Wup6bsplq1sKxlwk+VOXHiBIcOHSQkNJQ1a1Yx6tEHaRRdi5dffJ7nnnmKya+86LXssPAIUlJOyd6TmkLVsPDTyqTaa2NkHyIkJJT358ygfccrKVmyJJUvrELzlpeyYf06r2VHRESy2+O8U1J2Ex4efnqZXR7nffAgoaGhRESefmxYmPf3qyhlh2eTnZqSQlg22eEREZllMu53aGhWK75e/WjOO+88tmz+zmvZ+UG8/CsKfK401fCnXS1pP2dMfqKqPwEjgREAIhIqIvNFZKOIfCMijUSkBjAMo1y/FZHLROR6EfnOWrVf5Ke+m3YfpMYF5YgMKUvJEkJC42qs+P70qY+jKp9HhbIlWb/z98xtVSuWpnSwuYQVygYTd3EI2389fNqxudGoaTw7tieza+cO0tLSWDR/Np06J3h1bFpaGsMG9OKanjfQtXsPr2VmENesOdu2JbNzx3bS0tKYN2cWXRKSspTpnJDE9HenAbDg/blc3rY9IsLSjz5n4/fb2Pj9NobfNoKR9z7I0GG3eS27SVw827cl87OVvWDuLK7qkpilzFVdEpk13chetGAebS5vh4gQEXkRX33xGarKkcOHWbtmJbXr1PNadnzz5iQn/8iO7Ub27JkzSEjslqVMQmI33p02FYB5c+fQtn0HRISExG7MnjmDY8eOsWP7dpKTf6R5ixZnhexm8c35KTmZHfaaz509k67Z7nfXhG5Mf/dtAObPm0Nbe7937NjOiRMnAPh5505+/GErF3s58JZvArh97peOCREpAawFagMvqupKLw5bB9S3y48D61X1ahHpALytqk1E5BXgT1V9xsrZBFylqiki4t2wcTbSTypjFmzh9SHxlAgS5q7eTfIvfzLiitp8t/sgK77/FTADQEuyWZm1qpTnwYT6mQMUU77Yzg97/8xJTI4EBwcz+l/jGdAziZMn07m+zwDq1o9h/FNjaNgkjk6dE9mwfg3DB/Ti4MHf+eTDJUwc+w+Wf7mOJQvmsvrrL/n9wAHmzngHgHGTJhPTsLHXssc+O5Ee3buSnp5O3/4DiY6J5cknRtEkLp6uCUn0GzCYYTcNIK5hPUJCQnhj6nten9vfyX5y3AT69EgkPT2d3jcOpF50DGP/+TiNm8ZxVdck+vQbxB23DKJV02gqhYTyyhSjQAfdNIy7bruZdq2aoqr07tufmAYN8yR7/MQXSEq4ivT0dAYMHExMbCxjRj9GXLN4EpO6MXDwEAYP7Eds/dqEhIQy7d0ZAMTExtLj+p40bRRDcHAwE55/0evR60CQPW7881yT1IX09HT6DRhEdEws/xgziri4ZnRN7Eb/gYMZOrg/jWPrEhISypvTzP3++j9fMv6ZsZQsWZKgoCCem/gCF1Su7LXs/BDAg+dIjv0Yvvpyo8jeB+5Q1e88ttcAFqlqA49tIUCqqpYVkfVAD2uBIiK7gAbA3WRVmq8AtYBZwDxVPTVCc+p7hwJDAYIrVGlWc9hUf5zq31KU+TRDypUsMtlFnU+z0nl56GM+hyiqfJptW7dg3do1BdJ5TeKa6Uefe2NnQZUKJdeqanxB5OUVv46eq+rvwGdAgm1Sfysi3XIp3hT43i7nOD6Tw/cPAx4FqgPfisgFOZSZrKrxqhpfomzF/JyGw+EobAK4ee6P0fMLM5rKIlIW6ARsVtUm9vNBDsfUAJ4BJtlNXwB97b52wG+qegj4Azjf47haqrpSVR8DfsMoT4fDcZYTwDrTL32aYcBU268ZBMxS1UU5lKtlm+FlMMpwkqq+afeNBt4UkY3AESDDHWkhMEdEugN3YAaF6mCu3yfABj+cj8PhKGQCOSLI50pTVTdimtpnKrMDKHuG/QeA7jls/wFo5LHp3/mrpcPhCFxcEmKHw+HwGhNGWdS1yB2nNB0OR8DhlKbD4XDkAdc8dzgcDm8J8NRwTmk6HI6AoijdibzBKU2HwxF4BLDWdErT4XAEHEEB3D4v9kmIHQ5H4OHLiCAR6SwiW0UkWUQezGF/aRGZafevtBGKueKUpsPhCDx8pDVtZOKLQBcgBugjItnnaBkC/E9VawPjgdNnnfPAKU2HwxFw+DAJcQsgWVV/UtU0YAanRxt2BzLSn80BOsoZ0uL7NTVcoCEivwI783l4ZUxSkKKguMouavlOdt65WFUvLIhwEVlm6+ANZQDPuTcmq+pkj++6DuisqjfZ9X5AS1W93aPMd7bMbru+zZbJ8RoUq4GggtxMEVlT2Hn7irvsopbvZBcNqpr3eaFzx5s0k16loszANc8dDse5zG6ypoyMBFJzKyMiwUBF4EBuX+iUpsPhOJdZDdQRkSgRKYWZxDF7Tt8POJV+8jpghZ6h37JYNc8LyOS/L+Jkn2PyneyzHFU9ISK3A8uBEsAUVd0sImOANTYp+hvANBFJxliYvc/0ncVqIMjhcDgKimueOxwORx5wStPhcDjygFOaeUREqhR1HRwOR9HhlGYeEJFI4EkR6VmIMoPtf3evPBCRmna2U0chcKYImeKGexHzxgmMC0N7EUn0tzARaQM8LyJRqnrSY3tAPMCe9RCR8wpRbmXgLuARESlTWHJzqUuhv0OFff9FRDJccETkZhHpUJjyAw2nNPOAqu4F/gIqALeISBc/i+wHDAPeFpH7bUgYHg9wkSnPbC/ScIxyv09EaheC+APAfKA8cJeIlC4EmachIkGqelIM4VaZ+x2P636DiIwRkRh//nh4yLsHuImiDastcpyfZh6wymEAMAnoCFwjIqVUdYGfRD6KUdI/AweBESLSCXgP+EpV0/0k92/xeJGGAjcAN2N84eqJyNuq+oUfZZ8UkerAhUAb4KSITFLVv/wlMzsiUkJV0+0P1xfAIeCwiLyhqsv9JNPzh6onxtpeg8nKM1VEPlLVgz6UF5TRwhGRCOAqoD0QJCIJQDXgHVU95iuZZwNOaXqJiJQEYoEHVPVzEfk30APoZ5/l7FEG+ZVzEbBfVQ8DaZi42EOq+oaI7AdmY+aMHy8iPVV1my/k5qOeQcAFQEPMdegJ/AQcBu4QEfylOEWkF3APRlknAmHASBF5prBeYA+FORD4GPNDmgQ8aJXNUl/Ky6Yww4DzgIGqukVEbrayVUQ+UdXffSCvEhAObBGROEyr9HxgDOZ6nwDa2u2vFVTe2YRTmrng+ZACqOpxEUnDWHurVPVnEfkE6AV0EpEVqvpnAWVWxSiDXSLyiqoeFJG5wLMiUgHTNOqtqnNF5J8U8qQAntfEWiC/isgDwMVAd1VtLyLlge+BTTbxwxFfyreL4cAMVf3OZqTpCtwOlBCRsap6NNcv8VE97HUYA9wCDFbVAyIyBzgO3C8iZVV1no/keVp8I4A7gHRgHXCDqr4mIieBvsAJEfngTGGAXlIPaGvvb7SqthCRJ4H6wFv22g8FYjKs7gLKO3tQVffJ9sFGStnlVkAHu3wRMBZ4EqOwumLy8FX2kdwg4EbgOWAEUMFufwzTj5dQ1NfG1qc/MAFoCZQGagFbgZrAlRhrONzX98JjW0fgG6C5x7YF9rr55F7kUpcSOWx7E1jqsV4O8+P2sI9klvJYbg28i7H0YoDPgHHZ7ouvrntJ4B1Mt8PtOewfAmzBKNQifyYL8+PCKD3Ibl2KyF3A9ZgsKGWAxzGDDwOBupgmUn9V3VRAuXWAIFXdaq2pRIzyScY0fZoA41W1pS2faXkUBtmahtcADwArgKbAdGAhMBhzrUoDfVV1i4/l9rLyNgPbMRbPpcBczAs+FNNc3VdQubnUJaMPMwjzHBwCNqvqEhF5D/N89FQT61xKTcLbgsqsh8k4/gKm//ANu2uAqu61g26vAj+o6nAfyMv+/DcBrsB0w2zEWPcnbXP9/4BHfHGfzzac0vRAREqq6nG7nIDpv7zcNlHuBD4CxqoJ+A8Djqrq/woo8wLgV8yI5OOYZtdkTH9dFCYN/wsiMgvT11nglyOP9fNUXDUw1s5WVV0jIn0w1vYy4EOM4jiuxsvAl3UYjvEieBOjLI8D64EjmAGoI8CjqrrBl3JzqIcAn2IsrP2YdGKpqvqwbZpfAHT01Q+aiDTC/GCHYQYDGwN3A+8Dy1X1V6tYn8X8aP2q+Xyhs93nfpj+S1HVF+31j8bc4wsw13+x+nDQ6WzC9WlaROQKYLCIbMCMSH4CbBSRwUA7TB6+pcAUEblZVTf6Qq6q7rcj4h9jmueNgZnAn5iBoCYichwYB6T4Qqa3ZHuRbgPuw1hYe4CrVHW67UvrA5xU1ek+khsL/Kaqv4iZ4yUGY0WuF5EoIAGIUNUnRGQRcEL91I8pIq2AjWoG5moDe1T1VruvBjBGRC5X1etE5F5ftgBUdaOIhAK3Ascw1t3LGAUZJCLLbevkmowf+wLIyrjPN1l544E7reIegek26oZpASUUV4UJzk8TMLPVAf8E/oNtcgMNVHUXZsT8A/syfADsA3xqSanqCow7x62YAY2RmP6qizAuHrcCP6pq9uSpfsXjRWoDXILpw+yCGWx43ZaZCbwNfO4Lmbb52wdIF5EyagYYymAsfVR1O8bKbCUi56nqn35UmM2A+qp62A7EHccENrS0ddmBeR5i7foz9rh8D9BlP1ZVD2Ca5ScwSvNr4HVMV0gH21VTIIXpIbsM5jl8QFWnqcneXhd4WlXfAO4F4lV1sy/knbUUdadqUX+AUOAkkGTXq2MsvWvtem+M1TkJoxii/FiXBOAHINSuhwBVgBqFfE0yum3EXo9FmGZpLbu9GmbgZaaP5QZ5LLcA3rKy6mMsn0ftvm7AEqBiIV2PkcBtdnkIpg+3lV2fC4zw5XW3y4OA2zAj4oJRzM9iBiHLY9x9Igoor5a9zi2ASLvtBaCPR5lIjF9wcGE+g4H8KfaWpppf8iTgKRGpoMa6PI5xnAajKCdgEpgOU2Pp+KsuizEW1TcicoGq/k9V96mxaAqFbIMBQfZ6/B/GouokIuFq+iyH2/JhPpLr6VZzDWZwpzzwIOZHbRHQTEQ+BkYBD6mfmohi4tor2uVGmP7Llrav79+YaKRZIvI+kKaqz/tCbsZ1F5G7MUEUBzCtjHEYN67XMX2K9wBfqGq+u2tsn/0s4GHgCWCZiDTG9JfeKyLNxWQ6b4v54SqZX1nnHEWttQPlg2l2/oj5pZ0HlC3CunTHNEGDirAOIzEv0ChMN0ETjMUxDKhuy5zmguMDua0wVqxguo/ew1iZ4Xb/RVhL3E/nXQ4zuDQaWAmMsdt7Yroh+tn1qnhYegW5V5g+29Z2uS7G1ScYo9CWA9MwP9xBGKu7agHPsQvGZaudXS+LiS76E+M21hvTfz/dXoMGRfUcBuKnyCsQSB+gE8aqqWLXi1Jxli9keZ5NwxiMZXct8AjGsorCDFItxDRRfaowrZJsY6//XR7by1hl9Q4Q5udrEGT/1wV2WIVR3WP/9bYew4Hzc7p2+ZBZFjPANhUzbSyY0fIuwJeYFk5PW59nfXCOUfYa97frwR777rHKNBioYT8+8fs8lz7Fvnnuiap+jOlX/FREqmghxjLnUJcCRRflhWyj5G0xL+wHaiJaJmOapM9iQiQfApapDyJAPAc91PAlpu84M3uRmkGeW6xsv/nHWT/Mk3a0vhLGol6DCZONs3WZjXG7Oamqf3jW9j5JUQAAB8xJREFUPZ8yxT5jC4ENwBARuURV92D8XVfoqYGwKRiLu0Co6V4ag/EUqafGrzTDi2YqZpS+rqrusJ9CHXw8G3B+mjkgIt0xzdJ47PtcxFUqFERkIMYP8CBGQfVR1VTrSzocY4H2V9UTPpDlqah7AJWB71T1KxF5AeNUHe+pnPxFRl3syP1c4D+qOs4GHTyA8ZFcjGm2j1fVrb6SaZfLYhTjEKAOpu/yEMb/9WOMm09HVU0uqFwP+Q9hWhI3qOqPHtdgPiaaqdg5rXuLU5q5ICLlC9PaK2rEpLm7E+NFcFxEMkLo/qmqKdZfEDUDZwWRkz3qZCRmIG4xpi/tCVVdICKTMK5HF6vxkfQ7IjId2KKqT9j1KsBRTP9mTYw/6HU+lnkHxg/4Osxo9tWYuO8nMIEO9YEd6ofELCLyMKcU5w/2R/MWzDNQrNO/nQnXPM+Fc11hejaNxeSjjMKEJXazm2/GRIU8JSJhqnqgoArTkhlQYRVxU1Vtj+ln+xUzihukqndwyuXIL4hHAmExuTArAGtEpL+ITAY2YZzqRwK3ZCjMgvhhZpM/CDNK/rDtnkjG9B9/j0n3Vk1VPymIwhSRWBFpKx7TtHjU/2lgBvCatTyHAjc7hXlmXERQMSRb07Aixm3mJRvdM1BE/lTV5SJyCzARH/UlStaoqw2qulRETtgmYTDQzVq5A0TkC1W91xdyc6lLZmYeMRmJfhORFzGx3FMxg08vAPeISGlV/cWWzWIp51Fm9mMjMfHbW20d/lLVZBGZjbEyC9SfaFsPT2NS9pUUkaGqmmKb4XFW/gSgInA/0EaLu+O6FzhLsxjioTDvxSiH/4hJavsNJkPRrSKSqKpHVPVm9UEseQ5RV71EpAVm+pBqwJNWYQ7EvMB+SzVmlVe6iASJiel/SkReBrYBDVU1I/LmbuCgeuToLEj/tsd1b2AHnMpjrnWpjEFHEbkBc+7P2wGh/J5jO8wP3k2qejUmJDfa7muBcev6Q1VP2POt7RSmd7g+zWKEmLDAEpioozjgKYybVRdMuOZqYA6mydgaE+N8pKADYbYZ/hsm5+ZCMVnXn8Eo7E2YsNVETLO0OdCrMF5gEVmAifbaBLyC8VVchnEDmoZRKgNtWZ9YmNZZ/p+qmiQmf+r9GIX2JOYaPIiJRitQH6aIRGOa95+KSDVM7s1VmAQgvwBrrKWf7/MqtmgA+D25j/8/GFeqDRiFGIlJnjzNY/8VmJyYtTCWYCU/yN/MqRyh7wJD7fL5QAOMY3ukH6+BZ5hmOcyPxvmYkMx77PYozEh+05yO80EdSmCs+RiMcm5lr8VHmGkzfO5IjvG1zQhBvQnzY1XZrufbx7S4flyfZjHA+l5OxOS5XGm3bQW6ikhLVV2pqh+JyFeYaBOfj9Sq6mLbZ7pWRJZjFMY7dvefqvqdr2XmUIeMMM1wNa5U1TGZox5S1RdtsSeA11X1M1tWNJ+Zi6xlX1JVvxGTPaiZ3VUKqKfGredr4GvrK1lG/TAAqar/9Fh+XUyY6kWYTFLOyswjTmkWD5oBk1R1pYgEq/Gz3I5RGNeKyGWY5nNbjH+qX1DTHByOcRCvpqpHxGQy8uv0FJDFF/NhoLaIjAZesrtDrS/qq8DhDIVp65zfJnkX4B+YxBtg+ov3YSz5NsDLVnmFYnwxn/eHwszBxasHpg/ZOa3nE9eneQ7joSgmYQY0HrXuJqIm+iUEk0mnBiaM8TktnL7ELpg+zfbqp0zrHrKC1US9ZFyLC6zsfZjY6tKYGO/fMEmlb7PHFaQPszMmycnjqvqhdWcqrTbBhogMAzpgAgY6A5+qnyNvrFvZjZicAr0Kw7I/Zynq/gH38f8H84J+DDSz60HYmGPMCHFdzEtdmHXqjhmcCKIQ+tUwjvvxdjkU4wP6IjbPQLayBUm+kZFq8Gq7XhsThtrWo0wzYEohX++SmCz79QpT7rn4cc3z4sFKTPKHXmKm1l2LmSu8N9APmKOFPHe1mqifT9RPcx2JyFOY9H7BmOw9ezBx5GlqMqKPxCjt80XkfrVuVQXpwwQTMSUiScATIvITJmZ/vqp6Jmk+iJkfvhJmema/z/ekJlHxEn/LKQ645nkxQUQiMLHNHTGuRUcxoXvX6TnWVBORNzF5J5/HeAL8C9OnuBmIwAz0bLFRP9tU9Wk/1KEzRkk9rKpPyamJ2bpg5jRao4UUHurwLU5pFiPEJIZohvHN3IPpS/uhaGvlW2zU0X2qeqXHtuqYLEH7MYNQgzEO5BtUdYQt43N/RVuXScAlqvq7ddy/FdOn6Ldk1g7/4pSm45zCKqo+qjpYREpiBsBPiEg4xvK7CxMWWktVp9hj/ObgbS3LsZiR+hsw2f9d5M1ZjOvTdJxr7ALixOSl/AZAzARsqSKyEditJjHG53afX+eQV+NmVQIzG0BTpzDPfpyl6TinsC5V92N8Eaeq6rce+5Zi0t1NBZb6y7rMpV7lVPVIYclz+A+XsMNxTmEV4duYTO+PiMhgEWkoZhK0sphpI7YVpsK09XIK8xzBWZqOcxKbJORKYAQm5v6Iqt5TtLVynAs4pek4p7Fp19I81v3ah+k493HNc8e5zvGMhYI6rjsc4CxNh8PhyBPO0nQ4HI484JSmw+Fw5AGnNB0OhyMPOKXpcDgcecApTYfD4cgDTmk6HA5HHvh/WfVcl+XOKg8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create confusion matrix and classification report\n",
    "for_report = model.predict(test_x)\n",
    "out_pred = [np.argmax(x, axis=1) for x in for_report]\n",
    "out_pred = np.concatenate(out_pred, axis=0)\n",
    "\n",
    "y_ = [np.argmax(x, axis=1) for x in test_y]\n",
    "y_ = np.concatenate(y_, axis=0)\n",
    "\n",
    "cm = confusion_matrix(y_true=y_, y_pred=out_pred)\n",
    "print(cm)\n",
    "\n",
    "cr = classification_report(y_true=y_, y_pred=out_pred)\n",
    "print(cr)\n",
    "\n",
    "overall = classification_report(y_true=y_, y_pred=out_pred, output_dict=True)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=class_names, normalize=True, title='Normalized Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the average Precision, Recall and, F1-Score of different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comma, Period, Question Precision:\t0.719\n",
      "Comma, Period, Question Recall:\t\t0.707\n",
      "Comma, Period, Question F1-Score:\t0.712\n",
      "\n",
      "\n",
      "Overall Precision:\t0.575\n",
      "Overall Recall:\t\t0.447\n",
      "Overall F1-Score:\t0.455\n"
     ]
    }
   ],
   "source": [
    "# comma, period, question, exclaim, 3-dots\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "for i in range(2, 7):\n",
    "    precision.append(overall[str(i)]['precision'])\n",
    "    recall.append(overall[str(i)]['recall'])\n",
    "    f1.append(overall[str(i)]['f1-score'])\n",
    "\n",
    "print('Comma, Period, Question Precision:\\t{:.3f}'.format(np.average(precision[:3])))\n",
    "print('Comma, Period, Question Recall:\\t\\t{:.3f}'.format(np.average(recall[:3])))\n",
    "print('Comma, Period, Question F1-Score:\\t{:.3f}'.format(np.average(f1[:3])))\n",
    "print('\\n')\n",
    "\n",
    "print('Overall Precision:\\t{:.3f}'.format(np.average(precision)))\n",
    "print('Overall Recall:\\t\\t{:.3f}'.format(np.average(recall)))\n",
    "print('Overall F1-Score:\\t{:.3f}'.format(np.average(f1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
