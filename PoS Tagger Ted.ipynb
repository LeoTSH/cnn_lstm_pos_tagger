{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import io, keras, string, itertools, random, datetime, numpy as np, matplotlib.pyplot as plt, tensorflow as tf\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.initializers import glorot_uniform, random_uniform\n",
    "from keras.layers import Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Embedding, Conv1D, Flatten, Dense, Dropout, MaxPool1D, LSTM, \\\n",
    "Bidirectional, TimeDistributed, Dropout, GlobalMaxPooling1D, Input, concatenate, Reshape\n",
    "from keras import regularizers\n",
    "from keras.utils import plot_model\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom functions\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    '''\n",
    "    Description: Prints and plots the confusion matrix.\tNormalization can be applied by setting `normalize=True`\n",
    "\n",
    "    Args:\n",
    "    - cm: Confusion Matrix\n",
    "    - classes: Names of classes\n",
    "    - normalize: Whether to or to not normal values in Confusion Matrix\n",
    "    - cmap: Plot color\n",
    "    '''\n",
    "\n",
    "    # Check if normalize is true or false\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    # Format axis and plot Confusion Matrix\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data\n",
    "\n",
    "def get_labels(seq):\n",
    "    '''\n",
    "    Description: Creates a sequence of labels based on the input sequence\n",
    "\n",
    "    Args:\n",
    "    - seq: Input sequence\n",
    "    \n",
    "    Returns:\n",
    "        Sequence labels\n",
    "    '''\n",
    "    \n",
    "    labels_seq = []\n",
    "    seq = seq.split()\n",
    "    for i in range(len(seq)):\n",
    "        if ',' in seq[i]:\n",
    "            labels_seq.append('<comma>')\n",
    "        elif '.' in seq[i]:\n",
    "            labels_seq.append('<period>')\n",
    "        elif '?' in seq[i]:\n",
    "            labels_seq.append('<question>')\n",
    "        elif '!' in seq[i]:\n",
    "            labels_seq.append('<exclaim>')\n",
    "        else:\n",
    "            labels_seq.append('<na>')\n",
    "    return labels_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "name_1 = 'ted-glove-lstm'\n",
    "name_2 = 'ted-glove-cnn-lstm'\n",
    "model_name = name_1\n",
    "max_seq_len = 128\n",
    "drop_prob = 0.2\n",
    "no_filters_1 = 32\n",
    "no_filters_2 = 64\n",
    "no_filters_3 = 32\n",
    "filter_sizes = [32,32,32]\n",
    "kernel_weight = glorot_uniform(seed=50)\n",
    "bias = random_uniform(seed=50)\n",
    "kernel_reg = regularizers.l2(l=0.0001)\n",
    "kernels = [3,5,7]\n",
    "kernel_1 = 3\n",
    "kernel_2 = 5\n",
    "kernel_3 = 7\n",
    "lstm_hidden = 100\n",
    "embed_dim = 300\n",
    "adam_lr = 0.001\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "valid_split = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set misc parameters\n",
    "current = datetime.datetime.now()\n",
    "date = current.strftime('%b-%d')\n",
    "tensor_b = TensorBoard(log_dir='./tf_logs/model_{}_hidden_{}_dropout_{}_embed_dim_{}_lr_{}'.format(model_name, \n",
    "                        lstm_hidden, drop_prob,\n",
    "                        embed_dim, adam_lr), \n",
    "                        batch_size=batch_size, \n",
    "                        write_graph=True, histogram_freq=0)\n",
    "early_s = EarlyStopping(monitor='val_loss')\n",
    "class_names = ['Pad', 'NA', 'Comma', 'Period', 'Question', 'Exclaim', '3-dots']\n",
    "\n",
    "# Look-up table to remove punctuations from data\n",
    "table = str.maketrans('', '', punctuation)\n",
    "\n",
    "# Remove characters\n",
    "replace = ['♫', '♪', '–', '…', '(applause)', '(laughter)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre number of sentences: 235879\n",
      "\n",
      "\n",
      "(185073, ' and this is more fun.so this last one is called \"the sunshine kid.\"thank you very much for listening.old man sunshine was proud of his sun,and it brightened his day to see his little boy run,not because of what he’d done, nor the problems overcome,but that despite that his disposition remained a sunny one.it hadn’t always been like this.there’d been times when he’d tried to hide his brightness,you see, every star hits periods of hardship,it takes a brighter light to inspire them through the darkness.if we go back to when he was born in a nebula,we know that he never was thought of as regular,because he had a flair about him,to say the midas touch is wrongbut all he went near seemed to turn a little bronze,yes this sun was loved by some more than others,it was a case of joseph and his dreamcoat and his brothersbecause standing out from the crowd had its pros and its cons,and jealousy created enemies in those he outshonesuch as the shadow people.now the shadow people didn’t like the sunshine kid,because he showed up the dark things the shadow people did,and when he shone he showed the places where the shadow people hid,so the shadow people had an evil plan to get rid of him,first up — they made fun of his sunspots,shooting his dreams from the sky, their words were gunshots,designed to remind him he wasn’t very cooland he didn’t fit in with any popular kids at school.they said his head was up in space and they would bring him down to earth,essentially he came from nothing and that is what he was worth,he’d never get to go to university to learn,only degrees he’d ever show would be the first degree burnsfrom those that came too close, they told him he was too bright,that’s why no one ever looked him in the eyes,his judgment became cloudedso did the sky, with evaporated tearsas the sun started to cry.because the sunshine kid was bright, with a warm personality,and inside he burned savagelyhurt by the words and curses of the shadowy folkwho spoke holes in his soul and left cavities,and as his heart hardened, his spark darkened,every time they called him names it cooled his flames,he thought they might like him if he kept his light dimbut they were busy telling lightning she had terrible aim,he couldn’t quite get to grips with what they said,so he let his light be eclipsed by what they said,he fell into a lone star state like texas,and felt like he’d been punched in his solar plexus.but that’s when little miss sunshine came alongsinging her favorite song about how we’re made to be strong,and you don’t have to be wrong to belong, just be true to who you are,because we are all stars at heart.little miss sunshine was hot stuff,the kind of girl when you looked at heryou forgot stuff,but for him, there was no forgetting her,the minute he saw her her image burned in his retina,she was out of this world, and she accepted him,something about this girl meant he knew whenever she was next to him,things weren’t as dark as they seemed, and he dared to dream,shadows were nowhere to be seen; when she was there he beamed,his eyes would light up in ways that can’t be faked,when she grinned her rays erased the razor-tipped words of hate,they gave each other nicknames, they were \"cool star\" and \"fun sun,\"and gradually the shadowy damage became undone,she was one in a septillion, and she was brilliant,could turn the coldest blooded reptilians vermillion,loved by billions, from chileans to brazilians,and taught the sunshine kid the meaning of resilience.she said: “all the darkness in the worldcannot put out the light from a single candleso how the hell can they handle your light?only you can choose to dim it, and the sky is the limit, so silence the critics by burning.”and if eyes are windows to the soul then she drew back the curtainsand let the sun shine through the hurting.in a universe of adversity these stars stuck together,and though days became nights the memories would last forever,whether the weatherman said it or not, it would be fine,\\'cause even behind the clouds the kid could still shine.yes, the sunshine kid was bright, with a warm personality,and inside he burned savagely,fueled by the fire inspired across galaxiesby the girl who showed him belief.thank you very much.twenty-five years ago, scientists at cern created the world wide web.')\n",
      "\n",
      "\n",
      "Length of longest sentence: 4303\n",
      "Chunked longest sentence: 19\n",
      "Post number of sentences: 235896\n",
      "\n",
      "\n",
      "Counter({' ': 5035136, 'e': 2663136, 't': 2186841, 'a': 1811632, 'o': 1754525, 'i': 1605049, 'n': 1516022, 's': 1389255, 'r': 1196724, 'h': 1172089, 'l': 901650, 'd': 792836, 'u': 661643, 'c': 607949, 'm': 526851, 'w': 516723, 'y': 494505, 'g': 469126, 'f': 427060, 'p': 402954, 'b': 336104, 'v': 232920, 'k': 199756, 'x': 39658, 'j': 36083, '0': 32492, '—': 27887, 'z': 21023, 'q': 17817, '1': 15627, '2': 10250, '5': 6886, '9': 5657, '3': 4982, '4': 4041, '8': 3578, '6': 3223, '7': 3090, '’': 920, 'é': 283, 'í': 84, 'á': 65, 'ó': 48, 'ç': 36, 'ã': 35, 'è': 30, 'ö': 29, '“': 21, 'ñ': 20, '”': 20, 'ï': 17, 'ü': 13, 'à': 12, 'ù': 11, 'ā': 10, 'ä': 7, 'ø': 7, 'ê': 6, '\\xa0': 6, '‘': 6, 'â': 5, 'ō': 5, 'อ': 4, '£': 3, 'ë': 3, 'ô': 3, '²': 3, '\\x80': 3, 'ī': 3, 'ì': 3, 'ʾ': 3, 'ć': 2, 'ร': 2, '่': 2, 'ย': 2, 'æ': 2, '\\x93': 2, '•': 2, 'û': 1, 'º': 1, '˚': 1, 'ò': 1, '送': 1, '你': 1, '葱': 1, '¢': 1, '\\x94': 1, 'ă': 1, 'ť': 1, '€': 1, '∇': 1, 'τ': 1, 'č': 1, '¡': 1, 'å': 1, 'ě': 1, 'ū': 1, '¿': 1, 'ú': 1, 'ð': 1, 'प': 1, '्': 1, 'र': 1, 'े': 1, 'म': 1, 'š': 1, 'ọ': 1, '̀': 1, 'ẹ': 1})\n",
      "\n",
      "\n",
      "Number of sequences: \t235896\n",
      "Number of labels: \t235896\n"
     ]
    }
   ],
   "source": [
    "# Load and process input/label data\n",
    "# Read and load dataset\n",
    "data = open('./data/processed/ted_data', 'r', encoding='utf-8').read()\n",
    "\n",
    "# Convert all characters to lowercase\n",
    "data = data.lower()\n",
    "\n",
    "# Remove unnecessary characters\n",
    "for i in range(len(replace)):\n",
    "    data = data.replace(replace[i], '')\n",
    "\n",
    "# Group sentences into list\n",
    "data_split = data.split('\\n')\n",
    "print('Pre number of sentences:', len(data_split))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# Get longest sentence in dataset and its index\n",
    "print(max(enumerate(data_split), key=lambda x: len(x[1])))\n",
    "print('\\n')\n",
    "print('Length of longest sentence:', len(max(data_split, key=len)))\n",
    "\n",
    "# Clean/format longest sentence\n",
    "data_split[185073] = data_split[185073].replace(',', ', ')\n",
    "data_split[185073] = data_split[185073].replace('.', '.\\n')\n",
    "long_sent = data_split[185073].split('\\n')\n",
    "\n",
    "# Check number of sentences after chunking longest sentence\n",
    "print('Chunked longest sentence:', len(long_sent))\n",
    "\n",
    "# Remove data at index 185703\n",
    "del data_split[185073]\n",
    "\n",
    "# Add chunked sentences back to dataset\n",
    "for x in long_sent:\n",
    "    data_split.append(x)\n",
    "    \n",
    "# Remove empty rows\n",
    "data_split = data_split[:235896]\n",
    "\n",
    "# Check length of dataset after addition\n",
    "print('Post number of sentences:', len(data_split))\n",
    "print('\\n')\n",
    "\n",
    "# Get sequence labels\n",
    "process_labels = [get_labels(seq) for seq in data_split]\n",
    "process_labels = [' '.join(seq) for seq in process_labels]\n",
    "\n",
    "# Remove punctuations\n",
    "sequences = [seq.translate(table) for seq in data_split]\n",
    "\n",
    "# Combined sentences back into a single piece for Counter\n",
    "combined_sequences = ' '.join(sequences)\n",
    "\n",
    "# Check if there are characters to remove\n",
    "print(Counter(combined_sequences))\n",
    "print('\\n')\n",
    "    \n",
    "# Get all words in the dataset\n",
    "words = combined_sequences.split()\n",
    "\n",
    "# Records inputs and labels for reference\n",
    "with open('./data/processed/processed_input', 'w', encoding='utf-8') as f:\n",
    "    for x in sequences:\n",
    "        f.write(x+'\\n')\n",
    "\n",
    "with open('./data/processed/processed_labels', 'w', encoding='utf-8') as f:\n",
    "    for x in process_labels:\n",
    "        f.write(x+'\\n')\n",
    "\n",
    "# Check number of sequences and labels\n",
    "print('Number of sequences: \\t{}'.format(len(sequences)))\n",
    "print('Number of labels: \\t{}'.format(len(process_labels)))\n",
    "\n",
    "# Load processed labels\n",
    "y_labels = open('./data/processed/processed_labels', 'r', encoding='utf-8').read()\n",
    "y_labels = y_labels.split('\\n')\n",
    "y_labels = y_labels[:-1]\n",
    "all_labels = ' '.join(y_labels)\n",
    "labels_tag = all_labels.split()\n",
    "\n",
    "split = int(0.8*len(all_labels))\n",
    "test_y_counts = all_labels[split:]\n",
    "test_y_counts_split = test_y_counts.split()\n",
    "counts = Counter(test_y_counts_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 106070\n",
      "\n",
      "\n",
      "Class distribution: Counter({'<na>': 4352406, '<comma>': 354651, '<period>': 288659, '<question>': 25867, '<exclaim>': 2202})\n",
      "\n",
      "\n",
      "Number of unique labels: 6\n",
      "{'<na>': 1, '<comma>': 2, '<period>': 3, '<question>': 4, '<exclaim>': 5, '<pad>': 0}\n"
     ]
    }
   ],
   "source": [
    "# Build words vocab\n",
    "all_data = ' '.join(sequences)\n",
    "words = all_data.split()\n",
    "words_in_vocab = Counter(words)\n",
    "vocab = sorted(words_in_vocab, key=words_in_vocab.get, reverse=True)\n",
    "\n",
    "# Skip most common word\n",
    "vocab_to_int = {word: index for index, word in enumerate(vocab, 2)}\n",
    "vocab_to_int['<pad>'] = 0  # The special value used for padding\n",
    "vocab_to_int['<oov>'] = 1  # The special value used for OOVs\n",
    "unique_vocab = len(vocab_to_int)\n",
    "print('Number of unique words:', unique_vocab)\n",
    "print('\\n')\n",
    "\n",
    "# Build labels vocab\n",
    "labels_in_vocab = Counter(labels_tag)\n",
    "labels_vocab = sorted(labels_in_vocab, key=labels_in_vocab.get, reverse=True)\n",
    "label_to_int = {t: i for i, t in enumerate(labels_vocab, 1)}\n",
    "label_to_int['<pad>'] = 0  # The special value used to padding\n",
    "\n",
    "# Check labels\n",
    "no_classes = len(label_to_int)\n",
    "print('Class distribution:', Counter(labels_in_vocab))\n",
    "print('\\n')\n",
    "\n",
    "print('Number of unique labels:', no_classes)\n",
    "print(label_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'<na>': 3475153,\n",
       "         '<period>': 232197,\n",
       "         '<question>': 20620,\n",
       "         '<comma>': 286645,\n",
       "         '<exclaim>': 1746,\n",
       "         '<n': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = int(0.8*len(all_labels))\n",
    "train_y_counts = all_labels[:split]\n",
    "train_y_counts_split = train_y_counts.split()\n",
    "Counter(train_y_counts_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a>': 1,\n",
       "         '<na>': 877252,\n",
       "         '<period>': 56462,\n",
       "         '<comma>': 68006,\n",
       "         '<question>': 5247,\n",
       "         '<exclaim>': 456})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sequence: twentyfive years ago  scientists at cern created the world wide web\n",
      "\n",
      "\n",
      "Sample sequence: [14100    87   197   634    32  9807   498     2    80  1913   923     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n",
      "\n",
      "Sample label: [1 1 2 1 1 1 1 1 1 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "Encoded label [[0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "Maximum sequence length: 128\n",
      "\n",
      "\n",
      "Sequence and labels length check passed!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize input sequences\n",
    "seq_int = []\n",
    "for seq in sequences:\n",
    "    seq_int.append([vocab_to_int[word] for word in seq.split()])\n",
    "\n",
    "# Pad input sequences\n",
    "pad_seq = pad_sequences(sequences=seq_int, maxlen=max_seq_len, padding='post', value=0)\n",
    "\n",
    "# Check sample sequence\n",
    "print('Sample sequence:', sequences[-1])\n",
    "print('\\n')\n",
    "print('Sample sequence:', pad_seq[-1])\n",
    "print('\\n')\n",
    "\n",
    "# Tokenize output labels\n",
    "lab_int = []\n",
    "for lab in y_labels:\n",
    "    lab_int.append([label_to_int[word] for word in lab.split()])\n",
    "\n",
    "# Pad input labels\n",
    "pad_labels = pad_sequences(sequences=lab_int, maxlen=max_seq_len, padding='post', value=0)\n",
    "encoded_labels = [to_categorical(i, num_classes=no_classes) for i in pad_labels]\n",
    "\n",
    "# Check sample label\n",
    "print('Sample label:', pad_labels[-1])\n",
    "print('\\n')\n",
    "print('Encoded label', encoded_labels[-1])\n",
    "print('\\n')\n",
    "# Check max seq length\n",
    "print(\"Maximum sequence length: {}\".format(max_seq_len))\n",
    "print('\\n')\n",
    "\n",
    "# Check that all sequences and labels are at max sequence length \n",
    "assert len(pad_seq)==len(seq_int)\n",
    "assert len(pad_seq[0])==max_seq_len\n",
    "\n",
    "assert len(pad_labels)==len(lab_int)\n",
    "assert len(pad_labels[0])==max_seq_len\n",
    "print('Sequence and labels length check passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Dataset: \t(188716, 128) 188716\n",
      "Testing Dataset: \t\t(47180, 128) 47180\n"
     ]
    }
   ],
   "source": [
    "# Split train and label dataset\n",
    "train_test_split_frac = 0.8\n",
    "split_index = int(0.8*len(pad_seq))\n",
    "\n",
    "# Split data into training, validation, and test data (features and labels, x and y)\n",
    "train_val_x, test_x = pad_seq[:split_index], pad_seq[split_index:]\n",
    "train_val_y, test_y = encoded_labels[:split_index], encoded_labels[split_index:]\n",
    "\n",
    "# print out the shapes of your resultant feature data\n",
    "print('Training/Validation Dataset: \\t{}'.format(train_val_x.shape), len(train_val_y))\n",
    "print('Testing Dataset: \\t\\t{}'.format(test_x.shape), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 word vectors\n"
     ]
    }
   ],
   "source": [
    "# Load glove pre-trained vectors\n",
    "glove_index = dict()\n",
    "f = open('./data/embeddings/glove.6B.300d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    glove_index[word] = coefs\n",
    "f.close()\n",
    "print('{} word vectors'.format(len(glove_index)))\n",
    "\n",
    "embed_matrix = np.zeros((unique_vocab, embed_dim))\n",
    "for word, i in vocab_to_int.items():\n",
    "    embedding_vector = glove_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embed_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnn(max_seq_len, unique_vocab, embed_dim, embed_matrix, filter_sizes, kernels, kernel_weight, bias):\n",
    "    embed_input = Input(shape=(max_seq_len,))\n",
    "\n",
    "    # Add embedding layer using weights from glove\n",
    "    embed = Embedding(input_dim=unique_vocab, output_dim=embed_dim, weights=[embed_matrix], \n",
    "                        input_length=max_seq_len, trainable=False)(embed_input)\n",
    "    \n",
    "    embed = Dropout(rate=drop_prob, seed=50)(embed)\n",
    "\n",
    "    cnn_outputs = []\n",
    "    for i in range(len(filter_sizes)):\n",
    "        # Add conv1d layer\n",
    "        out_i = Conv1D(filters=filter_sizes[i], kernel_initializer=kernel_weight, bias_initializer=bias, \n",
    "                          kernel_size=kernels[i], kernel_regularizer=None, activation='relu', \n",
    "                          padding='SAME', strides=1)(embed)\n",
    "        out_i = BatchNormalization()(out_i)\n",
    "        cnn_outputs.append(out_i)\n",
    "\n",
    "    cnn_outputs = concatenate(cnn_outputs, axis=-1)\n",
    "    cnn_outputs = Dropout(rate=drop_prob, seed=50)(cnn_outputs)\n",
    "    cnn_outputs = Reshape((-1, sum(filter_sizes)))(cnn_outputs)\n",
    "    print('cnn output passed')\n",
    "    \n",
    "    dense = Dense(1024, activation='tanh')(cnn_outputs)\n",
    "    dense = Dropout(rate=drop_prob, seed=50)(dense)\n",
    "    \n",
    "    blstm_outputs = Bidirectional(LSTM(lstm_hidden, return_sequences=True))(dense)\n",
    "    print('blstm passed')\n",
    "    \n",
    "    blstm_outputs = Dropout(rate=drop_prob, seed=50)(blstm_outputs)\n",
    "    \n",
    "    output = TimeDistributed(Dense(no_classes, activation='softmax'))(blstm_outputs)\n",
    "    print('Time passed')\n",
    "    \n",
    "    model = Model(inputs=[embed_input], outputs=[output])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(adam_lr), \n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn output passed\n",
      "blstm passed\n",
      "Time passed\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 128, 300)     31821000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 128, 32)      28832       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 128, 32)      48032       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 128, 32)      67232       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 32)      128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 32)      128         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 32)      128         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 96)      0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 96)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 128, 96)      0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 1024)    99328       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128, 1024)    0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 128, 200)     900000      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128, 200)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 128, 6)       1206        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 32,966,014\n",
      "Trainable params: 1,144,822\n",
      "Non-trainable params: 31,821,192\n",
      "__________________________________________________________________________________________________\n",
      "Train on 132101 samples, validate on 56615 samples\n",
      "Epoch 1/20\n",
      "132101/132101 [==============================] - 406s 3ms/step - loss: 0.0422 - acc: 0.9864 - val_loss: 0.0347 - val_acc: 0.9881\n",
      "Epoch 2/20\n",
      "132101/132101 [==============================] - 390s 3ms/step - loss: 0.0323 - acc: 0.9890 - val_loss: 0.0322 - val_acc: 0.9888\n",
      "Epoch 3/20\n",
      "132101/132101 [==============================] - 390s 3ms/step - loss: 0.0302 - acc: 0.9896 - val_loss: 0.0303 - val_acc: 0.9894\n",
      "Epoch 4/20\n",
      "132101/132101 [==============================] - 389s 3ms/step - loss: 0.0289 - acc: 0.9899 - val_loss: 0.0292 - val_acc: 0.9896\n",
      "Epoch 5/20\n",
      "132101/132101 [==============================] - 390s 3ms/step - loss: 0.0281 - acc: 0.9902 - val_loss: 0.0284 - val_acc: 0.9900\n",
      "Epoch 6/20\n",
      "132101/132101 [==============================] - 390s 3ms/step - loss: 0.0275 - acc: 0.9903 - val_loss: 0.0280 - val_acc: 0.9901\n",
      "Epoch 7/20\n",
      "132101/132101 [==============================] - 390s 3ms/step - loss: 0.0270 - acc: 0.9905 - val_loss: 0.0277 - val_acc: 0.9902\n",
      "Epoch 8/20\n",
      "132101/132101 [==============================] - 390s 3ms/step - loss: 0.0266 - acc: 0.9906 - val_loss: 0.0274 - val_acc: 0.9903\n",
      "Epoch 9/20\n",
      "132101/132101 [==============================] - 390s 3ms/step - loss: 0.0263 - acc: 0.9907 - val_loss: 0.0272 - val_acc: 0.9904\n",
      "Epoch 10/20\n",
      "132101/132101 [==============================] - 392s 3ms/step - loss: 0.0260 - acc: 0.9908 - val_loss: 0.0267 - val_acc: 0.9905\n",
      "Epoch 11/20\n",
      "132101/132101 [==============================] - 390s 3ms/step - loss: 0.0258 - acc: 0.9908 - val_loss: 0.0268 - val_acc: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22124213b38>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model code\n",
    "model = test_cnn(max_seq_len=max_seq_len, unique_vocab=unique_vocab, embed_dim=embed_dim,\n",
    "                embed_matrix=embed_matrix, filter_sizes=filter_sizes, kernels=kernels,\n",
    "                 kernel_weight=kernel_weight, bias=bias)\n",
    "\n",
    "# Summarize model\n",
    "model.summary()\n",
    "\n",
    "# Fit, train and evaluate model\n",
    "model.fit(x=train_val_x, y=np.array(train_val_y), batch_size=batch_size, \n",
    "          epochs=epochs, validation_split=valid_split, steps_per_epoch=None, validation_steps=None,\n",
    "          shuffle=True, verbose=1, callbacks=[tensor_b, early_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Model code\n",
    "# # Create a sequential model\n",
    "# model = Sequential()\n",
    "\n",
    "# # Add embedding layer using weights from glove\n",
    "# model.add(Embedding(input_dim=unique_vocab, output_dim=embed_dim, weights=[embed_matrix], \n",
    "#                     input_length=max_seq_len, trainable=False))\n",
    "\n",
    "# # # Add dropout layer\n",
    "# # model.add(Dropout(rate=drop_prob, seed=50))\n",
    "\n",
    "# # Add conv1d layer\n",
    "# model.add(Conv1D(filters=no_filters_1, kernel_initializer=kernel_weight, bias_initializer=bias, \n",
    "#                   kernel_size=kernel_1, kernel_regularizer=None, activation='relu', \n",
    "#                   padding='SAME', strides=1))\n",
    "\n",
    "\n",
    "# # Add conv1d layer\n",
    "# model.add(Conv1D(filters=no_filters_2, kernel_initializer=kernel_weight, bias_initializer=bias, \n",
    "#                   kernel_size=kernel_2, kernel_regularizer=None, activation='relu', \n",
    "#                   padding='SAME', strides=1))\n",
    "\n",
    "\n",
    "# # Add conv1d layer\n",
    "# model.add(Conv1D(filters=no_filters_3, kernel_initializer=kernel_weight, bias_initializer=bias, \n",
    "#                   kernel_size=kernel_3, kernel_regularizer=None, activation='relu', \n",
    "#                   padding='SAME', strides=1))\n",
    "\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# # Add blstm layer\n",
    "# model.add(Bidirectional(LSTM(lstm_hidden, return_sequences=True)))\n",
    "\n",
    "# # Add dropout layer\n",
    "# model.add(Dropout(rate=drop_prob, seed=50))\n",
    "\n",
    "# # Add timedistributed layer\n",
    "# model.add(TimeDistributed(Dense(no_classes, activation='softmax')))\n",
    "\n",
    "# # Complile layers and model\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=Adam(adam_lr), \n",
    "#               metrics=['accuracy'])#, ignore_class_accuracy(0)])\n",
    "# # Summarize model\n",
    "# model.summary()\n",
    "# # Fit, train and evaluate model\n",
    "# model.fit(x=train_val_x, y=np.array(train_val_y), batch_size=batch_size, \n",
    "#           epochs=epochs, validation_split=valid_split, steps_per_epoch=None, validation_steps=None,\n",
    "#           shuffle=True, verbose=1, callbacks=[tensor_b, early_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions Index:\n",
      "[array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n",
      "       1, 1, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)]\n",
      "\n",
      "\n",
      "Prediction sequence:\n",
      "my poor parents did not care if we were any goodand we drove them crazy because we pushed we pushed because we wanted to be the best <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "\n",
      "Prediction output:\n",
      "<na> <na> <na> <na> <na> <na> <na> <na> <na> <na> <period> <na> <na> <na> <comma> <na> <na> <na> <na> <comma> <na> <na> <na> <na> <na> <na> <period> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "\n",
      "Combined prediction:\n",
      "my poor parents did not care if we were any goodand. We drove them crazy, because we pushed we pushed, because we wanted to be the best.                                                                                                     \n"
     ]
    }
   ],
   "source": [
    "# Load a sample of test data\n",
    "test_data = test_x[5874]\n",
    "\n",
    "# Restore tokenized test data back to normal sentence\n",
    "pred_x_seq = []\n",
    "for x in test_data:\n",
    "    for value, index in vocab_to_int.items():\n",
    "        if x == index:\n",
    "            pred_x_seq.append(value)\n",
    "\n",
    "# Get predicted output of test data\n",
    "pred_expand = model.predict(np.expand_dims(test_data, axis=0))\n",
    "\n",
    "# Retrieve position of highest probability from prediction\n",
    "pred_y = []\n",
    "for y in pred_expand:\n",
    "    pred_y.append(np.argmax(y, axis=1))\n",
    "print('Predictions Index:')\n",
    "print(pred_y)\n",
    "\n",
    "# Restore tokenized labels\n",
    "pred_y_seq = []\n",
    "for x in pred_y:\n",
    "    for y in x:\n",
    "        for value, index in label_to_int.items():\n",
    "            if y == index:\n",
    "                pred_y_seq.append(value)\n",
    "\n",
    "# Restore punctuations and capitalization                \n",
    "combined = []\n",
    "for i in range(len(pred_x_seq)):\n",
    "    if pred_y_seq[i] == '<comma>':\n",
    "        combined.append(str(pred_x_seq[i])+',')\n",
    "    elif pred_y_seq[i] == '<period>':\n",
    "        combined.append(str(pred_x_seq[i])+'.')\n",
    "    elif pred_y_seq[i] == '<question>':\n",
    "        combined.append(str(pred_x_seq[i])+'?')\n",
    "    elif pred_y_seq[i] == '<exclaim>':\n",
    "        combined.append(str(pred_x_seq[i])+'!')\n",
    "    else:\n",
    "        combined.append(str(pred_x_seq[i]))\n",
    "\n",
    "for i in range(len(combined)):\n",
    "    if '.' in combined[i]:\n",
    "        combined[i+1] = combined[i+1].capitalize()\n",
    "    if combined[i] == 'i':\n",
    "        combined[i] = combined[i].capitalize()\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "combined = ' '.join(combined)\n",
    "combined = combined.replace('<pad>', '')\n",
    "\n",
    "print('\\n')\n",
    "print('Prediction sequence:')            \n",
    "print(' '.join(pred_x_seq))\n",
    "print('\\n')\n",
    "print('Prediction output:')\n",
    "print(' '.join(pred_y_seq))\n",
    "print('\\n')\n",
    "print('Combined prediction:')\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset distribution: Counter({'<na>': 877252, '<comma>': 68006, '<period>': 56462, '<question>': 5247, '<exclaim>': 456, 'a>': 1})\n",
      "[[4961145       0       0      13       0       0]\n",
      " [     50  920899   13406    2827     567       0]\n",
      " [     17   31955   38888    2004     648       0]\n",
      " [    787    1971     975   56654      93       0]\n",
      " [      4    1708     748     532    2661       0]\n",
      " [      1     172     185     124       6       0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   4961158\n",
      "           1       0.96      0.98      0.97    937749\n",
      "           2       0.72      0.53      0.61     73512\n",
      "           3       0.91      0.94      0.92     60480\n",
      "           4       0.67      0.47      0.55      5653\n",
      "           5       0.00      0.00      0.00       488\n",
      "\n",
      "   micro avg       0.99      0.99      0.99   6039040\n",
      "   macro avg       0.71      0.65      0.68   6039040\n",
      "weighted avg       0.99      0.99      0.99   6039040\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[9.99997380e-01 0.00000000e+00 0.00000000e+00 2.62035597e-06\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.33191718e-05 9.82031439e-01 1.42959363e-02 3.01466597e-03\n",
      "  6.04639408e-04 0.00000000e+00]\n",
      " [2.31254761e-04 4.34690935e-01 5.29002068e-01 2.72608554e-02\n",
      "  8.81488737e-03 0.00000000e+00]\n",
      " [1.30125661e-02 3.25892857e-02 1.61210317e-02 9.36739418e-01\n",
      "  1.53769841e-03 0.00000000e+00]\n",
      " [7.07588891e-04 3.02140456e-01 1.32319123e-01 9.41093225e-02\n",
      "  4.70723510e-01 0.00000000e+00]\n",
      " [2.04918033e-03 3.52459016e-01 3.79098361e-01 2.54098361e-01\n",
      "  1.22950820e-02 0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create confusion matrix and classification report\n",
    "for_report = model.predict(test_x)\n",
    "out_pred = [np.argmax(x, axis=1) for x in for_report]\n",
    "out_pred = np.concatenate(out_pred, axis=0)\n",
    "\n",
    "y_ = [np.argmax(x, axis=1) for x in test_y]\n",
    "y_ = np.concatenate(y_, axis=0)\n",
    "\n",
    "print('Test dataset distribution:', counts)\n",
    "cm = confusion_matrix(y_true=y_, y_pred=out_pred)\n",
    "print(cm)\n",
    "\n",
    "cr = classification_report(y_true=y_, y_pred=out_pred)\n",
    "print(cr)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=class_names, normalize=True, title='Normalized Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
